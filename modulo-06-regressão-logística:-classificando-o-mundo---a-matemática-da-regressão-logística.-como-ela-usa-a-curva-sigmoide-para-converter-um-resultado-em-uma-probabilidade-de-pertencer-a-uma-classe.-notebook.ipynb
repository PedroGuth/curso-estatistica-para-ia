{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Regress√£o Log√≠stica: Classificando o Mundo\n\n## A Matem√°tica que Transforma N√∫meros em Decis√µes!\n\nFala, galera! Pedro Guth aqui! üöÄ\n\nChegamos no **M√≥dulo 6** do nosso curso \"Estat√≠stica para IA\" e hoje vamos desvendar um dos algoritmos mais elegantes da estat√≠stica: a **Regress√£o Log√≠stica**!\n\nT√°, mas o que diabos √© isso? Imagina que voc√™ t√° no Tinder (opa! üòÖ) e precisa decidir: dar like ou n√£o? A regress√£o log√≠stica √© exatamente isso - ela pega um monte de informa√ß√µes e te d√° uma probabilidade: \"Olha, tem 73% de chance de voc√™ curtir esse perfil!\"\n\nNos m√≥dulos anteriores, vimos:\n- Como descrever dados (M√≥dulo 1)\n- Distribui√ß√µes de probabilidade (M√≥dulo 2) \n- Teorema de Bayes (M√≥dulo 3)\n- Regress√£o Linear (M√≥dulo 4)\n- Correla√ß√£o (M√≥dulo 5)\n\nAgora vamos ver como a **curva sigmoide** transforma qualquer n√∫mero numa probabilidade entre 0 e 1. Liiindo!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Bora importar as bibliotecas!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para gr√°ficos mais bonitos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print \"üéØ Bibliotecas carregadas! Bora classificar o mundo!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Da Regress√£o Linear para a Log√≠stica: O Plot Twist!\n\nLembra da regress√£o linear do M√≥dulo 4? Ela era perfeita para prever valores cont√≠nuos, tipo: \"Quantos R$ vou gastar no a√ßa√≠ esse m√™s?\"\n\nMas e se a pergunta for: \"Vou comprar a√ßa√≠ hoje ou n√£o?\" A√≠ a coisa muda de figura!\n\nA regress√£o linear pode dar qualquer valor: -50, 2.7, 1000... Mas queremos uma resposta tipo \"Sim\" ou \"N√£o\", que matem√°ticamente √© 1 ou 0.\n\n**O problema:** Como transformar qualquer n√∫mero numa probabilidade entre 0 e 1?\n\n**A solu√ß√£o:** A fun√ß√£o **SIGMOIDE**! üé™\n\n```mermaid\ngraph LR\n    A[Dados de Entrada] --> B[Combina√ß√£o Linear]\n    B --> C[Fun√ß√£o Sigmoide]\n    C --> D[Probabilidade 0-1]\n    D --> E[Classifica√ß√£o]\n```\n\nA regress√£o log√≠stica √© como aquele amigo que sempre te d√° conselhos em porcentagem: \"Cara, tem 80% de chance de dar certo se voc√™ fizer isso!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos comparar regress√£o linear vs log√≠stica visualmente\n",
        "\n",
        "# Criando dados sint√©ticos\n",
        "np.random.seed(42)\n",
        "x = np.linspace(-6, 6, 100)\n",
        "\n",
        "# Regress√£o linear simples\n",
        "y_linear = 0.5 * x + 0.5\n",
        "\n",
        "# Fun√ß√£o sigmoide (cora√ß√£o da regress√£o log√≠stica)\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "y_sigmoid = sigmoid(x)\n",
        "\n",
        "# Plotando a compara√ß√£o\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Regress√£o Linear\n",
        "ax1.plot(x, y_linear, 'b-', linewidth=3, label='Regress√£o Linear')\n",
        "ax1.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Classe 0')\n",
        "ax1.axhline(y=1, color='g', linestyle='--', alpha=0.5, label='Classe 1')\n",
        "ax1.set_title('‚ùå Problema da Regress√£o Linear\\nPode dar valores fora de 0-1!')\n",
        "ax1.set_xlabel('Vari√°vel X')\n",
        "ax1.set_ylabel('Valor Previsto')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Regress√£o Log√≠stica (Sigmoide)\n",
        "ax2.plot(x, y_sigmoid, 'r-', linewidth=3, label='Fun√ß√£o Sigmoide')\n",
        "ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5, label='Classe 0')\n",
        "ax2.axhline(y=1, color='g', linestyle='--', alpha=0.5, label='Classe 1')\n",
        "ax2.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='Ponto de Decis√£o')\n",
        "ax2.set_title('‚úÖ Solu√ß√£o da Regress√£o Log√≠stica\\nSempre entre 0 e 1!')\n",
        "ax2.set_xlabel('Vari√°vel X')\n",
        "ax2.set_ylabel('Probabilidade')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print \"üéØ Olha que lindo! A sigmoide sempre fica entre 0 e 1!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä A Matem√°tica da Fun√ß√£o Sigmoide\n\nT√°, agora vem a parte boa! Vamos descomplicar a matem√°tica da sigmoide.\n\nA fun√ß√£o sigmoide √© definida como:\n\n$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n\nOnde:\n- $z$ √© nossa combina√ß√£o linear: $z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$\n- $e$ √© o n√∫mero de Euler (‚âà 2.718)\n- $\\sigma(z)$ √© nossa probabilidade (sempre entre 0 e 1)\n\n**Por que essa f√≥rmula √© genial?**\n\n1. **Quando z ‚Üí +‚àû**: $e^{-z} ‚Üí 0$, ent√£o $\\sigma(z) ‚Üí 1$\n2. **Quando z ‚Üí -‚àû**: $e^{-z} ‚Üí ‚àû$, ent√£o $\\sigma(z) ‚Üí 0$  \n3. **Quando z = 0**: $\\sigma(0) = 0.5$ (meio termo)\n\n√â como um **tradutor universal**: pega qualquer n√∫mero e transforma numa probabilidade!\n\n**üß† Dica do Pedro:** Pensa na sigmoide como aquela rampa de skate em formato de S. N√£o importa qu√£o alto voc√™ vai, sempre vai ficar dentro da pista (entre 0 e 1)!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos explorar o comportamento da sigmoide com diferentes valores\n",
        "\n",
        "def sigmoid_detalhada(z):\n",
        "    \"\"\"Fun√ß√£o sigmoide com explica√ß√£o passo a passo\"\"\"\n",
        "    exp_neg_z = np.exp(-z)\n",
        "    resultado = 1 / (1 + exp_neg_z)\n",
        "    return resultado, exp_neg_z\n",
        "\n",
        "# Testando valores espec√≠ficos\n",
        "valores_teste = [-5, -2, -1, 0, 1, 2, 5]\n",
        "\n",
        "print \"üìä AN√ÅLISE DETALHADA DA SIGMOIDE:\\n\"\n",
        "print \"z\\t| e^(-z)\\t| œÉ(z)\\t\\t| Interpreta√ß√£o\"\n",
        "print \"-\" * 65\n",
        "\n",
        "for z in valores_teste:\n",
        "    prob, exp_val = sigmoid_detalhada(z)\n",
        "    \n",
        "    if prob < 0.3:\n",
        "        interpretacao = \"Muito prov√°vel classe 0\"\n",
        "    elif prob < 0.7:\n",
        "        interpretacao = \"Incerto (zona cinza)\"\n",
        "    else:\n",
        "        interpretacao = \"Muito prov√°vel classe 1\"\n",
        "    \n",
        "    print f\"{z}\\t| {exp_val:.3f}\\t\\t| {prob:.3f}\\t\\t| {interpretacao}\"\n",
        "\n",
        "print \"\\nüéØ Repara como a sigmoide 'esmaga' valores extremos para 0 ou 1!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o comportamento da sigmoide em detalhes\n",
        "\n",
        "z_range = np.linspace(-8, 8, 1000)\n",
        "prob_range = sigmoid(z_range)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plotando a curva principal\n",
        "ax.plot(z_range, prob_range, 'b-', linewidth=4, label='œÉ(z) = 1/(1+e^(-z))')\n",
        "\n",
        "# Marcando pontos importantes\n",
        "pontos_importantes = [-4, -2, 0, 2, 4]\n",
        "for ponto in pontos_importantes:\n",
        "    prob_ponto = sigmoid(ponto)\n",
        "    ax.plot(ponto, prob_ponto, 'ro', markersize=10, alpha=0.7)\n",
        "    ax.annotate(f'z={ponto}\\nP={prob_ponto:.3f}', \n",
        "                xy=(ponto, prob_ponto), \n",
        "                xytext=(ponto, prob_ponto + 0.15),\n",
        "                ha='center', fontsize=10,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "# Linhas de refer√™ncia\n",
        "ax.axhline(y=0.5, color='orange', linestyle='--', linewidth=2, alpha=0.8, label='Ponto de Decis√£o (50%)')\n",
        "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Zonas de classifica√ß√£o\n",
        "ax.fill_between(z_range, 0, prob_range, where=(prob_range < 0.5), \n",
        "                alpha=0.2, color='red', label='Zona Classe 0')\n",
        "ax.fill_between(z_range, prob_range, 1, where=(prob_range > 0.5), \n",
        "                alpha=0.2, color='green', label='Zona Classe 1')\n",
        "\n",
        "ax.set_xlabel('Combina√ß√£o Linear (z)', fontsize=14)\n",
        "ax.set_ylabel('Probabilidade œÉ(z)', fontsize=14)\n",
        "ax.set_title('üéØ A Curva Sigmoide: Transformando N√∫meros em Probabilidades!', fontsize=16)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(-0.05, 1.05)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print \"üöÄ A sigmoide √© como um GPS da classifica√ß√£o - sempre te mostra onde voc√™ t√°!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≤ Odds, Log-Odds e a Transforma√ß√£o Logit\n\nAgora vamos conectar com conceitos de probabilidade que vimos no M√≥dulo 2! \n\n**Odds (Raz√£o de Chances):**\n\nSe a probabilidade de algo acontecer √© $p$, ent√£o:\n\n$$\\text{Odds} = \\frac{p}{1-p}$$\n\nExemplo: Se tem 70% de chance de chover (p = 0.7), ent√£o:\n- Odds = 0.7 / (1-0.7) = 0.7 / 0.3 = 2.33\n- Ou seja: \"2.33 para 1\" - pra cada 2.33 vezes que chove, 1 vez n√£o chove\n\n**Log-Odds (Logit):**\n\n$$\\text{Logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\nE aqui vem a m√°gica! Se aplicarmos a fun√ß√£o sigmoide no logit, voltamos para a probabilidade:\n\n$$p = \\frac{1}{1 + e^{-\\text{logit}(p)}}$$\n\n√â como se a sigmoide fosse a **fun√ß√£o inversa** do logit!\n\n**üß† Dica do Pedro:** Pensa assim - o logit \"estica\" as probabilidades de 0-1 para -‚àû a +‚àû, e a sigmoide \"comprime\" de volta para 0-1. √â como uma sanfona matem√°tica!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explorando a rela√ß√£o entre probabilidade, odds e logit\n",
        "\n",
        "def calcular_odds_logit(probabilidade):\n",
        "    \"\"\"Calcula odds e logit a partir da probabilidade\"\"\"\n",
        "    odds = probabilidade / (1 - probabilidade)\n",
        "    logit = np.log(odds)\n",
        "    return odds, logit\n",
        "\n",
        "def probabilidade_de_logit(logit):\n",
        "    \"\"\"Volta da logit para probabilidade (fun√ß√£o sigmoide)\"\"\"\n",
        "    return 1 / (1 + np.exp(-logit))\n",
        "\n",
        "# Testando algumas probabilidades\n",
        "probabilidades = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
        "\n",
        "print \"üé≤ TRANSFORMA√á√ïES ENTRE PROBABILIDADE, ODDS E LOGIT:\\n\"\n",
        "print \"Prob\\t| Odds\\t\\t| Logit\\t\\t| Prob (volta)\\t| Interpreta√ß√£o\"\n",
        "print \"-\" * 80\n",
        "\n",
        "for p in probabilidades:\n",
        "    odds, logit = calcular_odds_logit(p)\n",
        "    p_volta = probabilidade_de_logit(logit)\n",
        "    \n",
        "    if p < 0.5:\n",
        "        interpretacao = \"Favorece classe 0\"\n",
        "    elif p == 0.5:\n",
        "        interpretacao = \"Neutro\"\n",
        "    else:\n",
        "        interpretacao = \"Favorece classe 1\"\n",
        "    \n",
        "    print f\"{p:.2f}\\t| {odds:.3f}\\t\\t| {logit:.3f}\\t\\t| {p_volta:.3f}\\t\\t| {interpretacao}\"\n",
        "\n",
        "print \"\\nüéØ Repara: logit = 0 quando probabilidade = 0.5 (ponto neutro)!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando as tr√™s representa√ß√µes juntas\n",
        "\n",
        "p_range = np.linspace(0.01, 0.99, 100)  # Evitando 0 e 1 por causa do log\n",
        "odds_range = p_range / (1 - p_range)\n",
        "logit_range = np.log(odds_range)\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Probabilidade vs Odds\n",
        "ax1.plot(p_range, odds_range, 'b-', linewidth=3)\n",
        "ax1.set_xlabel('Probabilidade')\n",
        "ax1.set_ylabel('Odds')\n",
        "ax1.set_title('Probabilidade ‚Üí Odds')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.axhline(y=1, color='r', linestyle='--', alpha=0.7, label='Odds = 1 (50/50)')\n",
        "ax1.legend()\n",
        "\n",
        "# 2. Probabilidade vs Logit\n",
        "ax2.plot(p_range, logit_range, 'g-', linewidth=3)\n",
        "ax2.set_xlabel('Probabilidade')\n",
        "ax2.set_ylabel('Logit')\n",
        "ax2.set_title('Probabilidade ‚Üí Logit')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Logit = 0 (P=0.5)')\n",
        "ax2.legend()\n",
        "\n",
        "# 3. Logit vs Probabilidade (Sigmoide)\n",
        "logit_input = np.linspace(-5, 5, 100)\n",
        "prob_output = sigmoid(logit_input)\n",
        "ax3.plot(logit_input, prob_output, 'r-', linewidth=3)\n",
        "ax3.set_xlabel('Logit')\n",
        "ax3.set_ylabel('Probabilidade')\n",
        "ax3.set_title('Logit ‚Üí Probabilidade (Sigmoide)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.axvline(x=0, color='orange', linestyle='--', alpha=0.7, label='Ponto de decis√£o')\n",
        "ax3.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7)\n",
        "ax3.legend()\n",
        "\n",
        "# 4. Compara√ß√£o das tr√™s escalas\n",
        "idx_samples = np.linspace(10, 90, 9).astype(int)\n",
        "ax4.plot(p_range[idx_samples], p_range[idx_samples], 'bo-', label='Probabilidade', markersize=8)\n",
        "ax4.plot(p_range[idx_samples], odds_range[idx_samples]/10, 'ro-', label='Odds/10', markersize=8)\n",
        "ax4.plot(p_range[idx_samples], (logit_range[idx_samples]+5)/10, 'go-', label='(Logit+5)/10', markersize=8)\n",
        "ax4.set_xlabel('Probabilidade Original')\n",
        "ax4.set_ylabel('Valores Normalizados')\n",
        "ax4.set_title('Compara√ß√£o das Tr√™s Escalas')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print \"üîÑ Essas transforma√ß√µes s√£o a base da regress√£o log√≠stica!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Construindo o Modelo de Regress√£o Log√≠stica\n\nAgora vamos juntar todas as pe√ßas! A regress√£o log√≠stica combina:\n\n1. **Combina√ß√£o linear** (como na regress√£o linear do M√≥dulo 4)\n2. **Fun√ß√£o sigmoide** (para garantir probabilidades entre 0 e 1)\n\nO modelo completo √©:\n\n$$P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n)}}$$\n\nOnde:\n- $P(y=1|x)$ = Probabilidade da classe 1 dado o input x\n- $\\beta_0$ = Intercepto (vi√©s)\n- $\\beta_1, \\beta_2, ..., \\beta_n$ = Coeficientes das features\n- $x_1, x_2, ..., x_n$ = Valores das features\n\n**Como interpretar os coeficientes?**\n\n- Se $\\beta_i > 0$: aumentar $x_i$ **aumenta** a probabilidade da classe 1\n- Se $\\beta_i < 0$: aumentar $x_i$ **diminui** a probabilidade da classe 1\n- Quanto maior $|\\beta_i|$, maior a influ√™ncia da feature $x_i$\n\n**üß† Dica do Pedro:** Os coeficientes da regress√£o log√≠stica s√£o como os \"pesos\" de uma vota√ß√£o. Cada feature vota a favor ou contra a classe 1, e o peso do voto √© o coeficiente!\n\n```mermaid\ngraph TD\n    X1[Feature 1] --> L[Combina√ß√£o Linear]\n    X2[Feature 2] --> L\n    X3[Feature 3] --> L\n    B0[Intercepto Œ≤‚ÇÄ] --> L\n    L --> S[Fun√ß√£o Sigmoide]\n    S --> P[Probabilidade]\n    P --> D{P > 0.5?}\n    D -->|Sim| C1[Classe 1]\n    D -->|N√£o| C0[Classe 0]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos implementar regress√£o log√≠stica do zero!\n",
        "\n",
        "class RegressaoLogisticaDoZero:\n",
        "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.historico_custo = []\n",
        "    \n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"Fun√ß√£o sigmoide com prote√ß√£o contra overflow\"\"\"\n",
        "        z = np.clip(z, -500, 500)  # Evita overflow\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Treina o modelo usando gradient descent\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        \n",
        "        # Inicializa coeficientes com zeros\n",
        "        self.coef_ = np.zeros(n_features)\n",
        "        self.intercept_ = 0\n",
        "        \n",
        "        # Gradient descent\n",
        "        for i in range(self.max_iter):\n",
        "            # Combina√ß√£o linear\n",
        "            z = np.dot(X, self.coef_) + self.intercept_\n",
        "            \n",
        "            # Probabilidades\n",
        "            y_pred = self.sigmoid(z)\n",
        "            \n",
        "            # Fun√ß√£o de custo (log-likelihood negativa)\n",
        "            custo = -np.mean(y * np.log(y_pred + 1e-15) + (1 - y) * np.log(1 - y_pred + 1e-15))\n",
        "            self.historico_custo.append(custo)\n",
        "            \n",
        "            # Gradientes\n",
        "            erro = y_pred - y\n",
        "            grad_coef = np.dot(X.T, erro) / n_samples\n",
        "            grad_intercept = np.mean(erro)\n",
        "            \n",
        "            # Atualiza par√¢metros\n",
        "            self.coef_ -= self.learning_rate * grad_coef\n",
        "            self.intercept_ -= self.learning_rate * grad_intercept\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Retorna probabilidades\"\"\"\n",
        "        z = np.dot(X, self.coef_) + self.intercept_\n",
        "        return self.sigmoid(z)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Retorna classifica√ß√µes (0 ou 1)\"\"\"\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
        "\n",
        "print \"üõ†Ô∏è Classe RegressaoLogisticaDoZero implementada!\"\n",
        "print \"Agora temos nosso pr√≥prio algoritmo de classifica√ß√£o! üöÄ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um dataset sint√©tico para testar\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Criando dados: \"Vai chover hoje?\"\n",
        "# Features: umidade, temperatura, press√£o\n",
        "n_samples = 1000\n",
        "\n",
        "umidade = np.random.normal(60, 20, n_samples)  # 0-100%\n",
        "temperatura = np.random.normal(25, 8, n_samples)  # Celsius\n",
        "pressao = np.random.normal(1013, 50, n_samples)  # hPa\n",
        "\n",
        "# Criando a vari√°vel alvo com base numa l√≥gica\n",
        "# Mais chuva com: alta umidade, baixa temperatura, baixa press√£o\n",
        "z_real = -5 + 0.1 * umidade - 0.2 * temperatura - 0.01 * pressao\n",
        "prob_chuva = 1 / (1 + np.exp(-z_real))\n",
        "chuva = np.random.binomial(1, prob_chuva)\n",
        "\n",
        "# Montando o dataset\n",
        "X = np.column_stack([umidade, temperatura, pressao])\n",
        "y = chuva\n",
        "\n",
        "# Normalizando features (importante para converg√™ncia)\n",
        "X_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "# Dividindo em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print f\"üìä Dataset criado:\"\n",
        "print f\"   ‚Ä¢ {len(X_train)} amostras de treino\"\n",
        "print f\"   ‚Ä¢ {len(X_test)} amostras de teste\"\n",
        "print f\"   ‚Ä¢ {X.shape[1]} features: umidade, temperatura, press√£o\"\n",
        "print f\"   ‚Ä¢ Target: vai chover? (0=n√£o, 1=sim)\"\n",
        "print f\"   ‚Ä¢ Propor√ß√£o de chuva: {y.mean():.1%}\"\n",
        "\n",
        "# Visualizando as correla√ß√µes\n",
        "df = pd.DataFrame({\n",
        "    'Umidade': umidade,\n",
        "    'Temperatura': temperatura, \n",
        "    'Press√£o': pressao,\n",
        "    'Chuva': chuva\n",
        "})\n",
        "\n",
        "correlacoes = df.corr()['Chuva'].sort_values(ascending=False)\n",
        "print f\"\\nüîç Correla√ß√µes com a chuva:\"\n",
        "for feature, corr in correlacoes.items():\n",
        "    if feature != 'Chuva':\n",
        "        print f\"   ‚Ä¢ {feature}: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinando nosso modelo do zero\n",
        "\n",
        "print \"üöÄ Treinando regress√£o log√≠stica do zero...\\n\"\n",
        "\n",
        "# Nosso modelo\n",
        "modelo_proprio = RegressaoLogisticaDoZero(learning_rate=0.1, max_iter=1000)\n",
        "modelo_proprio.fit(X_train, y_train)\n",
        "\n",
        "# Modelo do sklearn para compara√ß√£o\n",
        "modelo_sklearn = LogisticRegression(max_iter=1000)\n",
        "modelo_sklearn.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previs√µes\n",
        "y_pred_proprio = modelo_proprio.predict(X_test)\n",
        "y_pred_sklearn = modelo_sklearn.predict(X_test)\n",
        "\n",
        "y_proba_proprio = modelo_proprio.predict_proba(X_test)\n",
        "y_proba_sklearn = modelo_sklearn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculando acur√°cias\n",
        "acc_proprio = accuracy_score(y_test, y_pred_proprio)\n",
        "acc_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print f\"üìä RESULTADOS:\\n\"\n",
        "print f\"Acur√°cia modelo pr√≥prio: {acc_proprio:.1%}\"\n",
        "print f\"Acur√°cia sklearn:        {acc_sklearn:.1%}\\n\"\n",
        "\n",
        "print f\"üîß COEFICIENTES APRENDIDOS:\\n\"\n",
        "features = ['Umidade', 'Temperatura', 'Press√£o']\n",
        "print f\"Feature\\t\\t| Nosso Modelo\\t| Sklearn\\t| Interpreta√ß√£o\")\n",
        "print \"-\" * 70\n",
        "print f\"Intercepto\\t| {modelo_proprio.intercept_:.3f}\\t\\t| {modelo_sklearn.intercept_[0]:.3f}\\t\\t| Vi√©s base\")\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    coef_proprio = modelo_proprio.coef_[i]\n",
        "    coef_sklearn = modelo_sklearn.coef_[0][i]\n",
        "    \n",
        "    if coef_proprio > 0:\n",
        "        interpretacao = \"‚Üë Favorece chuva\"\n",
        "    else:\n",
        "        interpretacao = \"‚Üì Desfavorece chuva\"\n",
        "    \n",
        "    print f\"{feature}\\t\\t| {coef_proprio:.3f}\\t\\t| {coef_sklearn:.3f}\\t\\t| {interpretacao}\")\n",
        "\n",
        "print \"\\nüéØ Nosso modelo aprendeu praticamente a mesma coisa que o sklearn!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o processo de aprendizado\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Curva de aprendizado (fun√ß√£o de custo)\n",
        "ax1.plot(modelo_proprio.historico_custo, 'b-', linewidth=2)\n",
        "ax1.set_xlabel('Itera√ß√µes')\n",
        "ax1.set_ylabel('Fun√ß√£o de Custo')\n",
        "ax1.set_title('üìà Converg√™ncia do Algoritmo')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Compara√ß√£o de probabilidades\n",
        "ax2.scatter(y_proba_sklearn, y_proba_proprio, alpha=0.6, s=20)\n",
        "ax2.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfeita concord√¢ncia')\n",
        "ax2.set_xlabel('Probabilidades Sklearn')\n",
        "ax2.set_ylabel('Probabilidades Nosso Modelo')\n",
        "ax2.set_title('üéØ Compara√ß√£o de Probabilidades')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Distribui√ß√£o de probabilidades por classe\n",
        "prob_chuva_sim = y_proba_proprio[y_test == 1]\n",
        "prob_chuva_nao = y_proba_proprio[y_test == 0]\n",
        "\n",
        "ax3.hist(prob_chuva_nao, bins=20, alpha=0.7, label='N√£o choveu', color='orange', density=True)\n",
        "ax3.hist(prob_chuva_sim, bins=20, alpha=0.7, label='Choveu', color='blue', density=True)\n",
        "ax3.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Ponto de decis√£o')\n",
        "ax3.set_xlabel('Probabilidade Prevista')\n",
        "ax3.set_ylabel('Densidade')\n",
        "ax3.set_title('üåßÔ∏è Distribui√ß√£o de Probabilidades')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Matriz de confus√£o\n",
        "cm = confusion_matrix(y_test, y_pred_proprio)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,\n",
        "            xticklabels=['N√£o Chuva', 'Chuva'],\n",
        "            yticklabels=['N√£o Chuva', 'Chuva'])\n",
        "ax4.set_xlabel('Predi√ß√£o')\n",
        "ax4.set_ylabel('Real')\n",
        "ax4.set_title('üé≤ Matriz de Confus√£o')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print \"‚úÖ Modelo treinado com sucesso! Ele aprendeu a prever chuva! üåßÔ∏è\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exemplo Pr√°tico: Classificador de E-mails Spam\n\nLembra do Teorema de Bayes do M√≥dulo 3? Agora vamos usar regress√£o log√≠stica para detectar spam!\n\nA vantagem da regress√£o log√≠stica sobre Bayes Naive √© que ela pode capturar **intera√ß√µes entre features** e n√£o assume independ√™ncia entre elas.\n\nVamos simular um detector de spam baseado em:\n- N√∫mero de palavras em MAI√öSCULO\n- N√∫mero de exclama√ß√µes (!!!)\n- Presen√ßa de palavras como \"GR√ÅTIS\", \"OFERTA\"\n- Tamanho do assunto\n\n**üß† Dica do Pedro:** Na vida real, usar√≠amos t√©cnicas como TF-IDF (Term Frequency-Inverse Document Frequency) para extrair features de texto. Mas aqui vamos simplificar para focar na regress√£o log√≠stica!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando dataset de emails sint√©tico\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def gerar_email_features(is_spam, n_emails):\n",
        "    \"\"\"Gera features de email baseado em se √© spam ou n√£o\"\"\"\n",
        "    emails = []\n",
        "    \n",
        "    for _ in range(n_emails):\n",
        "        if is_spam:\n",
        "            # Emails spam t√™m mais caracter√≠sticas \"gritantes\"\n",
        "            palavras_maiusculo = np.random.poisson(8)  # M√©dia 8 palavras em mai√∫sculo\n",
        "            num_exclamacoes = np.random.poisson(5)     # M√©dia 5 exclama√ß√µes\n",
        "            palavras_spam = np.random.poisson(3)       # M√©dia 3 palavras de spam\n",
        "            tamanho_assunto = np.random.normal(45, 15) # Assuntos mais longos\n",
        "        else:\n",
        "            # Emails leg√≠timos s√£o mais \"comportados\"\n",
        "            palavras_maiusculo = np.random.poisson(1)  # M√©dia 1 palavra em mai√∫sculo\n",
        "            num_exclamacoes = np.random.poisson(0.5)   # M√©dia 0.5 exclama√ß√µes\n",
        "            palavras_spam = 0                          # Sem palavras de spam\n",
        "            tamanho_assunto = np.random.normal(25, 10) # Assuntos mais curtos\n",
        "        \n",
        "        emails.append([\n",
        "            max(0, palavras_maiusculo),\n",
        "            max(0, num_exclamacoes), \n",
        "            max(0, palavras_spam),\n",
        "            max(5, tamanho_assunto)  # Assunto m√≠nimo de 5 caracteres\n",
        "        ])\n",
        "    \n",
        "    return np.array(emails)\n",
        "\n",
        "# Gerando dataset\n",
        "n_spam = 800\n",
        "n_legit = 1200\n",
        "\n",
        "emails_spam = gerar_email_features(True, n_spam)\n",
        "emails_legit = gerar_email_features(False, n_legit)\n",
        "\n",
        "# Juntando tudo\n",
        "X_emails = np.vstack([emails_spam, emails_legit])\n",
        "y_emails = np.hstack([np.ones(n_spam), np.zeros(n_legit)])\n",
        "\n",
        "# Embaralhando\n",
        "indices = np.random.permutation(len(X_emails))\n",
        "X_emails = X_emails[indices]\n",
        "y_emails = y_emails[indices]\n",
        "\n",
        "# Normalizando\n",
        "X_emails_norm = (X_emails - X_emails.mean(axis=0)) / X_emails.std(axis=0)\n",
        "\n",
        "print f\"üìß Dataset de emails criado:\"\n",
        "print f\"   ‚Ä¢ {len(X_emails)} emails totais\"\n",
        "print f\"   ‚Ä¢ {n_spam} spam ({n_spam/len(X_emails):.1%})\"\n",
        "print f\"   ‚Ä¢ {n_legit} leg√≠timos ({n_legit/len(X_emails):.1%})\"\n",
        "print f\"\\nüìä Features:\")\n",
        "features_email = ['Palavras MAI√öSCULO', 'Exclama√ß√µes', 'Palavras Spam', 'Tamanho Assunto']\n",
        "for i, feature in enumerate(features_email):\n",
        "    spam_avg = X_emails[y_emails == 1, i].mean()\n",
        "    legit_avg = X_emails[y_emails == 0, i].mean()\n",
        "    print f\"   ‚Ä¢ {feature}: Spam={spam_avg:.1f}, Leg√≠t={legit_avg:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinando detector de spam\n",
        "\n",
        "# Dividindo dataset\n",
        "X_train_email, X_test_email, y_train_email, y_test_email = train_test_split(\n",
        "    X_emails_norm, y_emails, test_size=0.3, random_state=42, stratify=y_emails\n",
        ")\n",
        "\n",
        "# Treinando modelo\n",
        "detector_spam = LogisticRegression(random_state=42)\n",
        "detector_spam.fit(X_train_email, y_train_email)\n",
        "\n",
        "# Fazendo previs√µes\n",
        "y_pred_email = detector_spam.predict(X_test_email)\n",
        "y_proba_email = detector_spam.predict_proba(X_test_email)[:, 1]\n",
        "\n",
        "# Avaliando performance\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(y_test_email, y_pred_email)\n",
        "precision = precision_score(y_test_email, y_pred_email)\n",
        "recall = recall_score(y_test_email, y_pred_email)\n",
        "\n",
        "print f\"üöÄ DETECTOR DE SPAM TREINADO!\\n\"\n",
        "print f\"üìä Performance:\")\n",
        "print f\"   ‚Ä¢ Acur√°cia:  {accuracy:.1%} (% de emails classificados corretamente)\")\n",
        "print f\"   ‚Ä¢ Precis√£o:  {precision:.1%} (% dos emails marcados como spam que realmente s√£o)\")\n",
        "print f\"   ‚Ä¢ Recall:    {recall:.1%} (% dos spams reais que foram detectados)\\n\")\n",
        "\n",
        "print f\"üîç Import√¢ncia das Features:\")\n",
        "for i, (feature, coef) in enumerate(zip(features_email, detector_spam.coef_[0])):\n",
        "    if coef > 0:\n",
        "        efeito = f\"‚Üë Aumenta chance de spam em {np.exp(coef):.2f}x\"\n",
        "    else:\n",
        "        efeito = f\"‚Üì Diminui chance de spam em {np.exp(-coef):.2f}x\"\n",
        "    \n",
        "    print f\"   ‚Ä¢ {feature}: {coef:.3f} - {efeito}\")\n",
        "\n",
        "print f\"\\nüéØ Intercepto: {detector_spam.intercept_[0]:.3f}\")\n",
        "print f\"   (Probabilidade base quando todas as features s√£o 0)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o detector com exemplos espec√≠ficos\n",
        "\n",
        "def testar_email(palavras_maiusculo, exclamacoes, palavras_spam, tamanho_assunto, descricao):\n",
        "    \"\"\"Testa um email espec√≠fico no detector\"\"\"\n",
        "    # Criando o vetor de features\n",
        "    email_features = np.array([[palavras_maiusculo, exclamacoes, palavras_spam, tamanho_assunto]])\n",
        "    \n",
        "    # Normalizando usando os mesmos par√¢metros do treino\n",
        "    email_norm = (email_features - X_emails.mean(axis=0)) / X_emails.std(axis=0)\n",
        "    \n",
        "    # Fazendo previs√£o\n",
        "    probabilidade = detector_spam.predict_proba(email_norm)[0, 1]\n",
        "    classificacao = \"SPAM\" if probabilidade > 0.5 else \"LEG√çTIMO\"\n",
        "    \n",
        "    print f\"üìß {descricao}:\")\n",
        "    print f\"   Features: {palavras_maiusculo} mai√∫sc, {exclamacoes} !, {palavras_spam} spam, {tamanho_assunto} chars\")\n",
        "    print f\"   Probabilidade SPAM: {probabilidade:.1%}\")\n",
        "    print f\"   Classifica√ß√£o: {classificacao}\\n\")\n",
        "    \n",
        "    return probabilidade\n",
        "\n",
        "print \"üß™ TESTANDO O DETECTOR COM EMAILS ESPEC√çFICOS:\\n\"\n",
        "\n",
        "# Teste 1: Email claramente spam\n",
        "testar_email(\n",
        "    palavras_maiusculo=12,\n",
        "    exclamacoes=8, \n",
        "    palavras_spam=5,\n",
        "    tamanho_assunto=60,\n",
        "    descricao=\"Email suspeito #1\"\n",
        ")\n",
        "\n",
        "# Teste 2: Email leg√≠timo\n",
        "testar_email(\n",
        "    palavras_maiusculo=0,\n",
        "    exclamacoes=0,\n",
        "    palavras_spam=0, \n",
        "    tamanho_assunto=20,\n",
        "    descricao=\"Email profissional\"\n",
        ")\n",
        "\n",
        "# Teste 3: Email no meio termo\n",
        "testar_email(\n",
        "    palavras_maiusculo=3,\n",
        "    exclamacoes=2,\n",
        "    palavras_spam=1,\n",
        "    tamanho_assunto=35,\n",
        "    descricao=\"Email promocional\"\n",
        ")\n",
        "\n",
        "# Teste 4: Email leg√≠timo mas entusiasmado\n",
        "testar_email(\n",
        "    palavras_maiusculo=2,\n",
        "    exclamacoes=3,\n",
        "    palavras_spam=0,\n",
        "    tamanho_assunto=25,\n",
        "    descricao=\"Email de amigo empolgado\"\n",
        ")\n",
        "\n",
        "print \"üéØ O modelo conseguiu distinguir bem os diferentes tipos de email!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualizando a Fronteira de Decis√£o\n\nUma das coisas mais legais da regress√£o log√≠stica √© que podemos visualizar como ela separa as classes!\n\nA **fronteira de decis√£o** √© onde a probabilidade = 0.5, ou seja, onde o modelo fica \"em d√∫vida\" entre as duas classes.\n\nMatematicamente, isso acontece quando:\n$$\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n = 0$$\n\nPara duas dimens√µes, a fronteira de decis√£o √© uma **linha reta**:\n$$x_2 = -\\frac{\\beta_0 + \\beta_1 x_1}{\\beta_2}$$\n\n**üß† Dica do Pedro:** A regress√£o log√≠stica sempre cria fronteiras de decis√£o **lineares**. Se seus dados precisam de fronteiras curvas, voc√™ vai precisar de t√©cnicas mais avan√ßadas como SVM com kernel ou redes neurais!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando fronteira de decis√£o em 2D\n",
        "\n",
        "# Vamos usar apenas 2 features para visualizar facilmente\n",
        "# Escolhendo as 2 features mais importantes do detector de spam\n",
        "feature_indices = np.argsort(np.abs(detector_spam.coef_[0]))[-2:]  # 2 maiores coeficientes\n",
        "feature_names_selected = [features_email[i] for i in feature_indices]\n",
        "\n",
        "print f\"üéØ Visualizando com as 2 features mais importantes:\")\n",
        "for i, (idx, name) in enumerate(zip(feature_indices, feature_names_selected)):\n",
        "    print f\"   {i+1}. {name} (coef: {detector_spam.coef_[0][idx]:.3f})\")\n",
        "\n",
        "# Dados 2D\n",
        "X_2d = X_emails_norm[:, feature_indices]\n",
        "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
        "    X_2d, y_emails, test_size=0.3, random_state=42, stratify=y_emails\n",
        ")\n",
        "\n",
        "# Treinando modelo 2D\n",
        "modelo_2d = LogisticRegression(random_state=42)\n",
        "modelo_2d.fit(X_train_2d, y_train_2d)\n",
        "\n",
        "# Criando grade para visualiza√ß√£o\n",
        "h = 0.1  # Resolu√ß√£o da grade\n",
        "x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
        "y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "# Previs√µes na grade\n",
        "Z = modelo_2d.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Gr√°fico 1: Mapa de probabilidades\n",
        "contour = ax1.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap='RdYlBu')\n",
        "scatter = ax1.scatter(X_2d[:, 0], X_2d[:, 1], c=y_emails, \n",
        "                     cmap='RdYlBu', edgecolors='black', alpha=0.7)\n",
        "\n",
        "# Linha de decis√£o (probabilidade = 0.5)\n",
        "ax1.contour(xx, yy, Z, levels=[0.5], colors='white', linestyles='--', linewidths=3)\n",
        "\n",
        "plt.colorbar(contour, ax=ax1, label='Probabilidade de SPAM')\n",
        "ax1.set_xlabel(f'{feature_names_selected[0]} (normalizado)')\n",
        "ax1.set_ylabel(f'{feature_names_selected[1]} (normalizado)')\n",
        "ax1.set_title('üéØ Mapa de Probabilidades + Fronteira de Decis√£o')\n",
        "\n",
        "# Gr√°fico 2: Apenas fronteira de decis√£o\n",
        "spam_points = X_2d[y_emails == 1]\n",
        "legit_points = X_2d[y_emails == 0]\n",
        "\n",
        "ax2.scatter(legit_points[:, 0], legit_points[:, 1], \n",
        "           c='blue', alpha=0.6, label='Leg√≠timo', s=30)\n",
        "ax2.scatter(spam_points[:, 0], spam_points[:, 1], \n",
        "           c='red', alpha=0.6, label='Spam', s=30)\n",
        "\n",
        "# Fronteira de decis√£o\n",
        "ax2.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='-', linewidths=3)\n",
        "\n",
        "# Zonas de confian√ßa\n",
        "ax2.contour(xx, yy, Z, levels=[0.2, 0.8], colors='gray', linestyles='--', alpha=0.5)\n",
        "\n",
        "ax2.set_xlabel(f'{feature_names_selected[0]} (normalizado)')\n",
        "ax2.set_ylabel(f'{feature_names_selected[1]} (normalizado)')\n",
        "ax2.set_title('üìß Classifica√ß√£o de Emails: Spam vs Leg√≠timo')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculando equa√ß√£o da fronteira\n",
        "w0, w1, w2 = modelo_2d.intercept_[0], modelo_2d.coef_[0][0], modelo_2d.coef_[0][1]\n",
        "print f\"\\nüìê Equa√ß√£o da fronteira de decis√£o:\")\n",
        "print f\"   {w2:.3f} * {feature_names_selected[1]} = -{w0:.3f} - {w1:.3f} * {feature_names_selected[0]}\")\n",
        "print f\"   ou: {feature_names_selected[1]} = {-w0/w2:.3f} + {-w1/w2:.3f} * {feature_names_selected[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è Exerc√≠cio Pr√°tico: Detector de Clientes Premium\n\nAgora √© sua vez! Vamos criar um modelo para prever se um cliente vai virar premium baseado no comportamento dele.\n\n**Cen√°rio:** Voc√™ trabalha numa empresa de streaming e quer identificar usu√°rios que t√™m potencial para assinar o plano premium.\n\n**Features dispon√≠veis:**\n- Horas assistidas por semana\n- N√∫mero de shows/filmes √∫nicos assistidos\n- Tempo desde o cadastro (em meses)\n- N√∫mero de dispositivos usados\n- Quantas vezes pulou propagandas\n\n**Seu desafio:**\n1. Treinar um modelo de regress√£o log√≠stica\n2. Interpretar os coeficientes\n3. Fazer previs√µes para novos usu√°rios\n4. Calcular m√©tricas de performance\n\n**üß† Dica do Pedro:** Pense como um usu√°rio premium se comporta diferente de um gratuito!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exerc√≠cio: Criando dataset de usu√°rios de streaming\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "def gerar_usuario_streaming(is_premium, n_usuarios):\n",
        "    \"\"\"Gera dados de usu√°rios de streaming\"\"\"\n",
        "    usuarios = []\n",
        "    \n",
        "    for _ in range(n_usuarios):\n",
        "        if is_premium:\n",
        "            # Usu√°rios premium assistem mais, exploram mais conte√∫do\n",
        "            horas_semana = np.random.normal(25, 8)        # Mais horas\n",
        "            shows_unicos = np.random.normal(15, 5)        # Mais variedade  \n",
        "            meses_cadastro = np.random.normal(18, 12)     # Usu√°rios mais antigos\n",
        "            dispositivos = np.random.poisson(3) + 1      # Mais dispositivos\n",
        "            pulos_propaganda = np.random.poisson(50)     # Pulam mais ads\n",
        "        else:\n",
        "            # Usu√°rios gratuitos t√™m comportamento mais limitado\n",
        "            horas_semana = np.random.normal(8, 4)         # Menos horas\n",
        "            shows_unicos = np.random.normal(5, 3)         # Menos variedade\n",
        "            meses_cadastro = np.random.normal(6, 6)       # Mais novos\n",
        "            dispositivos = np.random.poisson(1.5) + 1    # Menos dispositivos\n",
        "            pulos_propaganda = np.random.poisson(10)     # Pulam menos ads\n",
        "        \n",
        "        usuarios.append([\n",
        "            max(1, horas_semana),        # M√≠nimo 1 hora\n",
        "            max(1, shows_unicos),        # M√≠nimo 1 show\n",
        "            max(1, meses_cadastro),      # M√≠nimo 1 m√™s\n",
        "            max(1, dispositivos),        # M√≠nimo 1 dispositivo\n",
        "            max(0, pulos_propaganda)     # Pode ser 0\n",
        "        ])\n",
        "    \n",
        "    return np.array(usuarios)\n",
        "\n",
        "# TODO: Complete o c√≥digo abaixo\n",
        "\n",
        "# 1. Gere 1000 usu√°rios premium e 2000 usu√°rios gratuitos\n",
        "usuarios_premium = # SEU C√ìDIGO AQUI\n",
        "usuarios_gratuitos = # SEU C√ìDIGO AQUI\n",
        "\n",
        "# 2. Combine os dados em X e y\n",
        "X_streaming = # SEU C√ìDIGO AQUI\n",
        "y_streaming = # SEU C√ìDIGO AQUI\n",
        "\n",
        "# 3. Embaralhe os dados\n",
        "# SEU C√ìDIGO AQUI\n",
        "\n",
        "print \"üì∫ Dataset de streaming criado!\")\n",
        "print f\"   ‚Ä¢ Total de usu√°rios: {len(X_streaming)}\")\n",
        "print f\"   ‚Ä¢ Premium: {y_streaming.sum()} ({y_streaming.mean():.1%})\")\n",
        "print f\"   ‚Ä¢ Gratuitos: {len(y_streaming) - y_streaming.sum()}\")\n",
        "\n",
        "# Nomes das features\n",
        "features_streaming = [\n",
        "    'Horas/Semana', 'Shows √önicos', 'Meses Cadastro', \n",
        "    'Dispositivos', 'Pulos Propaganda'\n",
        "]\n",
        "\n",
        "# 4. Mostre estat√≠sticas por grupo\n",
        "print \"\\nüìä Comportamento m√©dio:\")\n",
        "print \"Feature\\t\\t\\t| Premium\\t| Gratuito\\t| Diferen√ßa\")\n",
        "print \"-\" * 60\n",
        "for i, feature in enumerate(features_streaming):\n",
        "    # SEU C√ìDIGO AQUI - calcule m√©dias para premium e gratuito\n",
        "    premium_avg = \n",
        "    gratuito_avg = \n",
        "    diferenca = premium_avg - gratuito_avg\n",
        "    print f\"{feature}\\t\\t| {premium_avg:.1f}\\t\\t| {gratuito_avg:.1f}\\t\\t| +{diferenca:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exerc√≠cio: Treinar modelo e avaliar performance\n",
        "\n",
        "# TODO: Complete as tarefas abaixo\n",
        "\n",
        "# 1. Normalize as features\n",
        "X_streaming_norm = # SEU C√ìDIGO AQUI\n",
        "\n",
        "# 2. Divida em treino e teste (70/30)\n",
        "X_train_stream, X_test_stream, y_train_stream, y_test_stream = # SEU C√ìDIGO AQUI\n",
        "\n",
        "# 3. Treine um modelo de regress√£o log√≠stica\n",
        "modelo_streaming = # SEU C√ìDIGO AQUI\n",
        "# SEU C√ìDIGO AQUI - fit\n",
        "\n",
        "# 4. Fa√ßa previs√µes\n",
        "y_pred_stream = # SEU C√ìDIGO AQUI\n",
        "y_proba_stream = # SEU C√ìDIGO AQUI\n",
        "\n",
        "# 5. Calcule m√©tricas\n",
        "accuracy_stream = # SEU C√ìDIGO AQUI\n",
        "precision_stream = # SEU C√ìDIGO AQUI  \n",
        "recall_stream = # SEU C√ìDIGO AQUI\n",
        "\n",
        "print \"üöÄ MODELO DE PREDI√á√ÉO DE USU√ÅRIOS PREMIUM\\n\"\n",
        "\n",
        "print f\"üìä Performance do Modelo:\"\n",
        "print f\"   ‚Ä¢ Acur√°cia:  {accuracy_stream:.1%}\"\n",
        "print f\"   ‚Ä¢ Precis√£o:  {precision_stream:.1%} (dos marcados como premium, quantos realmente s√£o)\"\n",
        "print f\"   ‚Ä¢ Recall:    {recall_stream:.1%} (dos premium reais, quantos foram detectados)\\n\")\n",
        "\n",
        "# 6. Interprete os coeficientes\n",
        "print f\"üîç Influ√™ncia de cada Feature:\")\n",
        "print f\"Feature\\t\\t\\t| Coeficiente\\t| Impacto\")\n",
        "print \"-\" * 55\n",
        "\n",
        "for i, (feature, coef) in enumerate(zip(features_streaming, modelo_streaming.coef_[0])):\n",
        "    # TODO: Calcule o fator multiplicativo (exponencial do coeficiente)\n",
        "    fator = # SEU C√ìDIGO AQUI\n",
        "    \n",
        "    if coef > 0:\n",
        "        impacto = f\"‚Üë +{(fator-1)*100:.0f}% chance premium\"\n",
        "    else:\n",
        "        impacto = f\"‚Üì -{(1-fator)*100:.0f}% chance premium\"\n",
        "    \n",
        "    print f\"{feature}\\t\\t| {coef:.3f}\\t\\t| {impacto}\")\n",
        "\n",
        "print f\"\\nIntercepto: {modelo_streaming.intercept_[0]:.3f}\")\n",
        "print f\"(Chance base quando todas as features s√£o m√©dia)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Resum√£o: O que Aprendemos sobre Regress√£o Log√≠stica\n\nUfa! Que jornada! Vamos recapitular os **pontos-chave** da regress√£o log√≠stica:\n\n### üìö **Conceitos Fundamentais:**\n\n1. **Fun√ß√£o Sigmoide**: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n   - Transforma qualquer n√∫mero em probabilidade (0 a 1)\n   - Formato de \"S\" caracter√≠stico\n   - Ponto de inflex√£o em z=0 (probabilidade=0.5)\n\n2. **Modelo Completo**: $P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n)}}$\n   - Combina regress√£o linear + fun√ß√£o sigmoide\n   - Sempre produz probabilidades v√°lidas\n\n3. **Interpreta√ß√£o dos Coeficientes**:\n   - $\\beta_i > 0$: feature aumenta chance da classe 1\n   - $\\beta_i < 0$: feature diminui chance da classe 1  \n   - $e^{\\beta_i}$ = fator multiplicativo nas odds\n\n### üîó **Conex√µes com M√≥dulos Anteriores:**\n\n- **M√≥dulo 2 (Probabilidade)**: Usamos conceitos de odds e probabilidade condicional\n- **M√≥dulo 3 (Bayes)**: Comparamos com classifica√ß√£o Naive Bayes  \n- **M√≥dulo 4 (Regress√£o Linear)**: Evolu√ß√£o natural para problemas de classifica√ß√£o\n- **M√≥dulo 5 (Correla√ß√£o)**: Features correlacionadas influenciam os coeficientes\n\n### üöÄ **Prepara√ß√£o para Pr√≥ximos M√≥dulos:**\n\n- **M√≥dulo 7 (Amostragem)**: Como o tamanho da amostra afeta a qualidade do modelo\n- **M√≥dulo 8 (Testes de Hip√≥tese)**: Testar se os coeficientes s√£o significativos\n- **M√≥dulo 10 (Valida√ß√£o)**: M√©tricas como precis√£o, recall, F1-score para avaliar classificadores\n\n### üí° **Aplica√ß√µes Pr√°ticas:**\n\n- ‚úÖ Detec√ß√£o de spam em emails\n- ‚úÖ Previs√£o de churn de clientes  \n- ‚úÖ Diagn√≥stico m√©dico (doente/saud√°vel)\n- ‚úÖ Aprova√ß√£o de cr√©dito\n- ‚úÖ Detec√ß√£o de fraude\n\n**üß† Dica Final do Pedro:** A regress√£o log√≠stica √© como um **juiz matem√°tico** - ela pesa todas as evid√™ncias (features) e d√° um veredicto probabil√≠stico. √â simples, interpret√°vel e funciona muito bem na pr√°tica!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-06_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C√≥digo final: Compara√ß√£o de todos os conceitos\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Evolu√ß√£o: Linear ‚Üí Log√≠stica\n",
        "x = np.linspace(-4, 4, 100)\n",
        "y_linear = x\n",
        "y_logistic = sigmoid(x)\n",
        "\n",
        "ax1.plot(x, y_linear, 'b--', linewidth=2, label='Regress√£o Linear', alpha=0.7)\n",
        "ax1.plot(x, y_logistic, 'r-', linewidth=3, label='Regress√£o Log√≠stica')\n",
        "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "ax1.axhline(y=1, color='gray', linestyle='-', alpha=0.3)\n",
        "ax1.fill_between(x, 0, 1, alpha=0.1, color='green', label='Zona de probabilidades v√°lidas')\n",
        "ax1.set_xlabel('Combina√ß√£o Linear (z)')\n",
        "ax1.set_ylabel('Sa√≠da do Modelo')\n",
        "ax1.set_title('üìà Evolu√ß√£o: Linear ‚Üí Log√≠stica')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Transforma√ß√µes: Probabilidade ‚Üî Logit\n",
        "p = np.linspace(0.01, 0.99, 100)\n",
        "logits = np.log(p / (1 - p))\n",
        "\n",
        "ax2.plot(p, logits, 'g-', linewidth=3, label='p ‚Üí logit')\n",
        "ax2.axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Ponto neutro')\n",
        "ax2.set_xlabel('Probabilidade')\n",
        "ax2.set_ylabel('Logit')\n",
        "ax2.set_title('üîÑ Transforma√ß√£o Logit')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Compara√ß√£o de Performance dos Modelos\n",
        "modelos = ['Chuva', 'Spam', 'Streaming']\n",
        "acuracias = [acc_proprio, accuracy, accuracy_stream]  # Substitua pelas suas vari√°veis\n",
        "\n",
        "bars = ax3.bar(modelos, acuracias, color=['skyblue', 'lightcoral', 'lightgreen'], alpha=0.8)\n",
        "ax3.set_ylabel('Acur√°cia')\n",
        "ax3.set_title('üèÜ Performance dos Modelos')\n",
        "ax3.set_ylim(0, 1)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, acc in zip(bars, acuracias):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Resumo Visual da Sigmoide\n",
        "z_range = np.linspace(-6, 6, 1000)\n",
        "prob_range = sigmoid(z_range)\n",
        "\n",
        "ax4.plot(z_range, prob_range, 'purple', linewidth=4, label='œÉ(z)')\n",
        "ax4.fill_between(z_range, 0, prob_range, where=(prob_range < 0.5), \n",
        "                alpha=0.3, color='red', label='Classe 0')\n",
        "ax4.fill_between(z_range, prob_range, 1, where=(prob_range > 0.5), \n",
        "                alpha=0.3, color='blue', label='Classe 1')\n",
        "\n",
        "# Pontos importantes\n",
        "pontos_z = [-2, 0, 2]\n",
        "for pz in pontos_z:\n",
        "    prob = sigmoid(pz)\n",
        "    ax4.plot(pz, prob, 'ko', markersize=8)\n",
        "    ax4.annotate(f'({pz}, {prob:.2f})', (pz, prob), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "ax4.set_xlabel('z (Combina√ß√£o Linear)')\n",
        "ax4.set_ylabel('œÉ(z) (Probabilidade)')\n",
        "ax4.set_title('üéØ A Fun√ß√£o Sigmoide: Cora√ß√£o da Regress√£o Log√≠stica')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print \"\\n\" + \"=\"*70\n",
        "print \"üéâ PARAB√âNS! Voc√™ dominou a Regress√£o Log√≠stica!\"\n",
        "print \"=\"*70\n",
        "print \"\\nüöÄ Pr√≥ximo destino: M√≥dulo 7 - Amostragem e Erro!\"\n",
        "print \"   Vamos aprender como tirar conclus√µes sobre popula√ß√µes usando amostras!\\n\"\n",
        "print \"üí° Lembre-se: A regress√£o log√≠stica √© sua ferramenta para transformar\")\n",
        "print \"   qualquer problema de classifica√ß√£o em probabilidades interpret√°veis!\\n\")\n",
        "print \"üß† Dica final: Na vida real, sempre valide seus modelos com dados\")\n",
        "print \"   que o modelo nunca viu. A matem√°tica √© linda, mas a realidade\")\n",
        "print \"   √© o teste final! üéØ\")"
      ]
    }
  ]
}