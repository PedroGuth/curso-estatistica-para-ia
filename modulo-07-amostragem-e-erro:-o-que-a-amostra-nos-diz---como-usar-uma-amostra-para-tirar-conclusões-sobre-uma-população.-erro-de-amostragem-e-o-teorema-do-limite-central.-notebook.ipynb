{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Da Amostra para o Universo: Desvendando os Segredos do Teorema do Limite Central\n\n**M√≥dulo 7 - Estat√≠stica para IA**\n\n*Por Pedro Nunes Guth*\n\n---\n\nE a√≠, pessoal! Bora para mais um m√≥dulo incr√≠vel! üöÄ\n\nT√°, mas vamos pensar numa situa√ß√£o bem brasileira: voc√™ quer saber quantos gols o Pel√© faria se jogasse hoje no Brasileir√£o. Obviamente n√£o d√° pra fazer ele jogar todos os jogos poss√≠veis (seria lindo, mas imposs√≠vel n√©?). Ent√£o o que fazemos? Pegamos uma **amostra** dos jogos e tentamos descobrir o **universo** todo!\n\nIsso √© exatamente o que vamos aprender hoje: como uma pequena amostra pode nos contar segredos sobre uma popula√ß√£o gigantesca. E o melhor: vamos entender o **Teorema do Limite Central**, que √© tipo o \"Holy Grail\" da estat√≠stica!\n\n**O que vamos ver hoje:**\n- Como funciona a amostragem\n- Tipos de erro que podem rolar\n- O Teorema do Limite Central (prepare-se para ter a mente explodida!)\n- Como aplicar isso em IA\n\nBora nessa jornada!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - As bibliotecas que v√£o nos ajudar nessa jornada!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from IPython.display import Markdown, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para deixar os gr√°ficos mais bonitos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Semente para reprodutibilidade (porque ci√™ncia √© reproduz√≠vel!)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"üéØ Bibliotecas carregadas! Bora come√ßar a explorar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≤ Parte 1: O Conceito de Amostragem\n\n### T√°, mas o que √© Amostragem?\n\nImagina que voc√™ quer saber a altura m√©dia dos brasileiros. Voc√™ n√£o vai medir os 215 milh√µes de brasileiros, n√©? Seria loucura! Ent√£o voc√™ pega uma **amostra** representativa - digamos 1000 pessoas - e usa ela pra estimar a altura de **toda** a popula√ß√£o.\n\nIsso √© **amostragem**: usar uma parte pequena (amostra) para entender o todo (popula√ß√£o).\n\n### Os Conceitos Fundamentais:\n\n**Popula√ß√£o (N)**: O conjunto completo que queremos estudar\n- Exemplo: Todos os usu√°rios do Instagram no Brasil\n\n**Amostra (n)**: Um subconjunto da popula√ß√£o que conseguimos observar\n- Exemplo: 5000 usu√°rios selecionados aleatoriamente\n\n**Par√¢metro**: Uma caracter√≠stica da **popula√ß√£o** (geralmente desconhecida)\n- Exemplo: Œº (mu) = m√©dia verdadeira da popula√ß√£o\n\n**Estat√≠stica**: Uma caracter√≠stica da **amostra** (que conseguimos calcular)\n- Exemplo: xÃÑ (x-barra) = m√©dia da amostra\n\n### Dica do Pedro üí°\n*Lembra dos m√≥dulos anteriores quando falamos de distribui√ß√µes? A m√°gica da amostragem √© que mesmo que a popula√ß√£o tenha qualquer formato, as m√©dias das amostras sempre tendem a formar uma distribui√ß√£o normal! Isso √© o Teorema do Limite Central que vamos ver daqui a pouco!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma popula√ß√£o simulada - imagine que s√£o as alturas dos brasileiros\n",
        "# Vou usar uma distribui√ß√£o que N√ÉO √© normal pra mostrar a m√°gica!\n",
        "\n",
        "# Popula√ß√£o: 100.000 brasileiros com altura seguindo uma distribui√ß√£o exponencial\n",
        "# (bem longe da normal!)\n",
        "populacao_size = 100000\n",
        "populacao = np.random.exponential(scale=1.70, size=populacao_size)  # M√©dia em torno de 1.70m\n",
        "\n",
        "# Par√¢metros VERDADEIROS da popula√ß√£o (que na vida real n√£o conhecemos)\n",
        "mu_real = np.mean(populacao)  # M√©dia verdadeira\n",
        "sigma_real = np.std(populacao)  # Desvio padr√£o verdadeiro\n",
        "\n",
        "print(f\"üìä POPULA√á√ÉO CRIADA!\")\n",
        "print(f\"Tamanho da popula√ß√£o: {populacao_size:,} pessoas\")\n",
        "print(f\"Altura m√©dia REAL (Œº): {mu_real:.3f}m\")\n",
        "print(f\"Desvio padr√£o REAL (œÉ): {sigma_real:.3f}m\")\n",
        "print(f\"Altura m√≠nima: {np.min(populacao):.3f}m\")\n",
        "print(f\"Altura m√°xima: {np.max(populacao):.3f}m\")\n",
        "\n",
        "# Visualizando a distribui√ß√£o da popula√ß√£o\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(populacao, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.axvline(mu_real, color='red', linestyle='--', linewidth=2, label=f'M√©dia Real = {mu_real:.3f}m')\n",
        "plt.title('Distribui√ß√£o das Alturas na Popula√ß√£o (Exponencial - N√£o Normal!)', fontsize=16)\n",
        "plt.xlabel('Altura (metros)')\n",
        "plt.ylabel('Frequ√™ncia')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Repara que a distribui√ß√£o √© bem assim√©trica, n√£o √© uma normal!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-07_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Parte 2: Tipos de Amostragem\n\n### Amostragem Aleat√≥ria Simples\n√â como fazer um sorteio justo - cada elemento da popula√ß√£o tem a mesma chance de ser escolhido.\n\n### Outras T√©cnicas:\n- **Estratificada**: Divide a popula√ß√£o em grupos e amostra de cada grupo\n- **Sistem√°tica**: Pega elementos em intervalos regulares\n- **Por Conglomerados**: Divide em grupos e sorteia grupos inteiros\n\n### Matem√°tica da Amostragem:\n\nQuando pegamos uma amostra de tamanho $n$ de uma popula√ß√£o com m√©dia $\\mu$ e desvio $\\sigma$, a m√©dia amostral $\\bar{X}$ tem as seguintes propriedades:\n\n$$E[\\bar{X}] = \\mu$$\n\n$$Var(\\bar{X}) = \\frac{\\sigma^2}{n}$$\n\n$$DP(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}$$\n\nEssa √∫ltima √© o **Erro Padr√£o** da m√©dia! Repara que quanto maior a amostra (n), menor o erro!\n\n### Dica do Pedro üí°\n*Olha s√≥ que lindo: o erro padr√£o diminui com a raiz quadrada do tamanho da amostra. Isso significa que pra ter metade do erro, voc√™ precisa de 4 vezes mais dados!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos testar diferentes tamanhos de amostra\n",
        "tamanhos_amostra = [10, 30, 100, 500, 1000]\n",
        "num_amostras = 1000  # Vamos pegar 1000 amostras de cada tamanho\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for n in tamanhos_amostra:\n",
        "    # Para cada tamanho, vamos coletar 1000 amostras diferentes\n",
        "    medias_amostrais = []\n",
        "    \n",
        "    for i in range(num_amostras):\n",
        "        # Amostragem aleat√≥ria simples\n",
        "        amostra = np.random.choice(populacao, size=n, replace=False)\n",
        "        media_amostra = np.mean(amostra)\n",
        "        medias_amostrais.append(media_amostra)\n",
        "    \n",
        "    # Calculando as estat√≠sticas das m√©dias amostrais\n",
        "    media_das_medias = np.mean(medias_amostrais)\n",
        "    erro_padrao_empirico = np.std(medias_amostrais)\n",
        "    erro_padrao_teorico = sigma_real / np.sqrt(n)\n",
        "    \n",
        "    resultados[n] = {\n",
        "        'medias': medias_amostrais,\n",
        "        'media_das_medias': media_das_medias,\n",
        "        'erro_padrao_empirico': erro_padrao_empirico,\n",
        "        'erro_padrao_teorico': erro_padrao_teorico\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nüìä AMOSTRA TAMANHO {n}:\")\n",
        "    print(f\"   M√©dia das m√©dias amostrais: {media_das_medias:.4f}m\")\n",
        "    print(f\"   Erro padr√£o emp√≠rico: {erro_padrao_empirico:.4f}m\")\n",
        "    print(f\"   Erro padr√£o te√≥rico: {erro_padrao_teorico:.4f}m\")\n",
        "    print(f\"   Diferen√ßa entre real e estimado: {abs(mu_real - media_das_medias):.4f}m\")\n",
        "\n",
        "print(f\"\\nüéØ M√©dia REAL da popula√ß√£o: {mu_real:.4f}m\")\n",
        "print(\"\\nüí° Repara como conforme aumenta o tamanho da amostra:\")\n",
        "print(\"   1. A m√©dia das m√©dias fica mais pr√≥xima da m√©dia real\")\n",
        "print(\"   2. O erro padr√£o diminui (menos variabilidade)\")\n",
        "print(\"   3. A teoria bate com a pr√°tica!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o efeito do tamanho da amostra\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, n in enumerate(tamanhos_amostra):\n",
        "    medias = resultados[n]['medias']\n",
        "    \n",
        "    axes[i].hist(medias, bins=30, alpha=0.7, color=f'C{i}', density=True, edgecolor='black')\n",
        "    axes[i].axvline(mu_real, color='red', linestyle='--', linewidth=2, label=f'Œº real = {mu_real:.3f}')\n",
        "    axes[i].axvline(np.mean(medias), color='green', linestyle='-', linewidth=2, \n",
        "                   label=f'M√©dia amostral = {np.mean(medias):.3f}')\n",
        "    \n",
        "    axes[i].set_title(f'Distribui√ß√£o das M√©dias\\nAmostra n={n}', fontsize=12)\n",
        "    axes[i].set_xlabel('M√©dia da Amostra')\n",
        "    axes[i].set_ylabel('Densidade')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Removendo o √∫ltimo subplot\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('üéØ Teorema do Limite Central em A√ß√£o!\\nRepara como as distribui√ß√µes ficam mais normais e estreitas', \n",
        "             fontsize=16, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"ü§Ø OLHA ESSA M√ÅGICA! Mesmo a popula√ß√£o sendo exponencial (assim√©trica),\")\n",
        "print(\"   as distribui√ß√µes das M√âDIAS amostrais ficam cada vez mais normais!\")\n",
        "print(\"   Isso √© o Teorema do Limite Central funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Parte 3: O Teorema do Limite Central - A Joia da Coroa!\n\n### O que diz o Teorema?\n\nBora para a defini√ß√£o formal (mas descomplicada):\n\n> **Se voc√™ pegar amostras suficientemente grandes (n ‚â• 30) de QUALQUER popula√ß√£o com m√©dia Œº e vari√¢ncia œÉ¬≤, a distribui√ß√£o das m√©dias amostrais se aproxima de uma distribui√ß√£o normal, independentemente da forma da popula√ß√£o original!**\n\nMatem√°ticamente:\n\n$$\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$\n\nOu padronizando:\n\n$$Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)$$\n\n### Por que isso √© REVOLUCION√ÅRIO?\n\n1. **N√£o importa a distribui√ß√£o original**: Exponencial, uniforme, qualquer coisa vira normal!\n2. **Permite infer√™ncia**: Podemos usar propriedades da normal para qualquer popula√ß√£o\n3. **Base de tudo**: Intervalos de confian√ßa, testes de hip√≥tese, tudo depende disso!\n\n### Analogia do Pedro üçï\n*√â como se voc√™ tivesse v√°rias pizzarias com sabores malucos e diferentes. Mas quando voc√™ pega a \"m√©dia\" de satisfa√ß√£o de v√°rias pessoas que comeram em cada pizzaria, essas m√©dias sempre formam uma curva bem comportada (normal), mesmo que os sabores individuais sejam completamente diferentes!*\n\n### Dica do Pedro üí°\n*Lembra do M√≥dulo 2 quando estudamos a distribui√ß√£o normal? Agora voc√™ entende por que ela √© t√£o importante! O TLC garante que ela aparece em todo lugar na estat√≠stica!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph TD\n    A[Popula√ß√£o com QUALQUER Distribui√ß√£o] --> B[Coleta Amostra 1]\n    A --> C[Coleta Amostra 2] \n    A --> D[Coleta Amostra 3]\n    A --> E[... Muitas Amostras ...]\n    A --> F[Coleta Amostra n]\n    \n    B --> G[Calcula M√©dia 1]\n    C --> H[Calcula M√©dia 2]\n    D --> I[Calcula M√©dia 3]\n    E --> J[...]\n    F --> K[Calcula M√©dia n]\n    \n    G --> L[Distribui√ß√£o das M√©dias]\n    H --> L\n    I --> L\n    J --> L\n    K --> L\n    \n    L --> M[üìä SEMPRE Normal! üéØ]\n    \n    style A fill:#ff9999\n    style M fill:#99ff99\n    style L fill:#99ccff\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos testar o TLC com diferentes distribui√ß√µes malucas!\n",
        "def teste_tlc(distribuicao_func, nome, n_amostra=100, n_simulacoes=1000):\n",
        "    \"\"\"\n",
        "    Testa o Teorema do Limite Central com qualquer distribui√ß√£o\n",
        "    \"\"\"\n",
        "    # Gera a popula√ß√£o\n",
        "    populacao = distribuicao_func(10000)\n",
        "    mu_pop = np.mean(populacao)\n",
        "    sigma_pop = np.std(populacao)\n",
        "    \n",
        "    # Coleta muitas amostras e calcula suas m√©dias\n",
        "    medias_amostrais = []\n",
        "    for _ in range(n_simulacoes):\n",
        "        amostra = np.random.choice(populacao, size=n_amostra)\n",
        "        medias_amostrais.append(np.mean(amostra))\n",
        "    \n",
        "    return populacao, medias_amostrais, mu_pop, sigma_pop\n",
        "\n",
        "# Testando com distribui√ß√µes bem diferentes\n",
        "distribuicoes = {\n",
        "    'Uniforme': lambda n: np.random.uniform(0, 10, n),\n",
        "    'Exponencial': lambda n: np.random.exponential(2, n),\n",
        "    'Chi-quadrado': lambda n: np.random.chisquare(2, n),\n",
        "    'Beta Assim√©trica': lambda n: np.random.beta(0.5, 2, n)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(4, 2, figsize=(16, 20))\n",
        "\n",
        "for i, (nome, func) in enumerate(distribuicoes.items()):\n",
        "    populacao, medias, mu, sigma = teste_tlc(func, nome)\n",
        "    \n",
        "    # Popula√ß√£o original\n",
        "    axes[i, 0].hist(populacao, bins=50, alpha=0.7, color='red', density=True)\n",
        "    axes[i, 0].set_title(f'Popula√ß√£o Original: {nome}\\n(Nada normal!)', fontsize=12)\n",
        "    axes[i, 0].set_ylabel('Densidade')\n",
        "    axes[i, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Distribui√ß√£o das m√©dias amostrais\n",
        "    axes[i, 1].hist(medias, bins=30, alpha=0.7, color='green', density=True)\n",
        "    \n",
        "    # Sobrepondo a normal te√≥rica\n",
        "    x = np.linspace(min(medias), max(medias), 100)\n",
        "    normal_teorica = stats.norm.pdf(x, mu, sigma/np.sqrt(100))\n",
        "    axes[i, 1].plot(x, normal_teorica, 'r--', linewidth=3, label='Normal Te√≥rica')\n",
        "    \n",
        "    axes[i, 1].set_title(f'M√©dias Amostrais: {nome}\\n(Olha s√≥, virou normal!)', fontsize=12)\n",
        "    axes[i, 1].set_ylabel('Densidade')\n",
        "    axes[i, 1].legend()\n",
        "    axes[i, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    print(f\"\\nüìä {nome}:\")\n",
        "    print(f\"   M√©dia populacional: {mu:.3f}\")\n",
        "    print(f\"   M√©dia das m√©dias amostrais: {np.mean(medias):.3f}\")\n",
        "    print(f\"   Erro padr√£o te√≥rico: {sigma/np.sqrt(100):.3f}\")\n",
        "    print(f\"   Erro padr√£o emp√≠rico: {np.std(medias):.3f}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nü§Ø M√ÅGICA PURA! N√£o importa como √© a popula√ß√£o original,\")\n",
        "print(\"   as m√©dias amostrais SEMPRE viram normais!\")\n",
        "print(\"   Isso √© o poder do Teorema do Limite Central!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-07_img_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Parte 4: Tipos de Erro na Amostragem\n\n### 1. Erro de Amostragem (Sampling Error)\n√â a diferen√ßa natural entre a estat√≠stica da amostra e o par√¢metro da popula√ß√£o. **√â inevit√°vel!** Acontece porque estamos olhando apenas uma parte do todo.\n\n$$\\text{Erro de Amostragem} = \\bar{X} - \\mu$$\n\n### 2. Erro Padr√£o (Standard Error)\n√â o desvio padr√£o da distribui√ß√£o amostral da m√©dia:\n\n$$SE = \\frac{\\sigma}{\\sqrt{n}}$$\n\nQuanto maior a amostra, menor o erro padr√£o!\n\n### 3. Erros N√£o-Amostrais\n- **Vi√©s de Sele√ß√£o**: Amostra n√£o representativa\n- **Erro de Medi√ß√£o**: Instrumentos ruins\n- **N√£o-resposta**: Pessoas que se recusam a participar\n\n### Matem√°tica dos Erros:\n\nPara um intervalo de confian√ßa de 95%, temos:\n\n$$P\\left(\\mu - 1.96 \\times \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} \\leq \\mu + 1.96 \\times \\frac{\\sigma}{\\sqrt{n}}\\right) = 0.95$$\n\nIsso significa que 95% das m√©dias amostrais estar√£o dentro de 1.96 erros padr√£o da m√©dia populacional!\n\n### Dica do Pedro üí°\n*Lembra do M√≥dulo 6 quando vimos regress√£o log√≠stica? Os erros de amostragem afetam diretamente a qualidade dos nossos modelos! Por isso √© t√£o importante entender isso.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando erros de amostragem\n",
        "def calcular_erros_amostragem(populacao, tamanhos_amostra, n_simulacoes=1000):\n",
        "    \"\"\"\n",
        "    Calcula erros de amostragem para diferentes tamanhos de amostra\n",
        "    \"\"\"\n",
        "    mu_real = np.mean(populacao)\n",
        "    sigma_real = np.std(populacao)\n",
        "    \n",
        "    resultados = {}\n",
        "    \n",
        "    for n in tamanhos_amostra:\n",
        "        erros = []\n",
        "        medias_amostrais = []\n",
        "        \n",
        "        for _ in range(n_simulacoes):\n",
        "            amostra = np.random.choice(populacao, size=n)\n",
        "            media_amostra = np.mean(amostra)\n",
        "            erro = media_amostra - mu_real  # Erro de amostragem\n",
        "            \n",
        "            medias_amostrais.append(media_amostra)\n",
        "            erros.append(erro)\n",
        "        \n",
        "        erro_padrao_teorico = sigma_real / np.sqrt(n)\n",
        "        erro_padrao_empirico = np.std(medias_amostrais)\n",
        "        \n",
        "        resultados[n] = {\n",
        "            'erros': erros,\n",
        "            'medias': medias_amostrais,\n",
        "            'erro_padrao_teorico': erro_padrao_teorico,\n",
        "            'erro_padrao_empirico': erro_padrao_empirico,\n",
        "            'erro_medio_absoluto': np.mean(np.abs(erros))\n",
        "        }\n",
        "    \n",
        "    return resultados, mu_real, sigma_real\n",
        "\n",
        "# Testando com nossa popula√ß√£o de alturas\n",
        "tamanhos = [20, 50, 100, 200, 500]\n",
        "resultados_erro, mu_real, sigma_real = calcular_erros_amostragem(populacao, tamanhos)\n",
        "\n",
        "# Visualizando os erros\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, n in enumerate(tamanhos):\n",
        "    erros = resultados_erro[n]['erros']\n",
        "    erro_padrao = resultados_erro[n]['erro_padrao_teorico']\n",
        "    \n",
        "    axes[i].hist(erros, bins=30, alpha=0.7, color=f'C{i}', density=True, edgecolor='black')\n",
        "    axes[i].axvline(0, color='red', linestyle='--', linewidth=2, label='Erro = 0 (perfeito)')\n",
        "    axes[i].axvline(-1.96*erro_padrao, color='orange', linestyle=':', linewidth=2, label='95% IC')\n",
        "    axes[i].axvline(1.96*erro_padrao, color='orange', linestyle=':', linewidth=2)\n",
        "    \n",
        "    axes[i].set_title(f'Distribui√ß√£o dos Erros\\nn = {n}', fontsize=12)\n",
        "    axes[i].set_xlabel('Erro de Amostragem')\n",
        "    axes[i].set_ylabel('Densidade')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "# Removendo o √∫ltimo subplot\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('üìä Distribui√ß√£o dos Erros de Amostragem\\nRepara como os erros diminuem com amostras maiores', \n",
        "             fontsize=16, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Tabela resumo\n",
        "print(\"\\nüìä RESUMO DOS ERROS:\")\n",
        "print(\"Tamanho | Erro Padr√£o Te√≥rico | Erro Padr√£o Emp√≠rico | Erro M√©dio Absoluto\")\n",
        "print(\"-\" * 80)\n",
        "for n in tamanhos:\n",
        "    teorico = resultados_erro[n]['erro_padrao_teorico']\n",
        "    empirico = resultados_erro[n]['erro_padrao_empirico']\n",
        "    medio = resultados_erro[n]['erro_medio_absoluto']\n",
        "    print(f\"   {n:3d}   |      {teorico:.4f}        |      {empirico:.4f}       |      {medio:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph TD\n    A[Popula√ß√£o Real Œº = ?] --> B[Amostra 1]\n    A --> C[Amostra 2]\n    A --> D[Amostra 3]\n    \n    B --> E[xÃÑ‚ÇÅ = 1.68]\n    C --> F[xÃÑ‚ÇÇ = 1.72]\n    D --> G[xÃÑ‚ÇÉ = 1.69]\n    \n    E --> H[Erro‚ÇÅ = xÃÑ‚ÇÅ - Œº]\n    F --> I[Erro‚ÇÇ = xÃÑ‚ÇÇ - Œº]\n    G --> J[Erro‚ÇÉ = xÃÑ‚ÇÉ - Œº]\n    \n    H --> K[Distribui√ß√£o dos Erros]\n    I --> K\n    J --> K\n    \n    K --> L[Erro Padr√£o = œÉ/‚àön]\n    \n    style A fill:#ff9999\n    style K fill:#99ccff\n    style L fill:#99ff99\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lise da rela√ß√£o entre tamanho da amostra e precis√£o\n",
        "tamanhos_grandes = np.arange(10, 1001, 20)\n",
        "erros_padroes = []\n",
        "custos_relativos = []  # Simula o \"custo\" de coletar dados\n",
        "\n",
        "for n in tamanhos_grandes:\n",
        "    erro_padrao = sigma_real / np.sqrt(n)\n",
        "    erros_padroes.append(erro_padrao)\n",
        "    custos_relativos.append(np.sqrt(n))  # Custo cresce com ‚àön\n",
        "\n",
        "# Gr√°fico da rela√ß√£o custo-benef√≠cio\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Erro padr√£o vs tamanho da amostra\n",
        "ax1.plot(tamanhos_grandes, erros_padroes, 'b-', linewidth=2, label='Erro Padr√£o')\n",
        "ax1.set_xlabel('Tamanho da Amostra (n)')\n",
        "ax1.set_ylabel('Erro Padr√£o')\n",
        "ax1.set_title('Erro Padr√£o vs Tamanho da Amostra\\n(Lei da Raiz Quadrada)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Custo vs precis√£o\n",
        "ax2.plot(custos_relativos, erros_padroes, 'r-', linewidth=2, label='Trade-off')\n",
        "ax2.set_xlabel('Custo Relativo (‚àön)')\n",
        "ax2.set_ylabel('Erro Padr√£o')\n",
        "ax2.set_title('Trade-off: Custo vs Precis√£o\\n(Quanto pagar pela precis√£o?)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "# Efici√™ncia marginal (quanto voc√™ ganha dobrando a amostra)\n",
        "eficiencia = []\n",
        "for i in range(1, len(erros_padroes)):\n",
        "    reducao_erro = erros_padroes[i-1] - erros_padroes[i]\n",
        "    eficiencia.append(reducao_erro)\n",
        "\n",
        "ax3.plot(tamanhos_grandes[1:], eficiencia, 'g-', linewidth=2, label='Ganho Marginal')\n",
        "ax3.set_xlabel('Tamanho da Amostra (n)')\n",
        "ax3.set_ylabel('Redu√ß√£o no Erro Padr√£o')\n",
        "ax3.set_title('Lei dos Rendimentos Decrescentes\\n(Cada observa√ß√£o adicional vale menos)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí∞ ECONOMIA DA AMOSTRAGEM:\")\n",
        "print(\"\\n1. üîç Lei da Raiz Quadrada: Para reduzir o erro pela metade, precisa de 4x mais dados\")\n",
        "print(\"2. üí∏ Trade-off Custo-Benef√≠cio: Cada observa√ß√£o adicional custa mais caro\")\n",
        "print(\"3. üìâ Rendimentos Decrescentes: A partir de certo ponto, n√£o compensa aumentar muito\")\n",
        "print(\"\\nüéØ DICA PR√ÅTICA: Amostras entre 100-500 geralmente s√£o um bom equil√≠brio!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Parte 5: Aplica√ß√µes Pr√°ticas em IA\n\n### Onde Usamos Isso em IA?\n\n1. **Valida√ß√£o de Modelos**: Cross-validation usa amostragem\n2. **A/B Testing**: Comparar vers√µes de algoritmos\n3. **Bootstrapping**: Reamostragem para estimar incerteza\n4. **Treinamento de Modelos**: Cada batch √© uma amostra\n5. **Avalia√ß√£o de Performance**: M√©tricas em dados de teste\n\n### Conex√£o com os Pr√≥ximos M√≥dulos:\n- **M√≥dulo 8 (Testes de Hip√≥tese)**: O TLC √© a base para testar se dois modelos s√£o diferentes\n- **M√≥dulo 9 (Intervalos de Confian√ßa)**: Usamos o erro padr√£o para criar intervalos\n- **M√≥dulo 10 (Valida√ß√£o)**: Cross-validation √© pura amostragem!\n\n### F√≥rmulas Importantes para IA:\n\n**Intervalo de Confian√ßa para Acur√°cia:**\n$$IC = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n\n**Teste de Diferen√ßa entre Modelos:**\n$$Z = \\frac{\\hat{p_1} - \\hat{p_2}}{\\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1} + \\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}}}$$\n\n### Dica do Pedro üí°\n*Agora voc√™ entende por que dividimos os dados em treino/valida√ß√£o/teste! Cada conjunto √© uma amostra diferente, e o TLC garante que podemos fazer infer√™ncias v√°lidas sobre a performance do modelo na popula√ß√£o toda!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simula√ß√£o pr√°tica: Comparando dois modelos de IA\n",
        "# Vamos simular as acur√°cias de dois modelos em diferentes amostras\n",
        "\n",
        "def simular_modelo_ia(acuracia_real, n_testes, tamanho_amostra=1000):\n",
        "    \"\"\"\n",
        "    Simula um modelo de IA com acur√°cia real conhecida\n",
        "    Retorna as acur√°cias observadas em diferentes amostras\n",
        "    \"\"\"\n",
        "    acuracias_observadas = []\n",
        "    \n",
        "    for _ in range(n_testes):\n",
        "        # Simula classifica√ß√µes corretas/incorretas\n",
        "        classificacoes = np.random.binomial(1, acuracia_real, tamanho_amostra)\n",
        "        acuracia_observada = np.mean(classificacoes)\n",
        "        acuracias_observadas.append(acuracia_observada)\n",
        "    \n",
        "    return acuracias_observadas\n",
        "\n",
        "# Simulando dois modelos\n",
        "modelo_a_real = 0.85  # 85% de acur√°cia real\n",
        "modelo_b_real = 0.87  # 87% de acur√°cia real (ligeiramente melhor)\n",
        "\n",
        "n_simulacoes = 1000\n",
        "tamanho_teste = 500  # Tamanho do conjunto de teste\n",
        "\n",
        "acuracias_a = simular_modelo_ia(modelo_a_real, n_simulacoes, tamanho_teste)\n",
        "acuracias_b = simular_modelo_ia(modelo_b_real, n_simulacoes, tamanho_teste)\n",
        "\n",
        "# An√°lise estat√≠stica\n",
        "media_a = np.mean(acuracias_a)\n",
        "media_b = np.mean(acuracias_b)\n",
        "std_a = np.std(acuracias_a)\n",
        "std_b = np.std(acuracias_b)\n",
        "\n",
        "# Erro padr√£o te√≥rico para propor√ß√µes\n",
        "se_a_teorico = np.sqrt(modelo_a_real * (1 - modelo_a_real) / tamanho_teste)\n",
        "se_b_teorico = np.sqrt(modelo_b_real * (1 - modelo_b_real) / tamanho_teste)\n",
        "\n",
        "print(\"ü§ñ SIMULA√á√ÉO DE MODELOS DE IA\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüìä MODELO A:\")\n",
        "print(f\"   Acur√°cia real: {modelo_a_real:.3f}\")\n",
        "print(f\"   Acur√°cia m√©dia observada: {media_a:.3f}\")\n",
        "print(f\"   Desvio padr√£o observado: {std_a:.4f}\")\n",
        "print(f\"   Erro padr√£o te√≥rico: {se_a_teorico:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä MODELO B:\")\n",
        "print(f\"   Acur√°cia real: {modelo_b_real:.3f}\")\n",
        "print(f\"   Acur√°cia m√©dia observada: {media_b:.3f}\")\n",
        "print(f\"   Desvio padr√£o observado: {std_b:.4f}\")\n",
        "print(f\"   Erro padr√£o te√≥rico: {se_b_teorico:.4f}\")\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Subplot 1: Distribui√ß√µes das acur√°cias\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(acuracias_a, bins=30, alpha=0.7, label=f'Modelo A (real={modelo_a_real})', color='red', density=True)\n",
        "plt.hist(acuracias_b, bins=30, alpha=0.7, label=f'Modelo B (real={modelo_b_real})', color='blue', density=True)\n",
        "plt.axvline(modelo_a_real, color='red', linestyle='--', linewidth=2, label='A: Acur√°cia Real')\n",
        "plt.axvline(modelo_b_real, color='blue', linestyle='--', linewidth=2, label='B: Acur√°cia Real')\n",
        "plt.xlabel('Acur√°cia Observada')\n",
        "plt.ylabel('Densidade')\n",
        "plt.title('Distribui√ß√£o das Acur√°cias\\n(TLC em a√ß√£o!)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Compara√ß√£o direta\n",
        "plt.subplot(1, 2, 2)\n",
        "diferenca = np.array(acuracias_b) - np.array(acuracias_a)\n",
        "plt.hist(diferenca, bins=30, alpha=0.7, color='green', density=True)\n",
        "plt.axvline(0, color='red', linestyle='--', linewidth=2, label='Diferen√ßa = 0')\n",
        "plt.axvline(np.mean(diferenca), color='green', linestyle='-', linewidth=2, \n",
        "           label=f'Diferen√ßa M√©dia = {np.mean(diferenca):.4f}')\n",
        "plt.xlabel('Diferen√ßa (B - A)')\n",
        "plt.ylabel('Densidade')\n",
        "plt.title('Distribui√ß√£o das Diferen√ßas\\n(B √© melhor que A?)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# An√°lise pr√°tica\n",
        "proporcao_b_melhor = np.mean(np.array(acuracias_b) > np.array(acuracias_a))\n",
        "print(f\"\\nüéØ AN√ÅLISE PR√ÅTICA:\")\n",
        "print(f\"   Diferen√ßa real entre modelos: {modelo_b_real - modelo_a_real:.3f}\")\n",
        "print(f\"   Diferen√ßa observada m√©dia: {np.mean(diferenca):.4f}\")\n",
        "print(f\"   % das vezes que B foi melhor que A: {proporcao_b_melhor:.1%}\")\n",
        "print(f\"\\nüí° Com apenas {tamanho_teste} exemplos de teste, h√° sobreposi√ß√£o!\")\n",
        "print(f\"   Isso mostra a import√¢ncia de entender variabilidade amostral em IA!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-07_img_03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio 1: Investigando o Tamanho M√≠nimo da Amostra\n\n**Desafio:** Voc√™ foi contratado pela Netflix para estimar a avalia√ß√£o m√©dia dos filmes brasileiros na plataforma. A popula√ß√£o tem m√©dia Œº = 7.2 e desvio padr√£o œÉ = 1.8.\n\n**Sua miss√£o:**\n1. Determinar qual tamanho de amostra √© necess√°rio para ter 95% de confian√ßa de que sua estimativa estar√° dentro de ¬±0.1 da m√©dia real\n2. Implementar uma simula√ß√£o para verificar sua resposta\n3. Analisar o trade-off entre precis√£o e custo\n\n**Dicas:**\n- Use a f√≥rmula: $n = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2$\n- Para 95% de confian√ßa, $z_{\\alpha/2} = 1.96$\n- E = margem de erro desejada (0.1)\n\n**Bora codar!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1 - SEU C√ìDIGO AQUI!\n",
        "\n",
        "# Par√¢metros dados\n",
        "mu_real = 7.2  # M√©dia real da popula√ß√£o\n",
        "sigma_real = 1.8  # Desvio padr√£o real\n",
        "margem_erro = 0.1  # Margem de erro desejada\n",
        "confianca = 0.95  # N√≠vel de confian√ßa\n",
        "z_critico = 1.96  # Valor z para 95% de confian√ßa\n",
        "\n",
        "# TODO: Calcule o tamanho da amostra necess√°rio\n",
        "# n = (z * sigma / E)¬≤\n",
        "n_necessario = None  # <-- Substitua pelo c√°lculo correto\n",
        "\n",
        "print(f\"üìä C√ÅLCULO DO TAMANHO DA AMOSTRA\")\n",
        "print(f\"Tamanho necess√°rio: {n_necessario} observa√ß√µes\")\n",
        "\n",
        "# TODO: Crie uma simula√ß√£o para verificar\n",
        "# 1. Gere uma popula√ß√£o com os par√¢metros dados\n",
        "# 2. Colete 1000 amostras do tamanho calculado\n",
        "# 3. Calcule quantas % ficaram dentro da margem de erro\n",
        "\n",
        "# Sua simula√ß√£o aqui...\n",
        "\n",
        "# TODO: Fa√ßa uma an√°lise de diferentes tamanhos de amostra\n",
        "# e mostre o trade-off precis√£o vs custo\n",
        "\n",
        "print(\"\\nüéØ Seu c√≥digo aqui! Boa sorte!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio 2: Detectando Vi√©s na Amostragem\n\n**Desafio:** Voc√™ suspeita que um sistema de recomenda√ß√£o est√° viesado - ele parece recomendar mais filmes para usu√°rios de certas regi√µes.\n\n**Cen√°rio:**\n- Popula√ß√£o: 60% Sudeste, 25% Nordeste, 10% Sul, 5% outras regi√µes\n- Voc√™ coletou 500 intera√ß√µes e encontrou: 70% Sudeste, 20% Nordeste, 8% Sul, 2% outras\n\n**Sua miss√£o:**\n1. Implementar um teste para detectar se essa diferen√ßa √© estatisticamente significativa\n2. Usar o TLC para calcular intervalos de confian√ßa para cada propor√ß√£o\n3. Criar uma visualiza√ß√£o que mostre o vi√©s\n4. Propor uma solu√ß√£o para corrigir o vi√©s\n\n**Dica:** Use a distribui√ß√£o normal para propor√ß√µes: $p \\pm z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2 - SEU C√ìDIGO AQUI!\n",
        "\n",
        "# Dados do problema\n",
        "proporcoes_reais = {'Sudeste': 0.60, 'Nordeste': 0.25, 'Sul': 0.10, 'Outras': 0.05}\n",
        "proporcoes_observadas = {'Sudeste': 0.70, 'Nordeste': 0.20, 'Sul': 0.08, 'Outras': 0.02}\n",
        "n_amostra = 500\n",
        "\n",
        "print(\"üîç AN√ÅLISE DE VI√âS NA AMOSTRAGEM\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# TODO: Para cada regi√£o, calcule:\n",
        "# 1. O intervalo de confian√ßa da propor√ß√£o observada\n",
        "# 2. Se a propor√ß√£o real est√° dentro do IC\n",
        "# 3. A diferen√ßa padronizada (z-score)\n",
        "\n",
        "for regiao in proporcoes_reais.keys():\n",
        "    p_real = proporcoes_reais[regiao]\n",
        "    p_obs = proporcoes_observadas[regiao]\n",
        "    \n",
        "    # TODO: Calcule o intervalo de confian√ßa\n",
        "    # IC = p ¬± z * sqrt(p(1-p)/n)\n",
        "    \n",
        "    # TODO: Calcule o z-score\n",
        "    # z = (p_obs - p_real) / sqrt(p_real(1-p_real)/n)\n",
        "    \n",
        "    print(f\"\\nüìä {regiao}:\")\n",
        "    print(f\"   Real: {p_real:.3f}, Observado: {p_obs:.3f}\")\n",
        "    # Seus c√°lculos aqui...\n",
        "\n",
        "# TODO: Crie uma visualiza√ß√£o comparando real vs observado\n",
        "\n",
        "# TODO: Implemente uma corre√ß√£o por pesos\n",
        "# Como voc√™ corrigiria esse vi√©s?\n",
        "\n",
        "print(\"\\nüéØ Complete o c√≥digo e descubra o vi√©s!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-07_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstra√ß√£o final: O poder do TLC em a√ß√£o!\n",
        "# Vamos mostrar como diferentes distribui√ß√µes convergem para a normal\n",
        "\n",
        "def demonstracao_tlc_final():\n",
        "    \"\"\"\n",
        "    Demonstra√ß√£o √©pica do Teorema do Limite Central\n",
        "    \"\"\"\n",
        "    # Criando distribui√ß√µes bem malucas\n",
        "    distribuicoes = {\n",
        "        'Bin√°ria': lambda n: np.random.choice([0, 1], n),\n",
        "        'Triangular': lambda n: np.random.triangular(0, 5, 10, n),\n",
        "        'Laplace': lambda n: np.random.laplace(5, 2, n),\n",
        "        'Gamma': lambda n: np.random.gamma(2, 2, n)\n",
        "    }\n",
        "    \n",
        "    tamanhos_amostra = [1, 5, 10, 30, 100]\n",
        "    n_simulacoes = 1000\n",
        "    \n",
        "    fig, axes = plt.subplots(len(distribuicoes), len(tamanhos_amostra), \n",
        "                            figsize=(20, 16))\n",
        "    \n",
        "    for i, (nome, func) in enumerate(distribuicoes.items()):\n",
        "        # Gera popula√ß√£o\n",
        "        populacao = func(10000)\n",
        "        mu = np.mean(populacao)\n",
        "        \n",
        "        for j, n in enumerate(tamanhos_amostra):\n",
        "            # Coleta m√©dias amostrais\n",
        "            medias = []\n",
        "            for _ in range(n_simulacoes):\n",
        "                amostra = np.random.choice(populacao, n)\n",
        "                medias.append(np.mean(amostra))\n",
        "            \n",
        "            # Plot\n",
        "            axes[i, j].hist(medias, bins=25, alpha=0.7, density=True, \n",
        "                           color=f'C{i}', edgecolor='black')\n",
        "            axes[i, j].axvline(mu, color='red', linestyle='--', linewidth=1)\n",
        "            \n",
        "            if i == 0:\n",
        "                axes[i, j].set_title(f'n = {n}', fontsize=12)\n",
        "            if j == 0:\n",
        "                axes[i, j].set_ylabel(f'{nome}', fontsize=12)\n",
        "            \n",
        "            axes[i, j].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('üéØ TEOREMA DO LIMITE CENTRAL: A M√ÅGICA ACONTECENDO!\\n' + \n",
        "                 'Repara como TODAS as distribui√ß√µes viram normais conforme n aumenta', \n",
        "                 fontsize=16, y=1.02)\n",
        "    plt.show()\n",
        "    \n",
        "    return \"Liiindo! Agora voc√™ entende o poder do TLC!\"\n",
        "\n",
        "resultado = demonstracao_tlc_final()\n",
        "print(f\"\\nüéâ {resultado}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÜ RESUMO DO QUE APRENDEMOS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. üé≤ Amostragem nos permite conhecer popula√ß√µes gigantes\")\n",
        "print(\"2. üìä O TLC garante que m√©dias amostrais s√£o sempre normais\")\n",
        "print(\"3. ‚ö†Ô∏è  Erros de amostragem s√£o inevit√°veis, mas previs√≠veis\")\n",
        "print(\"4. üìè Erro padr√£o = œÉ/‚àön (lei da raiz quadrada)\")\n",
        "print(\"5. ü§ñ Tudo isso √© fundamental para IA e Machine Learning\")\n",
        "print(\"\\nüöÄ Pr√≥ximo m√≥dulo: Testes de Hip√≥tese - vai ser √©pico!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Resumo e Pr√≥ximos Passos\n\n### O que Dominamos Hoje:\n\n**1. Fundamentos da Amostragem** üéØ\n- Diferen√ßa entre popula√ß√£o e amostra\n- Par√¢metros vs estat√≠sticas\n- Tipos de amostragem\n\n**2. Teorema do Limite Central** üöÄ\n- A m√°gica que transforma qualquer distribui√ß√£o em normal\n- F√≥rmula: $\\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})$\n- Por que √© a base de toda infer√™ncia estat√≠stica\n\n**3. Erros de Amostragem** ‚ö†Ô∏è\n- Erro padr√£o: $SE = \\frac{\\sigma}{\\sqrt{n}}$\n- Lei da raiz quadrada\n- Trade-off custo vs precis√£o\n\n**4. Aplica√ß√µes em IA** ü§ñ\n- Valida√ß√£o de modelos\n- A/B testing\n- Estima√ß√£o de incerteza\n\n### Conex√µes com o Curso:\n- **M√≥dulos 1-2**: Usamos distribui√ß√µes e medidas de centralidade\n- **M√≥dulos 3-6**: Aplicamos probabilidade e regress√£o\n- **M√≥dulos 8-10**: Vamos usar TLC para testes e valida√ß√£o\n\n### Dica Final do Pedro üí°\n*O TLC √© literalmente o \"Santo Graal\" da estat√≠stica! Agora voc√™ tem o superpoder de fazer infer√™ncias sobre popula√ß√µes gigantescas usando apenas pequenas amostras. No pr√≥ximo m√≥dulo, vamos usar isso para fazer testes de hip√≥tese - prepare-se para decidir cientificamente entre diferentes modelos de IA!*\n\n**Bora para o M√≥dulo 8: Testes de Hip√≥tese!** üéØ\n\n---\n\n*\"Na estat√≠stica, como na vida, uma boa amostra vale mais que mil opini√µes.\"* - Pedro Guth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-07_img_05.png)"
      ]
    }
  ]
}