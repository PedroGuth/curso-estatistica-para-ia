{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modulo5_correlacao_covariancia.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Correla√ß√£o e Covari√¢ncia: O Tinder das Vari√°veis! üíï\n\n## M√≥dulo 5: An√°lise de Correla√ß√£o e Covari√¢ncia - Onde as Vari√°veis se Encontram\n\n**Por Pedro Nunes Guth**\n\n---\n\nE a√≠, galera! T√° pronto pra descobrir quando duas vari√°veis est√£o \"dando match\"? üòÇ\n\nNos m√≥dulos anteriores, a gente j√° viu:\n- Como descrever uma vari√°vel sozinha (medidas de centralidade)\n- Como as distribui√ß√µes funcionam\n- Como fazer uma vari√°vel prever outra (regress√£o linear)\n\nMas e se eu te disser que existe uma forma de medir o quanto duas vari√°veis \"conversam\" entre si? √â isso que vamos ver hoje!\n\n**Bora descobrir quando as vari√°veis est√£o flertando! üî•**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O que vamos aprender hoje?\n\nImagina que voc√™ t√° no shopping e percebe que:\n- Quando faz calor, vende mais sorvete\n- Quando chove, vende mais guarda-chuva\n- Quando √© fim de m√™s, vende menos de tudo üòÖ\n\nIsso √© **CORRELA√á√ÉO** e **COVARI√ÇNCIA** na pr√°tica!\n\nHoje vamos entender:\n1. **Covari√¢ncia**: Como duas vari√°veis variam juntas\n2. **Correla√ß√£o**: A vers√£o \"normalizada\" da covari√¢ncia\n3. **Interpreta√ß√£o**: O que esses n√∫meros significam na vida real\n4. **Implementa√ß√£o**: Como calcular na m√£o e no Python\n\n**Dica do Pedro**: Correla√ß√£o ‚â† Causalidade! S√≥ porque duas coisas andam juntas, n√£o significa que uma causa a outra! üß†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup inicial - Importando as bibliotecas que vamos usar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurando o matplotlib para ficar mais bonito\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Seed para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"üöÄ Bibliotecas carregadas! Bora come√ßar!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Entendendo a Covari√¢ncia: A Base de Tudo\n\nT√°, mas o que √© **covari√¢ncia**?\n\nImagina duas pessoas dan√ßando. Se elas se movem na mesma dire√ß√£o ao mesmo tempo, elas est√£o \"co-variando\" positivamente. Se uma vai pra direita quando a outra vai pra esquerda, est√£o co-variando negativamente.\n\n### üßÆ A Matem√°tica por Tr√°s\n\nA covari√¢ncia entre duas vari√°veis X e Y √© calculada assim:\n\n$$Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$\n\nOnde:\n- $x_i$ e $y_i$ s√£o os valores individuais\n- $\\bar{x}$ e $\\bar{y}$ s√£o as m√©dias\n- $n$ √© o n√∫mero de observa√ß√µes\n\n**Traduzindo**: Pra cada ponto, a gente v√™ o quanto X est√° longe da sua m√©dia E o quanto Y est√° longe da sua m√©dia. Depois multiplica esses \"desvios\" e tira a m√©dia de tudo.\n\n### üé≠ Interpreta√ß√£o:\n- **Positiva**: Quando X aumenta, Y tende a aumentar\n- **Negativa**: Quando X aumenta, Y tende a diminuir  \n- **Zero**: X e Y n√£o t√™m rela√ß√£o linear\n\n**Dica do Pedro**: A covari√¢ncia n√£o tem limite! Pode ser qualquer valor. Por isso ela √© meio dif√≠cil de interpretar na pr√°tica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar alguns dados pra entender na pr√°tica\n",
        "# Exemplo: Horas de estudo vs Nota na prova\n",
        "\n",
        "horas_estudo = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "notas = np.array([3, 4, 5, 6, 7, 7.5, 8, 8.5, 9, 9.5])\n",
        "\n",
        "print(\"üìö Dados: Horas de Estudo vs Notas\")\n",
        "print(f\"Horas de estudo: {horas_estudo}\")\n",
        "print(f\"Notas: {notas}\")\n",
        "\n",
        "# Calculando a m√©dia de cada vari√°vel\n",
        "media_horas = np.mean(horas_estudo)\n",
        "media_notas = np.mean(notas)\n",
        "\n",
        "print(f\"\\nüìä M√©dias:\")\n",
        "print(f\"M√©dia de horas: {media_horas}\")\n",
        "print(f\"M√©dia de notas: {media_notas}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a covari√¢ncia na m√£o (pra entender o processo)\n",
        "def calcular_covariancia_manual(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a covari√¢ncia entre duas vari√°veis na m√£o\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    media_x = np.mean(x)\n",
        "    media_y = np.mean(y)\n",
        "    \n",
        "    # Calculando os desvios\n",
        "    desvios_x = x - media_x\n",
        "    desvios_y = y - media_y\n",
        "    \n",
        "    # Produto dos desvios\n",
        "    produtos = desvios_x * desvios_y\n",
        "    \n",
        "    # Covari√¢ncia amostral (n-1)\n",
        "    covariancia = np.sum(produtos) / (n - 1)\n",
        "    \n",
        "    return covariancia, desvios_x, desvios_y, produtos\n",
        "\n",
        "# Calculando\n",
        "cov_manual, desvios_h, desvios_n, produtos = calcular_covariancia_manual(horas_estudo, notas)\n",
        "\n",
        "print(\"üîç Processo de c√°lculo da covari√¢ncia:\")\n",
        "print(f\"Desvios das horas: {desvios_h}\")\n",
        "print(f\"Desvios das notas: {desvios_n}\")\n",
        "print(f\"Produtos dos desvios: {produtos}\")\n",
        "print(f\"\\nüìà Covari√¢ncia calculada na m√£o: {cov_manual:.4f}\")\n",
        "\n",
        "# Comparando com o NumPy\n",
        "cov_numpy = np.cov(horas_estudo, notas)[0, 1]\n",
        "print(f\"üìà Covari√¢ncia pelo NumPy: {cov_numpy:.4f}\")\n",
        "print(f\"\\n‚úÖ Diferen√ßa: {abs(cov_manual - cov_numpy):.10f} (quase zero!)\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Correla√ß√£o: A Covari√¢ncia \"Normalizada\"\n\nO problema da covari√¢ncia √© que ela depende da escala dos dados. Se eu medir altura em metros ou cent√≠metros, a covari√¢ncia vai ser completamente diferente!\n\n√â a√≠ que entra a **CORRELA√á√ÉO** pra salvar o dia! ü¶∏‚Äç‚ôÇÔ∏è\n\n### üßÆ A F√≥rmula da Correla√ß√£o de Pearson\n\n$$r = \\frac{Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n\n**Traduzindo**: A correla√ß√£o √© a covari√¢ncia dividida pelo produto dos desvios padr√£o das duas vari√°veis.\n\n### üé≠ Interpreta√ß√£o da Correla√ß√£o:\n- **r = 1**: Correla√ß√£o perfeita positiva (linha reta crescente)\n- **r = -1**: Correla√ß√£o perfeita negativa (linha reta decrescente)\n- **r = 0**: Sem correla√ß√£o linear\n- **0.7 ‚â§ |r| < 1**: Correla√ß√£o forte\n- **0.3 ‚â§ |r| < 0.7**: Correla√ß√£o moderada\n- **0 < |r| < 0.3**: Correla√ß√£o fraca\n\n**Dica do Pedro**: A correla√ß√£o sempre fica entre -1 e 1. √â como uma nota! Muito mais f√°cil de interpretar que a covari√¢ncia! üìä"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a correla√ß√£o na m√£o\n",
        "def calcular_correlacao_manual(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a correla√ß√£o de Pearson na m√£o\n",
        "    \"\"\"\n",
        "    # J√° temos a covari√¢ncia\n",
        "    covariancia = np.cov(x, y)[0, 1]\n",
        "    \n",
        "    # Calculando os desvios padr√£o\n",
        "    desvio_x = np.std(x, ddof=1)  # ddof=1 para desvio amostral\n",
        "    desvio_y = np.std(y, ddof=1)\n",
        "    \n",
        "    # Correla√ß√£o\n",
        "    correlacao = covariancia / (desvio_x * desvio_y)\n",
        "    \n",
        "    return correlacao, covariancia, desvio_x, desvio_y\n",
        "\n",
        "# Calculando para nossos dados\n",
        "corr_manual, cov, std_h, std_n = calcular_correlacao_manual(horas_estudo, notas)\n",
        "\n",
        "print(\"üîç Processo de c√°lculo da correla√ß√£o:\")\n",
        "print(f\"Covari√¢ncia: {cov:.4f}\")\n",
        "print(f\"Desvio padr√£o das horas: {std_h:.4f}\")\n",
        "print(f\"Desvio padr√£o das notas: {std_n:.4f}\")\n",
        "print(f\"\\nüìà Correla√ß√£o calculada na m√£o: {corr_manual:.4f}\")\n",
        "\n",
        "# Comparando com m√©todos prontos\n",
        "corr_numpy = np.corrcoef(horas_estudo, notas)[0, 1]\n",
        "corr_scipy = stats.pearsonr(horas_estudo, notas)[0]\n",
        "\n",
        "print(f\"üìà Correla√ß√£o pelo NumPy: {corr_numpy:.4f}\")\n",
        "print(f\"üìà Correla√ß√£o pelo SciPy: {corr_scipy:.4f}\")\n",
        "\n",
        "# Interpreta√ß√£o\n",
        "print(f\"\\nüéØ Interpreta√ß√£o:\")\n",
        "if corr_manual >= 0.7:\n",
        "    print(f\"Correla√ß√£o FORTE e POSITIVA! As vari√°veis andam muito juntas! üí™\")\n",
        "elif corr_manual >= 0.3:\n",
        "    print(f\"Correla√ß√£o MODERADA e POSITIVA! Tem uma rela√ß√£o boa a√≠! üëç\")\n",
        "else:\n",
        "    print(f\"Correla√ß√£o FRACA... As vari√°veis n√£o conversam muito... üòê\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando Correla√ß√µes: O Poder dos Gr√°ficos\n\nUma imagem vale mais que mil palavras, n√©? Vamos ver como diferentes correla√ß√µes aparecem visualmente!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-05_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando diferentes tipos de correla√ß√£o para visualizar\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "x = np.random.randn(n)\n",
        "\n",
        "# Diferentes tipos de correla√ß√£o\n",
        "y_forte_pos = 2 * x + 0.5 * np.random.randn(n)      # Correla√ß√£o forte positiva\n",
        "y_forte_neg = -2 * x + 0.5 * np.random.randn(n)     # Correla√ß√£o forte negativa  \n",
        "y_moderada = 0.8 * x + 1.5 * np.random.randn(n)     # Correla√ß√£o moderada\n",
        "y_sem_corr = np.random.randn(n)                      # Sem correla√ß√£o\n",
        "\n",
        "# Calculando as correla√ß√µes\n",
        "corr_forte_pos = np.corrcoef(x, y_forte_pos)[0, 1]\n",
        "corr_forte_neg = np.corrcoef(x, y_forte_neg)[0, 1]\n",
        "corr_moderada = np.corrcoef(x, y_moderada)[0, 1]\n",
        "corr_sem = np.corrcoef(x, y_sem_corr)[0, 1]\n",
        "\n",
        "# Criando o gr√°fico\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('üéØ Diferentes Tipos de Correla√ß√£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Forte positiva\n",
        "axes[0,0].scatter(x, y_forte_pos, alpha=0.6, color='green')\n",
        "axes[0,0].plot(np.sort(x), np.poly1d(np.polyfit(x, y_forte_pos, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[0,0].set_title(f'Correla√ß√£o Forte Positiva\\nr = {corr_forte_pos:.3f}')\n",
        "axes[0,0].set_xlabel('X')\n",
        "axes[0,0].set_ylabel('Y')\n",
        "\n",
        "# Forte negativa\n",
        "axes[0,1].scatter(x, y_forte_neg, alpha=0.6, color='red')\n",
        "axes[0,1].plot(np.sort(x), np.poly1d(np.polyfit(x, y_forte_neg, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[0,1].set_title(f'Correla√ß√£o Forte Negativa\\nr = {corr_forte_neg:.3f}')\n",
        "axes[0,1].set_xlabel('X')\n",
        "axes[0,1].set_ylabel('Y')\n",
        "\n",
        "# Moderada\n",
        "axes[1,0].scatter(x, y_moderada, alpha=0.6, color='orange')\n",
        "axes[1,0].plot(np.sort(x), np.poly1d(np.polyfit(x, y_moderada, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[1,0].set_title(f'Correla√ß√£o Moderada\\nr = {corr_moderada:.3f}')\n",
        "axes[1,0].set_xlabel('X')\n",
        "axes[1,0].set_ylabel('Y')\n",
        "\n",
        "# Sem correla√ß√£o\n",
        "axes[1,1].scatter(x, y_sem_corr, alpha=0.6, color='gray')\n",
        "axes[1,1].plot(np.sort(x), np.poly1d(np.polyfit(x, y_sem_corr, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[1,1].set_title(f'Sem Correla√ß√£o\\nr = {corr_sem:.3f}')\n",
        "axes[1,1].set_xlabel('X')\n",
        "axes[1,1].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Repara como a linha vermelha (tend√™ncia) muda conforme a correla√ß√£o!\")\n",
        "print(\"üí° Quanto mais pr√≥ximo de 1 ou -1, mais os pontos ficam perto da linha!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Matriz de Correla√ß√£o: Analisando M√∫ltiplas Vari√°veis\n\nNa vida real, raramente temos s√≥ duas vari√°veis. Normalmente temos um monte delas! \n\n√â a√≠ que entra a **Matriz de Correla√ß√£o** - uma tabela que mostra a correla√ß√£o entre TODAS as combina√ß√µes de vari√°veis.\n\n### üßÆ Estrutura da Matriz\n\nPara vari√°veis X, Y, Z, a matriz fica assim:\n\n$$\\begin{pmatrix}\n1 & r_{XY} & r_{XZ} \\\\\nr_{YX} & 1 & r_{YZ} \\\\\nr_{ZX} & r_{ZY} & 1\n\\end{pmatrix}$$\n\n**Caracter√≠sticas importantes:**\n- A diagonal sempre √© 1 (correla√ß√£o de uma vari√°vel com ela mesma)\n- A matriz √© sim√©trica (r_XY = r_YX)\n- Os valores v√£o de -1 a 1\n\n**Dica do Pedro**: A matriz de correla√ß√£o √© uma das ferramentas mais poderosas pra entender seus dados! Use e abuse! üî•"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando um dataset mais interessante pra analisar\n",
        "# Vamos simular dados de vendas de uma loja\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "\n",
        "# Criando vari√°veis relacionadas\n",
        "temperatura = np.random.normal(25, 5, n)  # Temperatura m√©dia 25¬∞C\n",
        "vendas_sorvete = 10 + 2 * temperatura + np.random.normal(0, 10, n)  # Positivamente correlacionado\n",
        "vendas_chocolate_quente = 100 - 1.5 * temperatura + np.random.normal(0, 8, n)  # Negativamente correlacionado\n",
        "vendas_agua = 5 + 1.5 * temperatura + np.random.normal(0, 5, n)  # Positivamente correlacionado\n",
        "vendas_aleatorio = np.random.normal(50, 15, n)  # Sem correla√ß√£o com temperatura\n",
        "\n",
        "# Criando o DataFrame\n",
        "df_vendas = pd.DataFrame({\n",
        "    'Temperatura': temperatura,\n",
        "    'Vendas_Sorvete': vendas_sorvete,\n",
        "    'Vendas_Chocolate_Quente': vendas_chocolate_quente,\n",
        "    'Vendas_Agua': vendas_agua,\n",
        "    'Vendas_Aleatorio': vendas_aleatorio\n",
        "})\n",
        "\n",
        "print(\"üè™ Dataset de Vendas criado!\")\n",
        "print(f\"Shape: {df_vendas.shape}\")\n",
        "print(\"\\nüìä Primeiras 5 linhas:\")\n",
        "print(df_vendas.head())\n",
        "\n",
        "print(\"\\nüìà Estat√≠sticas b√°sicas:\")\n",
        "print(df_vendas.describe())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a matriz de correla√ß√£o\n",
        "matriz_corr = df_vendas.corr()\n",
        "\n",
        "print(\"üîÑ Matriz de Correla√ß√£o:\")\n",
        "print(matriz_corr.round(3))\n",
        "\n",
        "# Visualizando com heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "heatmap = sns.heatmap(matriz_corr, \n",
        "                     annot=True,  # Mostra os valores\n",
        "                     cmap='RdBu_r',  # Colormap: vermelho para negativo, azul para positivo\n",
        "                     center=0,  # Centro em zero\n",
        "                     square=True,  # C√©lulas quadradas\n",
        "                     fmt='.3f',  # Formato dos n√∫meros\n",
        "                     cbar_kws={'label': 'Correla√ß√£o'})\n",
        "\n",
        "plt.title('üî• Heatmap da Matriz de Correla√ß√£o - Vendas vs Temperatura', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretando os resultados\n",
        "print(\"\\nüéØ Interpreta√ß√µes:\")\n",
        "temp_sorvete = matriz_corr.loc['Temperatura', 'Vendas_Sorvete']\n",
        "temp_chocolate = matriz_corr.loc['Temperatura', 'Vendas_Chocolate_Quente']\n",
        "temp_agua = matriz_corr.loc['Temperatura', 'Vendas_Agua']\n",
        "temp_aleatorio = matriz_corr.loc['Temperatura', 'Vendas_Aleatorio']\n",
        "\n",
        "print(f\"üç¶ Temperatura x Sorvete: {temp_sorvete:.3f} - Correla√ß√£o {'FORTE' if abs(temp_sorvete) > 0.7 else 'MODERADA' if abs(temp_sorvete) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_sorvete > 0 else 'NEGATIVA'}\")\n",
        "print(f\"‚òï Temperatura x Chocolate: {temp_chocolate:.3f} - Correla√ß√£o {'FORTE' if abs(temp_chocolate) > 0.7 else 'MODERADA' if abs(temp_chocolate) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_chocolate > 0 else 'NEGATIVA'}\")\n",
        "print(f\"üíß Temperatura x √Ågua: {temp_agua:.3f} - Correla√ß√£o {'FORTE' if abs(temp_agua) > 0.7 else 'MODERADA' if abs(temp_agua) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_agua > 0 else 'NEGATIVA'}\")\n",
        "print(f\"üé≤ Temperatura x Aleat√≥rio: {temp_aleatorio:.3f} - Correla√ß√£o {'FORTE' if abs(temp_aleatorio) > 0.7 else 'MODERADA' if abs(temp_aleatorio) > 0.3 else 'FRACA'}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Armadilhas da Correla√ß√£o: Cuidados Importantes!\n\nAntes de sair por a√≠ tirando conclus√µes, vamos falar dos **PERIGOS** da correla√ß√£o:\n\n### üö® 1. Correla√ß√£o ‚â† Causalidade\n**O erro mais comum!** S√≥ porque duas coisas andam juntas, n√£o significa que uma causa a outra.\n\n**Exemplo cl√°ssico**: Consumo de sorvete e afogamentos t√™m correla√ß√£o positiva. Ser√° que sorvete causa afogamento? üòÇ Claro que n√£o! A causa comum √© o CALOR!\n\n### üö® 2. Correla√ß√£o Esp√∫ria\nDuas vari√°veis podem estar correlacionadas por puro acaso ou por uma terceira vari√°vel.\n\n### üö® 3. Rela√ß√µes N√£o-Lineares\nA correla√ß√£o de Pearson s√≥ mede rela√ß√µes **lineares**. Pode existir uma rela√ß√£o forte, mas n√£o linear!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-05_img_02.png)\n\n**Dica do Pedro**: Sempre olhe o gr√°fico! N√∫meros sozinhos podem mentir! üëÄ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrando armadilhas da correla√ß√£o\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# 1. Rela√ß√£o n√£o-linear (par√°bola)\n",
        "x_nonlinear = np.linspace(-3, 3, n)\n",
        "y_nonlinear = x_nonlinear**2 + 0.5 * np.random.randn(n)\n",
        "\n",
        "# 2. Outliers que afetam a correla√ß√£o\n",
        "x_outlier = np.random.randn(n)\n",
        "y_outlier = 0.3 * x_outlier + 0.5 * np.random.randn(n)\n",
        "# Adicionando alguns outliers\n",
        "x_outlier[-5:] = [4, 5, 6, 7, 8]\n",
        "y_outlier[-5:] = [4, 5, 6, 7, 8]\n",
        "\n",
        "# 3. Correla√ß√£o esp√∫ria (por acaso)\n",
        "anos = np.arange(2000, 2020)\n",
        "vendas_margarina = 500 + 2 * anos + 5 * np.random.randn(20)  # Crescendo com o tempo\n",
        "divorcios = 800 + 1.5 * anos + 8 * np.random.randn(20)      # Tamb√©m crescendo com o tempo\n",
        "\n",
        "# Calculando correla√ß√µes\n",
        "corr_nonlinear = np.corrcoef(x_nonlinear, y_nonlinear)[0, 1]\n",
        "corr_outlier = np.corrcoef(x_outlier, y_outlier)[0, 1]\n",
        "corr_spurious = np.corrcoef(vendas_margarina, divorcios)[0, 1]\n",
        "\n",
        "# Plotando\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('‚ö†Ô∏è Armadilhas da Correla√ß√£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Rela√ß√£o n√£o-linear\n",
        "axes[0,0].scatter(x_nonlinear, y_nonlinear, alpha=0.6)\n",
        "axes[0,0].set_title(f'Rela√ß√£o N√£o-Linear\\nCorrela√ß√£o Linear: {corr_nonlinear:.3f}\\n(Mas v√™ como a rela√ß√£o √© forte!)')\n",
        "axes[0,0].set_xlabel('X')\n",
        "axes[0,0].set_ylabel('Y')\n",
        "\n",
        "# Outliers\n",
        "colors = ['blue'] * (n-5) + ['red'] * 5\n",
        "axes[0,1].scatter(x_outlier, y_outlier, c=colors, alpha=0.6)\n",
        "axes[0,1].set_title(f'Efeito dos Outliers\\nCorrela√ß√£o: {corr_outlier:.3f}\\n(Pontos vermelhos = outliers)')\n",
        "axes[0,1].set_xlabel('X')\n",
        "axes[0,1].set_ylabel('Y')\n",
        "\n",
        "# Correla√ß√£o esp√∫ria\n",
        "axes[1,0].scatter(vendas_margarina, divorcios, alpha=0.6, color='purple')\n",
        "axes[1,0].set_title(f'Correla√ß√£o Esp√∫ria\\nr = {corr_spurious:.3f}\\n(Ser√° que margarina causa div√≥rcio? üòÇ)')\n",
        "axes[1,0].set_xlabel('Vendas de Margarina')\n",
        "axes[1,0].set_ylabel('N√∫mero de Div√≥rcios')\n",
        "\n",
        "# Exemplo de dados sem padr√£o (ru√≠do)\n",
        "x_noise = np.random.randn(n)\n",
        "y_noise = np.random.randn(n)\n",
        "corr_noise = np.corrcoef(x_noise, y_noise)[0, 1]\n",
        "axes[1,1].scatter(x_noise, y_noise, alpha=0.6, color='gray')\n",
        "axes[1,1].set_title(f'Ru√≠do Puro\\nr = {corr_noise:.3f}\\n(Sem padr√£o real)')\n",
        "axes[1,1].set_xlabel('X')\n",
        "axes[1,1].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üö® Li√ß√µes importantes:\")\n",
        "print(f\"1. Rela√ß√£o n√£o-linear pode ter correla√ß√£o baixa ({corr_nonlinear:.3f}), mas v√™ o gr√°fico!\")\n",
        "print(f\"2. Outliers podem inflar a correla√ß√£o artificialmente ({corr_outlier:.3f})\")\n",
        "print(f\"3. Correla√ß√£o alta ({corr_spurious:.3f}) n√£o significa causalidade!\")\n",
        "print(f\"4. Ru√≠do puro ainda pode ter correla√ß√£o n√£o-zero ({corr_noise:.3f}) por acaso!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Tipos de Correla√ß√£o: Al√©m da Pearson\n\nA correla√ß√£o de Pearson √© a mais famosa, mas n√£o √© a √∫nica! Dependendo dos seus dados, outras podem ser mais apropriadas:\n\n### üìä Tipos Principais:\n\n1. **Pearson** (que j√° vimos): Para dados **num√©ricos** com rela√ß√£o **linear**\n2. **Spearman**: Para dados **ordinais** ou rela√ß√µes **monot√¥nicas** (n√£o necessariamente lineares)\n3. **Kendall**: Similar ao Spearman, mas mais robusta para amostras pequenas\n\n### üßÆ Correla√ß√£o de Spearman\n\n$$r_s = 1 - \\frac{6\\sum d_i^2}{n(n^2-1)}$$\n\nOnde $d_i$ √© a diferen√ßa entre os ranks de cada observa√ß√£o.\n\n**Quando usar**: Dados ordinais, distribui√ß√µes n√£o-normais, rela√ß√µes monot√¥nicas.\n\n**Dica do Pedro**: Se seus dados n√£o s√£o \"bem comportados\" (muito assim√©tricos, com outliers), use Spearman! √â mais robusta! üí™"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comparando diferentes tipos de correla√ß√£o\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "\n",
        "# Criando dados com diferentes caracter√≠sticas\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# 1. Dados normais (Pearson funciona bem)\n",
        "x_normal = np.random.randn(n)\n",
        "y_normal = 2 * x_normal + np.random.randn(n)\n",
        "\n",
        "# 2. Dados com outliers\n",
        "x_outlier = np.random.randn(n)\n",
        "y_outlier = 2 * x_outlier + np.random.randn(n)\n",
        "# Adicionando outliers extremos\n",
        "x_outlier[-3:] = [10, 15, 20]\n",
        "y_outlier[-3:] = [-10, -15, -20]\n",
        "\n",
        "# 3. Rela√ß√£o monot√¥nica n√£o-linear\n",
        "x_mono = np.random.randn(n)\n",
        "y_mono = np.sign(x_mono) * (x_mono**2) + 0.5 * np.random.randn(n)\n",
        "\n",
        "# Fun√ß√£o para calcular todas as correla√ß√µes\n",
        "def comparar_correlacoes(x, y, nome):\n",
        "    pearson = np.corrcoef(x, y)[0, 1]\n",
        "    spearman, _ = spearmanr(x, y)\n",
        "    kendall, _ = kendalltau(x, y)\n",
        "    \n",
        "    print(f\"\\nüìä {nome}:\")\n",
        "    print(f\"  Pearson:  {pearson:.4f}\")\n",
        "    print(f\"  Spearman: {spearman:.4f}\")\n",
        "    print(f\"  Kendall:  {kendall:.4f}\")\n",
        "    \n",
        "    return pearson, spearman, kendall\n",
        "\n",
        "# Comparando\n",
        "print(\"üîç Compara√ß√£o dos M√©todos de Correla√ß√£o:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "p1, s1, k1 = comparar_correlacoes(x_normal, y_normal, \"Dados Normais\")\n",
        "p2, s2, k2 = comparar_correlacoes(x_outlier, y_outlier, \"Com Outliers\")\n",
        "p3, s3, k3 = comparar_correlacoes(x_mono, y_mono, \"Rela√ß√£o Monot√¥nica\")\n",
        "\n",
        "# Visualizando\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('üîÑ Compara√ß√£o dos M√©todos de Correla√ß√£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Dados normais\n",
        "axes[0].scatter(x_normal, y_normal, alpha=0.6, color='blue')\n",
        "axes[0].set_title(f'Dados Normais\\nPearson: {p1:.3f} | Spearman: {s1:.3f}')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "\n",
        "# Com outliers\n",
        "colors = ['blue'] * (n-3) + ['red'] * 3\n",
        "axes[1].scatter(x_outlier, y_outlier, c=colors, alpha=0.6)\n",
        "axes[1].set_title(f'Com Outliers\\nPearson: {p2:.3f} | Spearman: {s2:.3f}')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "\n",
        "# Monot√¥nica\n",
        "axes[2].scatter(x_mono, y_mono, alpha=0.6, color='green')\n",
        "axes[2].set_title(f'Rela√ß√£o Monot√¥nica\\nPearson: {p3:.3f} | Spearman: {s3:.3f}')\n",
        "axes[2].set_xlabel('X')\n",
        "axes[2].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Conclus√µes:\")\n",
        "print(\"‚Ä¢ Para dados normais: todos os m√©todos funcionam bem\")\n",
        "print(\"‚Ä¢ Com outliers: Spearman √© mais robusta que Pearson\")\n",
        "print(\"‚Ä¢ Para rela√ß√µes monot√¥nicas: Spearman captura melhor que Pearson\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Aplica√ß√£o Pr√°tica: An√°lise de Dataset Real\n\nBora colocar a m√£o na massa com um exemplo mais realista! Vamos analisar um dataset de vendas de uma empresa.\n\n### üíº Cen√°rio:\nUma empresa quer entender quais fatores mais influenciam suas vendas:\n- Gastos com marketing\n- Temperatura m√©dia do m√™s\n- N√∫mero de funcion√°rios\n- Pre√ßo m√©dio dos produtos\n- Satisfa√ß√£o do cliente\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-05_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando um dataset realista de vendas\n",
        "np.random.seed(42)\n",
        "n_meses = 120  # 10 anos de dados mensais\n",
        "\n",
        "# Vari√°veis independentes (com alguma correla√ß√£o natural entre elas)\n",
        "marketing = np.random.exponential(5000, n_meses)  # Gastos com marketing (distribui√ß√£o exponencial)\n",
        "temperatura = 15 + 10 * np.sin(np.arange(n_meses) * 2 * np.pi / 12) + np.random.normal(0, 2, n_meses)  # Sazonal\n",
        "funcionarios = 20 + 0.1 * np.arange(n_meses) + np.random.normal(0, 2, n_meses)  # Crescimento ao longo do tempo\n",
        "preco_medio = 100 + np.random.normal(0, 10, n_meses)  # Pre√ßo relativamente est√°vel\n",
        "satisfacao = 3 + 2 * np.random.beta(2, 1, n_meses)  # Satisfa√ß√£o de 3 a 5\n",
        "\n",
        "# Vendas como fun√ß√£o das outras vari√°veis (com ru√≠do)\n",
        "vendas = (0.8 * marketing + \n",
        "          500 * temperatura + \n",
        "          200 * funcionarios + \n",
        "          -30 * preco_medio +  # Pre√ßo alto diminui vendas\n",
        "          2000 * satisfacao +\n",
        "          np.random.normal(0, 5000, n_meses))  # Ru√≠do\n",
        "\n",
        "# Garantindo valores positivos para vendas\n",
        "vendas = np.maximum(vendas, 1000)\n",
        "\n",
        "# Criando DataFrame\n",
        "df_empresa = pd.DataFrame({\n",
        "    'Vendas': vendas,\n",
        "    'Marketing': marketing,\n",
        "    'Temperatura': temperatura,\n",
        "    'Funcionarios': funcionarios,\n",
        "    'Preco_Medio': preco_medio,\n",
        "    'Satisfacao': satisfacao\n",
        "})\n",
        "\n",
        "print(\"üè™ Dataset da Empresa criado!\")\n",
        "print(f\"üìä Shape: {df_empresa.shape}\")\n",
        "print(f\"üìÖ Per√≠odo: {n_meses} meses ({n_meses//12} anos)\")\n",
        "\n",
        "print(\"\\nüìà Estat√≠sticas Descritivas:\")\n",
        "print(df_empresa.describe().round(2))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# An√°lise completa de correla√ß√£o\n",
        "print(\"üîç AN√ÅLISE DE CORRELA√á√ÉO - EMPRESA XYZ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Matriz de correla√ß√£o\n",
        "corr_matrix = df_empresa.corr()\n",
        "print(\"\\nüìä Matriz de Correla√ß√£o:\")\n",
        "print(corr_matrix.round(3))\n",
        "\n",
        "# Heatmap mais detalhado\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # M√°scara para mostrar s√≥ metade\n",
        "\n",
        "heatmap = sns.heatmap(corr_matrix, \n",
        "                     mask=mask,\n",
        "                     annot=True, \n",
        "                     cmap='RdBu_r', \n",
        "                     center=0,\n",
        "                     square=True, \n",
        "                     fmt='.3f',\n",
        "                     cbar_kws={'label': 'Correla√ß√£o'},\n",
        "                     linewidths=0.5)\n",
        "\n",
        "plt.title('üî• Matriz de Correla√ß√£o - Empresa XYZ\\n(An√°lise de Fatores que Influenciam Vendas)', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# An√°lise espec√≠fica das correla√ß√µes com vendas\n",
        "correlacoes_vendas = corr_matrix['Vendas'].drop('Vendas').sort_values(key=abs, ascending=False)\n",
        "\n",
        "print(\"\\nüéØ CORRELA√á√ïES COM VENDAS (ordenadas por for√ßa):\")\n",
        "print(\"-\" * 50)\n",
        "for variavel, corr in correlacoes_vendas.items():\n",
        "    forca = \"FORTE\" if abs(corr) > 0.7 else \"MODERADA\" if abs(corr) > 0.3 else \"FRACA\"\n",
        "    direcao = \"POSITIVA\" if corr > 0 else \"NEGATIVA\"\n",
        "    emoji = \"üìà\" if corr > 0 else \"üìâ\"\n",
        "    print(f\"{emoji} {variavel:12}: {corr:+.3f} - {forca} {direcao}\")\n",
        "\n",
        "# Insights de neg√≥cio\n",
        "print(\"\\nüíº INSIGHTS DE NEG√ìCIO:\")\n",
        "print(\"-\" * 30)\n",
        "maior_corr = correlacoes_vendas.abs().idxmax()\n",
        "maior_valor = correlacoes_vendas[maior_corr]\n",
        "print(f\"‚Ä¢ A vari√°vel que MAIS influencia vendas: {maior_corr} (r = {maior_valor:+.3f})\")\n",
        "\n",
        "menor_corr = correlacoes_vendas.abs().idxmin()\n",
        "menor_valor = correlacoes_vendas[menor_corr]\n",
        "print(f\"‚Ä¢ A vari√°vel que MENOS influencia vendas: {menor_corr} (r = {menor_valor:+.3f})\")\n",
        "\n",
        "# Recomenda√ß√µes\n",
        "print(\"\\nüöÄ RECOMENDA√á√ïES:\")\n",
        "print(\"-\" * 20)\n",
        "if correlacoes_vendas['Marketing'] > 0.5:\n",
        "    print(\"‚Ä¢ ‚úÖ Investir mais em marketing pode aumentar vendas significativamente!\")\n",
        "if correlacoes_vendas['Satisfacao'] > 0.3:\n",
        "    print(\"‚Ä¢ ‚úÖ Melhorar satisfa√ß√£o do cliente √© fundamental!\")\n",
        "if correlacoes_vendas['Preco_Medio'] < -0.3:\n",
        "    print(\"‚Ä¢ ‚ö†Ô∏è  Cuidado com pre√ßos muito altos - podem reduzir vendas!\")\n",
        "if abs(correlacoes_vendas['Funcionarios']) > 0.4:\n",
        "    print(\"‚Ä¢ üë• N√∫mero de funcion√°rios tem impacto nas vendas - considerar otimiza√ß√£o!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 1: An√°lise de Correla√ß√£o\n\nAgora √© sua vez! Vou te dar um dataset e voc√™ vai fazer uma an√°lise completa de correla√ß√£o.\n\n### üéØ Desafio: An√°lise de Notas de Estudantes\n\nVoc√™ recebeu dados de 500 estudantes com as seguintes vari√°veis:\n- **Horas_Estudo**: Horas semanais de estudo\n- **Horas_TV**: Horas semanais assistindo TV\n- **Horas_Sono**: Horas di√°rias de sono\n- **Nota_Final**: Nota final do semestre (0-10)\n- **Faltas**: N√∫mero de faltas no semestre\n\n### üìù Tarefas:\n1. Calcule a matriz de correla√ß√£o\n2. Crie um heatmap\n3. Identifique as 3 correla√ß√µes mais fortes com a Nota_Final\n4. Fa√ßa recomenda√ß√µes para os estudantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EXERC√çCIO 1: Dataset de estudantes\n",
        "# Vou criar o dataset - voc√™ faz a an√°lise!\n",
        "\n",
        "np.random.seed(123)\n",
        "n_estudantes = 500\n",
        "\n",
        "# Criando vari√°veis realistas\n",
        "horas_estudo = np.random.gamma(2, 2, n_estudantes)  # M√©dia ~4h, assim√©trica\n",
        "horas_tv = np.random.exponential(3, n_estudantes)   # M√©dia 3h, alguns assistem muito\n",
        "horas_sono = np.random.normal(7, 1.5, n_estudantes)  # M√©dia 7h, normal\n",
        "horas_sono = np.clip(horas_sono, 4, 12)  # Limitando valores realistas\n",
        "\n",
        "# Faltas correlacionadas negativamente com estudo\n",
        "faltas = np.random.poisson(3, n_estudantes) + np.random.poisson(np.maximum(5 - horas_estudo/2, 0))\n",
        "\n",
        "# Nota final como fun√ß√£o das outras vari√°veis\n",
        "nota_final = (2 + \n",
        "              0.8 * horas_estudo +      # Mais estudo = nota maior\n",
        "              -0.2 * horas_tv +         # Mais TV = nota menor\n",
        "              0.3 * horas_sono +        # Sono adequado ajuda\n",
        "              -0.15 * faltas +          # Faltas prejudicam\n",
        "              np.random.normal(0, 1, n_estudantes))  # Ru√≠do\n",
        "\n",
        "# Limitando nota entre 0 e 10\n",
        "nota_final = np.clip(nota_final, 0, 10)\n",
        "\n",
        "# Criando DataFrame\n",
        "df_estudantes = pd.DataFrame({\n",
        "    'Horas_Estudo': horas_estudo,\n",
        "    'Horas_TV': horas_tv,\n",
        "    'Horas_Sono': horas_sono,\n",
        "    'Nota_Final': nota_final,\n",
        "    'Faltas': faltas\n",
        "})\n",
        "\n",
        "print(\"üìö Dataset de Estudantes criado!\")\n",
        "print(f\"üë• {n_estudantes} estudantes\")\n",
        "print(\"\\nüìä Primeiras 5 linhas:\")\n",
        "print(df_estudantes.head())\n",
        "print(\"\\nüìà Estat√≠sticas:\")\n",
        "print(df_estudantes.describe().round(2))\n",
        "\n",
        "print(\"\\nüéØ AGORA √â SUA VEZ!\")\n",
        "print(\"Fa√ßa a an√°lise de correla√ß√£o completa:\")\n",
        "print(\"1. Calcule a matriz de correla√ß√£o\")\n",
        "print(\"2. Crie um heatmap\")\n",
        "print(\"3. Analise as correla√ß√µes com Nota_Final\")\n",
        "print(\"4. D√™ recomenda√ß√µes para os estudantes\")\n",
        "print(\"\\nüí™ Bora l√°!\")\n",
        "\n",
        "# SEU C√ìDIGO AQUI:\n",
        "# matriz_corr_estudantes = ...\n",
        "# ..."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Conex√£o com Regress√£o Linear (M√≥dulo 4)\n\nLembra da regress√£o linear que vimos no m√≥dulo anterior? A correla√ß√£o est√° **DIRETAMENTE** ligada a ela!\n\n### üßÆ A Matem√°tica da Conex√£o\n\nPara regress√£o simples $y = a + bx$, o coeficiente angular $b$ √©:\n\n$$b = r \\cdot \\frac{\\sigma_y}{\\sigma_x}$$\n\nE o $R^2$ (coeficiente de determina√ß√£o) √©:\n\n$$R^2 = r^2$$\n\n**Traduzindo**: \n- A **correla√ß√£o** te diz a DIRE√á√ÉO e FOR√áA da rela√ß√£o\n- A **regress√£o** te d√° a EQUA√á√ÉO para fazer previs√µes\n- O **R¬≤** te diz quanto da varia√ß√£o √© explicada pelo modelo\n\n**Dica do Pedro**: Correla√ß√£o e regress√£o s√£o irm√£s! Uma ajuda a entender a outra! üëØ‚Äç‚ôÄÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrando a conex√£o entre correla√ß√£o e regress√£o\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Usando nossos dados de horas de estudo vs notas\n",
        "x = horas_estudo.reshape(-1, 1)  # sklearn precisa de 2D\n",
        "y = nota_final\n",
        "\n",
        "# Calculando correla√ß√£o\n",
        "correlacao = np.corrcoef(horas_estudo, nota_final)[0, 1]\n",
        "\n",
        "# Fazendo regress√£o linear\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(x, y)\n",
        "y_pred = modelo.predict(x)\n",
        "\n",
        "# Calculando R¬≤\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Coeficientes\n",
        "coef_angular = modelo.coef_[0]\n",
        "intercepto = modelo.intercept_\n",
        "\n",
        "print(\"üîó CONEX√ÉO: CORRELA√á√ÉO ‚Üî REGRESS√ÉO\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Correla√ß√£o (r): {correlacao:.4f}\")\n",
        "print(f\"üìà R¬≤ da regress√£o: {r2:.4f}\")\n",
        "print(f\"üéØ r¬≤ = {correlacao**2:.4f}\")\n",
        "print(f\"‚úÖ Diferen√ßa r¬≤ vs R¬≤: {abs(correlacao**2 - r2):.10f}\")\n",
        "\n",
        "print(f\"\\nüìê Equa√ß√£o da reta: y = {intercepto:.3f} + {coef_angular:.3f}x\")\n",
        "print(f\"üìä Desvio padr√£o X: {np.std(horas_estudo, ddof=1):.3f}\")\n",
        "print(f\"üìä Desvio padr√£o Y: {np.std(nota_final, ddof=1):.3f}\")\n",
        "print(f\"üßÆ b te√≥rico: r * (œÉy/œÉx) = {correlacao * np.std(nota_final, ddof=1) / np.std(horas_estudo, ddof=1):.3f}\")\n",
        "\n",
        "# Visualizando\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(horas_estudo, nota_final, alpha=0.5, color='blue', label='Dados')\n",
        "\n",
        "# Linha de regress√£o\n",
        "x_linha = np.linspace(horas_estudo.min(), horas_estudo.max(), 100)\n",
        "y_linha = intercepto + coef_angular * x_linha\n",
        "plt.plot(x_linha, y_linha, 'r-', linewidth=2, label=f'Regress√£o: y = {intercepto:.2f} + {coef_angular:.2f}x')\n",
        "\n",
        "plt.xlabel('Horas de Estudo por Semana')\n",
        "plt.ylabel('Nota Final')\n",
        "plt.title(f'üîó Correla√ß√£o vs Regress√£o\\nr = {correlacao:.3f} | R¬≤ = {r2:.3f}', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionando texto explicativo\n",
        "plt.text(0.05, 0.95, f'üí° R¬≤ = r¬≤ = {correlacao:.3f}¬≤ = {r2:.3f}', \n",
        "         transform=plt.gca().transAxes, fontsize=12, \n",
        "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
        "print(f\"‚Ä¢ A correla√ß√£o r = {correlacao:.3f} indica rela√ß√£o {'forte' if abs(correlacao) > 0.7 else 'moderada' if abs(correlacao) > 0.3 else 'fraca'}\")\n",
        "print(f\"‚Ä¢ O R¬≤ = {r2:.3f} significa que {r2*100:.1f}% da varia√ß√£o nas notas √© explicada pelas horas de estudo\")\n",
        "print(f\"‚Ä¢ Para cada hora extra de estudo, a nota aumenta {coef_angular:.3f} pontos em m√©dia\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 2: Implementa√ß√£o do Zero\n\nAgora o desafio HARDCORE! Vou te dar apenas os dados, e voc√™ vai implementar TUDO do zero:\n\n### üèóÔ∏è Desafio: Implemente suas pr√≥prias fun√ß√µes\n\n**Crie as seguintes fun√ß√µes:**\n1. `minha_covariancia(x, y)` - Calcula covari√¢ncia do zero\n2. `minha_correlacao(x, y)` - Calcula correla√ß√£o do zero\n3. `matriz_correlacao_completa(dataframe)` - Matriz de correla√ß√£o completa\n4. `interpretar_correlacao(r)` - Retorna interpreta√ß√£o textual\n\n### üìä Teste com dados reais\nUse o dataset que vou fornecer e compare seus resultados com o NumPy/SciPy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EXERC√çCIO 2: Implementa√ß√£o do Zero\n",
        "# Vou dar os dados, voc√™ implementa as fun√ß√µes!\n",
        "\n",
        "# Dataset de teste\n",
        "np.random.seed(777)\n",
        "n = 50\n",
        "dados_teste = pd.DataFrame({\n",
        "    'A': np.random.normal(10, 2, n),\n",
        "    'B': np.random.normal(5, 1, n),\n",
        "    'C': np.random.exponential(2, n),\n",
        "    'D': np.random.uniform(0, 10, n)\n",
        "})\n",
        "\n",
        "# Criando algumas correla√ß√µes artificiais\n",
        "dados_teste['B'] = dados_teste['A'] * 0.7 + np.random.normal(0, 0.5, n)  # Correla√ß√£o forte com A\n",
        "dados_teste['C'] = dados_teste['A'] * -0.4 + np.random.normal(5, 1, n)   # Correla√ß√£o negativa com A\n",
        "\n",
        "print(\"üéØ EXERC√çCIO 2: IMPLEMENTA√á√ÉO DO ZERO\")\n",
        "print(\"=\" * 50)\n",
        "print(\"üìä Dataset de teste criado!\")\n",
        "print(dados_teste.head())\n",
        "\n",
        "print(\"\\nüèóÔ∏è SUAS TAREFAS:\")\n",
        "print(\"1. Implemente minha_covariancia(x, y)\")\n",
        "print(\"2. Implemente minha_correlacao(x, y)\")\n",
        "print(\"3. Implemente matriz_correlacao_completa(df)\")\n",
        "print(\"4. Implemente interpretar_correlacao(r)\")\n",
        "print(\"5. Compare com NumPy/SciPy\")\n",
        "\n",
        "# IMPLEMENTE AQUI:\n",
        "\n",
        "def minha_covariancia(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a covari√¢ncia entre duas vari√°veis\n",
        "    \"\"\"\n",
        "    # SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "def minha_correlacao(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a correla√ß√£o de Pearson entre duas vari√°veis\n",
        "    \"\"\"\n",
        "    # SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "def matriz_correlacao_completa(df):\n",
        "    \"\"\"\n",
        "    Cria matriz de correla√ß√£o completa para um DataFrame\n",
        "    \"\"\"\n",
        "    # SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "def interpretar_correlacao(r):\n",
        "    \"\"\"\n",
        "    Retorna interpreta√ß√£o textual da correla√ß√£o\n",
        "    \"\"\"\n",
        "    # SEU C√ìDIGO AQUI\n",
        "    pass\n",
        "\n",
        "print(\"\\nüí™ Bora implementar! Depois teste com:\")\n",
        "print(\"‚Ä¢ minha_correlacao(dados_teste['A'], dados_teste['B'])\")\n",
        "print(\"‚Ä¢ matriz_correlacao_completa(dados_teste)\")\n",
        "print(\"‚Ä¢ Compare com dados_teste.corr()\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Preparando para o Pr√≥ximo M√≥dulo: Regress√£o Log√≠stica\n\nNo pr√≥ximo m√≥dulo, vamos ver **Regress√£o Log√≠stica** - onde a correla√ß√£o tamb√©m vai ser importante!\n\n### üîÆ O que vem por a√≠:\n- Como classificar ao inv√©s de prever valores cont√≠nuos\n- A curva sigmoide e probabilidades\n- Como a correla√ß√£o ajuda a escolher features\n\n### üß† Conceitos que vamos reusar:\n1. **Matriz de correla√ß√£o** para sele√ß√£o de features\n2. **Multicolinearidade** (quando features s√£o muito correlacionadas)\n3. **An√°lise explorat√≥ria** antes de modelar\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-05_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Resumo Final: O que Aprendemos\n\n**Liiindo!** Voc√™ chegou ao final do M√≥dulo 5! üéâ\n\n### üéØ Conceitos Principais:\n\n#### üìä **Covari√¢ncia**\n- Mede como duas vari√°veis variam juntas\n- F√≥rmula: $Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$\n- Problema: depende da escala dos dados\n\n#### üéØ **Correla√ß√£o**\n- Covari√¢ncia \"normalizada\" (sempre entre -1 e 1)\n- F√≥rmula: $r = \\frac{Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y}$\n- Interpreta√ß√£o mais f√°cil\n\n#### ‚ö†Ô∏è **Cuidados**\n- Correla√ß√£o ‚â† Causalidade\n- Outliers podem distorcer\n- S√≥ mede rela√ß√µes lineares (Pearson)\n\n#### üîß **Tipos**\n- **Pearson**: Para dados num√©ricos normais\n- **Spearman**: Para dados ordinais ou n√£o-normais\n- **Kendall**: Similar ao Spearman, mais robusta\n\n### üí™ **Habilidades Desenvolvidas:**\n‚úÖ Calcular correla√ß√£o na m√£o e com Python  \n‚úÖ Interpretar matrizes de correla√ß√£o  \n‚úÖ Criar visualiza√ß√µes (heatmaps)  \n‚úÖ Identificar armadilhas e limita√ß√µes  \n‚úÖ Aplicar em casos reais de neg√≥cio  \n‚úÖ Conectar com regress√£o linear  \n\n### üéä **Dica Final do Pedro:**\nCorrela√ß√£o √© uma das ferramentas mais poderosas em Data Science! Use ela pra:\n- Entender seus dados antes de modelar\n- Selecionar features importantes\n- Detectar problemas (multicolinearidade)\n- Comunicar insights para o neg√≥cio\n\n**Bora pro pr√≥ximo m√≥dulo dominar a Regress√£o Log√≠stica! üöÄ**"
      ]
    }
  ]
}