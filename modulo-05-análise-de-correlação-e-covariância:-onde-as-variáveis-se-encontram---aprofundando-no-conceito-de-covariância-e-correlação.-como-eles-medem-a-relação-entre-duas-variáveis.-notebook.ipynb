{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modulo5_correlacao_covariancia.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“Š CorrelaÃ§Ã£o e CovariÃ¢ncia: O Tinder das VariÃ¡veis! ğŸ’•\n\n## MÃ³dulo 5: AnÃ¡lise de CorrelaÃ§Ã£o e CovariÃ¢ncia - Onde as VariÃ¡veis se Encontram\n\n**Por Pedro Nunes Guth**\n\n---\n\nE aÃ­, galera! TÃ¡ pronto pra descobrir quando duas variÃ¡veis estÃ£o \"dando match\"? ğŸ˜‚\n\nNos mÃ³dulos anteriores, a gente jÃ¡ viu:\n- Como descrever uma variÃ¡vel sozinha (medidas de centralidade)\n- Como as distribuiÃ§Ãµes funcionam\n- Como fazer uma variÃ¡vel prever outra (regressÃ£o linear)\n\nMas e se eu te disser que existe uma forma de medir o quanto duas variÃ¡veis \"conversam\" entre si? Ã‰ isso que vamos ver hoje!\n\n**Bora descobrir quando as variÃ¡veis estÃ£o flertando! ğŸ”¥**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ O que vamos aprender hoje?\n\nImagina que vocÃª tÃ¡ no shopping e percebe que:\n- Quando faz calor, vende mais sorvete\n- Quando chove, vende mais guarda-chuva\n- Quando Ã© fim de mÃªs, vende menos de tudo ğŸ˜…\n\nIsso Ã© **CORRELAÃ‡ÃƒO** e **COVARIÃ‚NCIA** na prÃ¡tica!\n\nHoje vamos entender:\n1. **CovariÃ¢ncia**: Como duas variÃ¡veis variam juntas\n2. **CorrelaÃ§Ã£o**: A versÃ£o \"normalizada\" da covariÃ¢ncia\n3. **InterpretaÃ§Ã£o**: O que esses nÃºmeros significam na vida real\n4. **ImplementaÃ§Ã£o**: Como calcular na mÃ£o e no Python\n\n**Dica do Pedro**: CorrelaÃ§Ã£o â‰  Causalidade! SÃ³ porque duas coisas andam juntas, nÃ£o significa que uma causa a outra! ğŸ§ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup inicial - Importando as bibliotecas que vamos usar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurando o matplotlib para ficar mais bonito\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Seed para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"ğŸš€ Bibliotecas carregadas! Bora comeÃ§ar!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Entendendo a CovariÃ¢ncia: A Base de Tudo\n\nTÃ¡, mas o que Ã© **covariÃ¢ncia**?\n\nImagina duas pessoas danÃ§ando. Se elas se movem na mesma direÃ§Ã£o ao mesmo tempo, elas estÃ£o \"co-variando\" positivamente. Se uma vai pra direita quando a outra vai pra esquerda, estÃ£o co-variando negativamente.\n\n### ğŸ§® A MatemÃ¡tica por TrÃ¡s\n\nA covariÃ¢ncia entre duas variÃ¡veis X e Y Ã© calculada assim:\n\n$$Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$\n\nOnde:\n- $x_i$ e $y_i$ sÃ£o os valores individuais\n- $\\bar{x}$ e $\\bar{y}$ sÃ£o as mÃ©dias\n- $n$ Ã© o nÃºmero de observaÃ§Ãµes\n\n**Traduzindo**: Pra cada ponto, a gente vÃª o quanto X estÃ¡ longe da sua mÃ©dia E o quanto Y estÃ¡ longe da sua mÃ©dia. Depois multiplica esses \"desvios\" e tira a mÃ©dia de tudo.\n\n### ğŸ­ InterpretaÃ§Ã£o:\n- **Positiva**: Quando X aumenta, Y tende a aumentar\n- **Negativa**: Quando X aumenta, Y tende a diminuir  \n- **Zero**: X e Y nÃ£o tÃªm relaÃ§Ã£o linear\n\n**Dica do Pedro**: A covariÃ¢ncia nÃ£o tem limite! Pode ser qualquer valor. Por isso ela Ã© meio difÃ­cil de interpretar na prÃ¡tica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar alguns dados pra entender na prÃ¡tica\n",
        "# Exemplo: Horas de estudo vs Nota na prova\n",
        "\n",
        "horas_estudo = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "notas = np.array([3, 4, 5, 6, 7, 7.5, 8, 8.5, 9, 9.5])\n",
        "\n",
        "print(\"ğŸ“š Dados: Horas de Estudo vs Notas\")\n",
        "print(f\"Horas de estudo: {horas_estudo}\")\n",
        "print(f\"Notas: {notas}\")\n",
        "\n",
        "# Calculando a mÃ©dia de cada variÃ¡vel\n",
        "media_horas = np.mean(horas_estudo)\n",
        "media_notas = np.mean(notas)\n",
        "\n",
        "print(f\"\\nğŸ“Š MÃ©dias:\")\n",
        "print(f\"MÃ©dia de horas: {media_horas}\")\n",
        "print(f\"MÃ©dia de notas: {media_notas}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a covariÃ¢ncia na mÃ£o (pra entender o processo)\n",
        "def calcular_covariancia_manual(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a covariÃ¢ncia entre duas variÃ¡veis na mÃ£o\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    media_x = np.mean(x)\n",
        "    media_y = np.mean(y)\n",
        "    \n",
        "    # Calculando os desvios\n",
        "    desvios_x = x - media_x\n",
        "    desvios_y = y - media_y\n",
        "    \n",
        "    # Produto dos desvios\n",
        "    produtos = desvios_x * desvios_y\n",
        "    \n",
        "    # CovariÃ¢ncia amostral (n-1)\n",
        "    covariancia = np.sum(produtos) / (n - 1)\n",
        "    \n",
        "    return covariancia, desvios_x, desvios_y, produtos\n",
        "\n",
        "# Calculando\n",
        "cov_manual, desvios_h, desvios_n, produtos = calcular_covariancia_manual(horas_estudo, notas)\n",
        "\n",
        "print(\"ğŸ” Processo de cÃ¡lculo da covariÃ¢ncia:\")\n",
        "print(f\"Desvios das horas: {desvios_h}\")\n",
        "print(f\"Desvios das notas: {desvios_n}\")\n",
        "print(f\"Produtos dos desvios: {produtos}\")\n",
        "print(f\"\\nğŸ“ˆ CovariÃ¢ncia calculada na mÃ£o: {cov_manual:.4f}\")\n",
        "\n",
        "# Comparando com o NumPy\n",
        "cov_numpy = np.cov(horas_estudo, notas)[0, 1]\n",
        "print(f\"ğŸ“ˆ CovariÃ¢ncia pelo NumPy: {cov_numpy:.4f}\")\n",
        "print(f\"\\nâœ… DiferenÃ§a: {abs(cov_manual - cov_numpy):.10f} (quase zero!)\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ CorrelaÃ§Ã£o: A CovariÃ¢ncia \"Normalizada\"\n\nO problema da covariÃ¢ncia Ã© que ela depende da escala dos dados. Se eu medir altura em metros ou centÃ­metros, a covariÃ¢ncia vai ser completamente diferente!\n\nÃ‰ aÃ­ que entra a **CORRELAÃ‡ÃƒO** pra salvar o dia! ğŸ¦¸â€â™‚ï¸\n\n### ğŸ§® A FÃ³rmula da CorrelaÃ§Ã£o de Pearson\n\n$$r = \\frac{Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n\n**Traduzindo**: A correlaÃ§Ã£o Ã© a covariÃ¢ncia dividida pelo produto dos desvios padrÃ£o das duas variÃ¡veis.\n\n### ğŸ­ InterpretaÃ§Ã£o da CorrelaÃ§Ã£o:\n- **r = 1**: CorrelaÃ§Ã£o perfeita positiva (linha reta crescente)\n- **r = -1**: CorrelaÃ§Ã£o perfeita negativa (linha reta decrescente)\n- **r = 0**: Sem correlaÃ§Ã£o linear\n- **0.7 â‰¤ |r| < 1**: CorrelaÃ§Ã£o forte\n- **0.3 â‰¤ |r| < 0.7**: CorrelaÃ§Ã£o moderada\n- **0 < |r| < 0.3**: CorrelaÃ§Ã£o fraca\n\n**Dica do Pedro**: A correlaÃ§Ã£o sempre fica entre -1 e 1. Ã‰ como uma nota! Muito mais fÃ¡cil de interpretar que a covariÃ¢ncia! ğŸ“Š"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a correlaÃ§Ã£o na mÃ£o\n",
        "def calcular_correlacao_manual(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a correlaÃ§Ã£o de Pearson na mÃ£o\n",
        "    \"\"\"\n",
        "    # JÃ¡ temos a covariÃ¢ncia\n",
        "    covariancia = np.cov(x, y)[0, 1]\n",
        "    \n",
        "    # Calculando os desvios padrÃ£o\n",
        "    desvio_x = np.std(x, ddof=1)  # ddof=1 para desvio amostral\n",
        "    desvio_y = np.std(y, ddof=1)\n",
        "    \n",
        "    # CorrelaÃ§Ã£o\n",
        "    correlacao = covariancia / (desvio_x * desvio_y)\n",
        "    \n",
        "    return correlacao, covariancia, desvio_x, desvio_y\n",
        "\n",
        "# Calculando para nossos dados\n",
        "corr_manual, cov, std_h, std_n = calcular_correlacao_manual(horas_estudo, notas)\n",
        "\n",
        "print(\"ğŸ” Processo de cÃ¡lculo da correlaÃ§Ã£o:\")\n",
        "print(f\"CovariÃ¢ncia: {cov:.4f}\")\n",
        "print(f\"Desvio padrÃ£o das horas: {std_h:.4f}\")\n",
        "print(f\"Desvio padrÃ£o das notas: {std_n:.4f}\")\n",
        "print(f\"\\nğŸ“ˆ CorrelaÃ§Ã£o calculada na mÃ£o: {corr_manual:.4f}\")\n",
        "\n",
        "# Comparando com mÃ©todos prontos\n",
        "corr_numpy = np.corrcoef(horas_estudo, notas)[0, 1]\n",
        "corr_scipy = stats.pearsonr(horas_estudo, notas)[0]\n",
        "\n",
        "print(f\"ğŸ“ˆ CorrelaÃ§Ã£o pelo NumPy: {corr_numpy:.4f}\")\n",
        "print(f\"ğŸ“ˆ CorrelaÃ§Ã£o pelo SciPy: {corr_scipy:.4f}\")\n",
        "\n",
        "# InterpretaÃ§Ã£o\n",
        "print(f\"\\nğŸ¯ InterpretaÃ§Ã£o:\")\n",
        "if corr_manual >= 0.7:\n",
        "    print(f\"CorrelaÃ§Ã£o FORTE e POSITIVA! As variÃ¡veis andam muito juntas! ğŸ’ª\")\n",
        "elif corr_manual >= 0.3:\n",
        "    print(f\"CorrelaÃ§Ã£o MODERADA e POSITIVA! Tem uma relaÃ§Ã£o boa aÃ­! ğŸ‘\")\n",
        "else:\n",
        "    print(f\"CorrelaÃ§Ã£o FRACA... As variÃ¡veis nÃ£o conversam muito... ğŸ˜\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Visualizando CorrelaÃ§Ãµes: O Poder dos GrÃ¡ficos\n\nUma imagem vale mais que mil palavras, nÃ©? Vamos ver como diferentes correlaÃ§Ãµes aparecem visualmente!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estatÃ­stica-para-ia-modulo-05_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando diferentes tipos de correlaÃ§Ã£o para visualizar\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "x = np.random.randn(n)\n",
        "\n",
        "# Diferentes tipos de correlaÃ§Ã£o\n",
        "y_forte_pos = 2 * x + 0.5 * np.random.randn(n)      # CorrelaÃ§Ã£o forte positiva\n",
        "y_forte_neg = -2 * x + 0.5 * np.random.randn(n)     # CorrelaÃ§Ã£o forte negativa  \n",
        "y_moderada = 0.8 * x + 1.5 * np.random.randn(n)     # CorrelaÃ§Ã£o moderada\n",
        "y_sem_corr = np.random.randn(n)                      # Sem correlaÃ§Ã£o\n",
        "\n",
        "# Calculando as correlaÃ§Ãµes\n",
        "corr_forte_pos = np.corrcoef(x, y_forte_pos)[0, 1]\n",
        "corr_forte_neg = np.corrcoef(x, y_forte_neg)[0, 1]\n",
        "corr_moderada = np.corrcoef(x, y_moderada)[0, 1]\n",
        "corr_sem = np.corrcoef(x, y_sem_corr)[0, 1]\n",
        "\n",
        "# Criando o grÃ¡fico\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('ğŸ¯ Diferentes Tipos de CorrelaÃ§Ã£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Forte positiva\n",
        "axes[0,0].scatter(x, y_forte_pos, alpha=0.6, color='green')\n",
        "axes[0,0].plot(np.sort(x), np.poly1d(np.polyfit(x, y_forte_pos, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[0,0].set_title(f'CorrelaÃ§Ã£o Forte Positiva\\nr = {corr_forte_pos:.3f}')\n",
        "axes[0,0].set_xlabel('X')\n",
        "axes[0,0].set_ylabel('Y')\n",
        "\n",
        "# Forte negativa\n",
        "axes[0,1].scatter(x, y_forte_neg, alpha=0.6, color='red')\n",
        "axes[0,1].plot(np.sort(x), np.poly1d(np.polyfit(x, y_forte_neg, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[0,1].set_title(f'CorrelaÃ§Ã£o Forte Negativa\\nr = {corr_forte_neg:.3f}')\n",
        "axes[0,1].set_xlabel('X')\n",
        "axes[0,1].set_ylabel('Y')\n",
        "\n",
        "# Moderada\n",
        "axes[1,0].scatter(x, y_moderada, alpha=0.6, color='orange')\n",
        "axes[1,0].plot(np.sort(x), np.poly1d(np.polyfit(x, y_moderada, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[1,0].set_title(f'CorrelaÃ§Ã£o Moderada\\nr = {corr_moderada:.3f}')\n",
        "axes[1,0].set_xlabel('X')\n",
        "axes[1,0].set_ylabel('Y')\n",
        "\n",
        "# Sem correlaÃ§Ã£o\n",
        "axes[1,1].scatter(x, y_sem_corr, alpha=0.6, color='gray')\n",
        "axes[1,1].plot(np.sort(x), np.poly1d(np.polyfit(x, y_sem_corr, 1))(np.sort(x)), 'r--', linewidth=2)\n",
        "axes[1,1].set_title(f'Sem CorrelaÃ§Ã£o\\nr = {corr_sem:.3f}')\n",
        "axes[1,1].set_xlabel('X')\n",
        "axes[1,1].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š Repara como a linha vermelha (tendÃªncia) muda conforme a correlaÃ§Ã£o!\")\n",
        "print(\"ğŸ’¡ Quanto mais prÃ³ximo de 1 ou -1, mais os pontos ficam perto da linha!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ Matriz de CorrelaÃ§Ã£o: Analisando MÃºltiplas VariÃ¡veis\n\nNa vida real, raramente temos sÃ³ duas variÃ¡veis. Normalmente temos um monte delas! \n\nÃ‰ aÃ­ que entra a **Matriz de CorrelaÃ§Ã£o** - uma tabela que mostra a correlaÃ§Ã£o entre TODAS as combinaÃ§Ãµes de variÃ¡veis.\n\n### ğŸ§® Estrutura da Matriz\n\nPara variÃ¡veis X, Y, Z, a matriz fica assim:\n\n$$\\begin{pmatrix}\n1 & r_{XY} & r_{XZ} \\\\\nr_{YX} & 1 & r_{YZ} \\\\\nr_{ZX} & r_{ZY} & 1\n\\end{pmatrix}$$\n\n**CaracterÃ­sticas importantes:**\n- A diagonal sempre Ã© 1 (correlaÃ§Ã£o de uma variÃ¡vel com ela mesma)\n- A matriz Ã© simÃ©trica (r_XY = r_YX)\n- Os valores vÃ£o de -1 a 1\n\n**Dica do Pedro**: A matriz de correlaÃ§Ã£o Ã© uma das ferramentas mais poderosas pra entender seus dados! Use e abuse! ğŸ”¥"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando um dataset mais interessante pra analisar\n",
        "# Vamos simular dados de vendas de uma loja\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "\n",
        "# Criando variÃ¡veis relacionadas\n",
        "temperatura = np.random.normal(25, 5, n)  # Temperatura mÃ©dia 25Â°C\n",
        "vendas_sorvete = 10 + 2 * temperatura + np.random.normal(0, 10, n)  # Positivamente correlacionado\n",
        "vendas_chocolate_quente = 100 - 1.5 * temperatura + np.random.normal(0, 8, n)  # Negativamente correlacionado\n",
        "vendas_agua = 5 + 1.5 * temperatura + np.random.normal(0, 5, n)  # Positivamente correlacionado\n",
        "vendas_aleatorio = np.random.normal(50, 15, n)  # Sem correlaÃ§Ã£o com temperatura\n",
        "\n",
        "# Criando o DataFrame\n",
        "df_vendas = pd.DataFrame({\n",
        "    'Temperatura': temperatura,\n",
        "    'Vendas_Sorvete': vendas_sorvete,\n",
        "    'Vendas_Chocolate_Quente': vendas_chocolate_quente,\n",
        "    'Vendas_Agua': vendas_agua,\n",
        "    'Vendas_Aleatorio': vendas_aleatorio\n",
        "})\n",
        "\n",
        "print(\"ğŸª Dataset de Vendas criado!\")\n",
        "print(f\"Shape: {df_vendas.shape}\")\n",
        "print(\"\\nğŸ“Š Primeiras 5 linhas:\")\n",
        "print(df_vendas.head())\n",
        "\n",
        "print(\"\\nğŸ“ˆ EstatÃ­sticas bÃ¡sicas:\")\n",
        "print(df_vendas.describe())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculando a matriz de correlaÃ§Ã£o\n",
        "matriz_corr = df_vendas.corr()\n",
        "\n",
        "print(\"ğŸ”„ Matriz de CorrelaÃ§Ã£o:\")\n",
        "print(matriz_corr.round(3))\n",
        "\n",
        "# Visualizando com heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "heatmap = sns.heatmap(matriz_corr, \n",
        "                     annot=True,  # Mostra os valores\n",
        "                     cmap='RdBu_r',  # Colormap: vermelho para negativo, azul para positivo\n",
        "                     center=0,  # Centro em zero\n",
        "                     square=True,  # CÃ©lulas quadradas\n",
        "                     fmt='.3f',  # Formato dos nÃºmeros\n",
        "                     cbar_kws={'label': 'CorrelaÃ§Ã£o'})\n",
        "\n",
        "plt.title('ğŸ”¥ Heatmap da Matriz de CorrelaÃ§Ã£o - Vendas vs Temperatura', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretando os resultados\n",
        "print(\"\\nğŸ¯ InterpretaÃ§Ãµes:\")\n",
        "temp_sorvete = matriz_corr.loc['Temperatura', 'Vendas_Sorvete']\n",
        "temp_chocolate = matriz_corr.loc['Temperatura', 'Vendas_Chocolate_Quente']\n",
        "temp_agua = matriz_corr.loc['Temperatura', 'Vendas_Agua']\n",
        "temp_aleatorio = matriz_corr.loc['Temperatura', 'Vendas_Aleatorio']\n",
        "\n",
        "print(f\"ğŸ¦ Temperatura x Sorvete: {temp_sorvete:.3f} - CorrelaÃ§Ã£o {'FORTE' if abs(temp_sorvete) > 0.7 else 'MODERADA' if abs(temp_sorvete) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_sorvete > 0 else 'NEGATIVA'}\")\n",
        "print(f\"â˜• Temperatura x Chocolate: {temp_chocolate:.3f} - CorrelaÃ§Ã£o {'FORTE' if abs(temp_chocolate) > 0.7 else 'MODERADA' if abs(temp_chocolate) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_chocolate > 0 else 'NEGATIVA'}\")\n",
        "print(f\"ğŸ’§ Temperatura x Ãgua: {temp_agua:.3f} - CorrelaÃ§Ã£o {'FORTE' if abs(temp_agua) > 0.7 else 'MODERADA' if abs(temp_agua) > 0.3 else 'FRACA'} e {'POSITIVA' if temp_agua > 0 else 'NEGATIVA'}\")\n",
        "print(f\"ğŸ² Temperatura x AleatÃ³rio: {temp_aleatorio:.3f} - CorrelaÃ§Ã£o {'FORTE' if abs(temp_aleatorio) > 0.7 else 'MODERADA' if abs(temp_aleatorio) > 0.3 else 'FRACA'}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš ï¸ Armadilhas da CorrelaÃ§Ã£o: Cuidados Importantes!\n\nAntes de sair por aÃ­ tirando conclusÃµes, vamos falar dos **PERIGOS** da correlaÃ§Ã£o:\n\n### ğŸš¨ 1. CorrelaÃ§Ã£o â‰  Causalidade\n**O erro mais comum!** SÃ³ porque duas coisas andam juntas, nÃ£o significa que uma causa a outra.\n\n**Exemplo clÃ¡ssico**: Consumo de sorvete e afogamentos tÃªm correlaÃ§Ã£o positiva. SerÃ¡ que sorvete causa afogamento? ğŸ˜‚ Claro que nÃ£o! A causa comum Ã© o CALOR!\n\n### ğŸš¨ 2. CorrelaÃ§Ã£o EspÃºria\nDuas variÃ¡veis podem estar correlacionadas por puro acaso ou por uma terceira variÃ¡vel.\n\n### ğŸš¨ 3. RelaÃ§Ãµes NÃ£o-Lineares\nA correlaÃ§Ã£o de Pearson sÃ³ mede relaÃ§Ãµes **lineares**. Pode existir uma relaÃ§Ã£o forte, mas nÃ£o linear!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estatÃ­stica-para-ia-modulo-05_img_02.png)\n\n**Dica do Pedro**: Sempre olhe o grÃ¡fico! NÃºmeros sozinhos podem mentir! ğŸ‘€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrando armadilhas da correlaÃ§Ã£o\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# 1. RelaÃ§Ã£o nÃ£o-linear (parÃ¡bola)\n",
        "x_nonlinear = np.linspace(-3, 3, n)\n",
        "y_nonlinear = x_nonlinear**2 + 0.5 * np.random.randn(n)\n",
        "\n",
        "# 2. Outliers que afetam a correlaÃ§Ã£o\n",
        "x_outlier = np.random.randn(n)\n",
        "y_outlier = 0.3 * x_outlier + 0.5 * np.random.randn(n)\n",
        "# Adicionando alguns outliers\n",
        "x_outlier[-5:] = [4, 5, 6, 7, 8]\n",
        "y_outlier[-5:] = [4, 5, 6, 7, 8]\n",
        "\n",
        "# 3. CorrelaÃ§Ã£o espÃºria (por acaso)\n",
        "anos = np.arange(2000, 2020)\n",
        "vendas_margarina = 500 + 2 * anos + 5 * np.random.randn(20)  # Crescendo com o tempo\n",
        "divorcios = 800 + 1.5 * anos + 8 * np.random.randn(20)      # TambÃ©m crescendo com o tempo\n",
        "\n",
        "# Calculando correlaÃ§Ãµes\n",
        "corr_nonlinear = np.corrcoef(x_nonlinear, y_nonlinear)[0, 1]\n",
        "corr_outlier = np.corrcoef(x_outlier, y_outlier)[0, 1]\n",
        "corr_spurious = np.corrcoef(vendas_margarina, divorcios)[0, 1]\n",
        "\n",
        "# Plotando\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('âš ï¸ Armadilhas da CorrelaÃ§Ã£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# RelaÃ§Ã£o nÃ£o-linear\n",
        "axes[0,0].scatter(x_nonlinear, y_nonlinear, alpha=0.6)\n",
        "axes[0,0].set_title(f'RelaÃ§Ã£o NÃ£o-Linear\\nCorrelaÃ§Ã£o Linear: {corr_nonlinear:.3f}\\n(Mas vÃª como a relaÃ§Ã£o Ã© forte!)')\n",
        "axes[0,0].set_xlabel('X')\n",
        "axes[0,0].set_ylabel('Y')\n",
        "\n",
        "# Outliers\n",
        "colors = ['blue'] * (n-5) + ['red'] * 5\n",
        "axes[0,1].scatter(x_outlier, y_outlier, c=colors, alpha=0.6)\n",
        "axes[0,1].set_title(f'Efeito dos Outliers\\nCorrelaÃ§Ã£o: {corr_outlier:.3f}\\n(Pontos vermelhos = outliers)')\n",
        "axes[0,1].set_xlabel('X')\n",
        "axes[0,1].set_ylabel('Y')\n",
        "\n",
        "# CorrelaÃ§Ã£o espÃºria\n",
        "axes[1,0].scatter(vendas_margarina, divorcios, alpha=0.6, color='purple')\n",
        "axes[1,0].set_title(f'CorrelaÃ§Ã£o EspÃºria\\nr = {corr_spurious:.3f}\\n(SerÃ¡ que margarina causa divÃ³rcio? ğŸ˜‚)')\n",
        "axes[1,0].set_xlabel('Vendas de Margarina')\n",
        "axes[1,0].set_ylabel('NÃºmero de DivÃ³rcios')\n",
        "\n",
        "# Exemplo de dados sem padrÃ£o (ruÃ­do)\n",
        "x_noise = np.random.randn(n)\n",
        "y_noise = np.random.randn(n)\n",
        "corr_noise = np.corrcoef(x_noise, y_noise)[0, 1]\n",
        "axes[1,1].scatter(x_noise, y_noise, alpha=0.6, color='gray')\n",
        "axes[1,1].set_title(f'RuÃ­do Puro\\nr = {corr_noise:.3f}\\n(Sem padrÃ£o real)')\n",
        "axes[1,1].set_xlabel('X')\n",
        "axes[1,1].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸš¨ LiÃ§Ãµes importantes:\")\n",
        "print(f\"1. RelaÃ§Ã£o nÃ£o-linear pode ter correlaÃ§Ã£o baixa ({corr_nonlinear:.3f}), mas vÃª o grÃ¡fico!\")\n",
        "print(f\"2. Outliers podem inflar a correlaÃ§Ã£o artificialmente ({corr_outlier:.3f})\")\n",
        "print(f\"3. CorrelaÃ§Ã£o alta ({corr_spurious:.3f}) nÃ£o significa causalidade!\")\n",
        "print(f\"4. RuÃ­do puro ainda pode ter correlaÃ§Ã£o nÃ£o-zero ({corr_noise:.3f}) por acaso!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Tipos de CorrelaÃ§Ã£o: AlÃ©m da Pearson\n\nA correlaÃ§Ã£o de Pearson Ã© a mais famosa, mas nÃ£o Ã© a Ãºnica! Dependendo dos seus dados, outras podem ser mais apropriadas:\n\n### ğŸ“Š Tipos Principais:\n\n1. **Pearson** (que jÃ¡ vimos): Para dados **numÃ©ricos** com relaÃ§Ã£o **linear**\n2. **Spearman**: Para dados **ordinais** ou relaÃ§Ãµes **monotÃ´nicas** (nÃ£o necessariamente lineares)\n3. **Kendall**: Similar ao Spearman, mas mais robusta para amostras pequenas\n\n### ğŸ§® CorrelaÃ§Ã£o de Spearman\n\n$$r_s = 1 - \\frac{6\\sum d_i^2}{n(n^2-1)}$$\n\nOnde $d_i$ Ã© a diferenÃ§a entre os ranks de cada observaÃ§Ã£o.\n\n**Quando usar**: Dados ordinais, distribuiÃ§Ãµes nÃ£o-normais, relaÃ§Ãµes monotÃ´nicas.\n\n**Dica do Pedro**: Se seus dados nÃ£o sÃ£o \"bem comportados\" (muito assimÃ©tricos, com outliers), use Spearman! Ã‰ mais robusta! ğŸ’ª"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Comparando diferentes tipos de correlaÃ§Ã£o\n",
        "from scipy.stats import spearmanr, kendalltau\n",
        "\n",
        "# Criando dados com diferentes caracterÃ­sticas\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "\n",
        "# 1. Dados normais (Pearson funciona bem)\n",
        "x_normal = np.random.randn(n)\n",
        "y_normal = 2 * x_normal + np.random.randn(n)\n",
        "\n",
        "# 2. Dados com outliers\n",
        "x_outlier = np.random.randn(n)\n",
        "y_outlier = 2 * x_outlier + np.random.randn(n)\n",
        "# Adicionando outliers extremos\n",
        "x_outlier[-3:] = [10, 15, 20]\n",
        "y_outlier[-3:] = [-10, -15, -20]\n",
        "\n",
        "# 3. RelaÃ§Ã£o monotÃ´nica nÃ£o-linear\n",
        "x_mono = np.random.randn(n)\n",
        "y_mono = np.sign(x_mono) * (x_mono**2) + 0.5 * np.random.randn(n)\n",
        "\n",
        "# FunÃ§Ã£o para calcular todas as correlaÃ§Ãµes\n",
        "def comparar_correlacoes(x, y, nome):\n",
        "    pearson = np.corrcoef(x, y)[0, 1]\n",
        "    spearman, _ = spearmanr(x, y)\n",
        "    kendall, _ = kendalltau(x, y)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š {nome}:\")\n",
        "    print(f\"  Pearson:  {pearson:.4f}\")\n",
        "    print(f\"  Spearman: {spearman:.4f}\")\n",
        "    print(f\"  Kendall:  {kendall:.4f}\")\n",
        "    \n",
        "    return pearson, spearman, kendall\n",
        "\n",
        "# Comparando\n",
        "print(\"ğŸ” ComparaÃ§Ã£o dos MÃ©todos de CorrelaÃ§Ã£o:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "p1, s1, k1 = comparar_correlacoes(x_normal, y_normal, \"Dados Normais\")\n",
        "p2, s2, k2 = comparar_correlacoes(x_outlier, y_outlier, \"Com Outliers\")\n",
        "p3, s3, k3 = comparar_correlacoes(x_mono, y_mono, \"RelaÃ§Ã£o MonotÃ´nica\")\n",
        "\n",
        "# Visualizando\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('ğŸ”„ ComparaÃ§Ã£o dos MÃ©todos de CorrelaÃ§Ã£o', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Dados normais\n",
        "axes[0].scatter(x_normal, y_normal, alpha=0.6, color='blue')\n",
        "axes[0].set_title(f'Dados Normais\\nPearson: {p1:.3f} | Spearman: {s1:.3f}')\n",
        "axes[0].set_xlabel('X')\n",
        "axes[0].set_ylabel('Y')\n",
        "\n",
        "# Com outliers\n",
        "colors = ['blue'] * (n-3) + ['red'] * 3\n",
        "axes[1].scatter(x_outlier, y_outlier, c=colors, alpha=0.6)\n",
        "axes[1].set_title(f'Com Outliers\\nPearson: {p2:.3f} | Spearman: {s2:.3f}')\n",
        "axes[1].set_xlabel('X')\n",
        "axes[1].set_ylabel('Y')\n",
        "\n",
        "# MonotÃ´nica\n",
        "axes[2].scatter(x_mono, y_mono, alpha=0.6, color='green')\n",
        "axes[2].set_title(f'RelaÃ§Ã£o MonotÃ´nica\\nPearson: {p3:.3f} | Spearman: {s3:.3f}')\n",
        "axes[2].set_xlabel('X')\n",
        "axes[2].set_ylabel('Y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ ConclusÃµes:\")\n",
        "print(\"â€¢ Para dados normais: todos os mÃ©todos funcionam bem\")\n",
        "print(\"â€¢ Com outliers: Spearman Ã© mais robusta que Pearson\")\n",
        "print(\"â€¢ Para relaÃ§Ãµes monotÃ´nicas: Spearman captura melhor que Pearson\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ AplicaÃ§Ã£o PrÃ¡tica: AnÃ¡lise de Dataset Real\n\nBora colocar a mÃ£o na massa com um exemplo mais realista! Vamos analisar um dataset de vendas de uma empresa.\n\n### ğŸ’¼ CenÃ¡rio:\nUma empresa quer entender quais fatores mais influenciam suas vendas:\n- Gastos com marketing\n- Temperatura mÃ©dia do mÃªs\n- NÃºmero de funcionÃ¡rios\n- PreÃ§o mÃ©dio dos produtos\n- SatisfaÃ§Ã£o do cliente\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estatÃ­stica-para-ia-modulo-05_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criando um dataset realista de vendas\n",
        "np.random.seed(42)\n",
        "n_meses = 120  # 10 anos de dados mensais\n",
        "\n",
        "# VariÃ¡veis independentes (com alguma correlaÃ§Ã£o natural entre elas)\n",
        "marketing = np.random.exponential(5000, n_meses)  # Gastos com marketing (distribuiÃ§Ã£o exponencial)\n",
        "temperatura = 15 + 10 * np.sin(np.arange(n_meses) * 2 * np.pi / 12) + np.random.normal(0, 2, n_meses)  # Sazonal\n",
        "funcionarios = 20 + 0.1 * np.arange(n_meses) + np.random.normal(0, 2, n_meses)  # Crescimento ao longo do tempo\n",
        "preco_medio = 100 + np.random.normal(0, 10, n_meses)  # PreÃ§o relativamente estÃ¡vel\n",
        "satisfacao = 3 + 2 * np.random.beta(2, 1, n_meses)  # SatisfaÃ§Ã£o de 3 a 5\n",
        "\n",
        "# Vendas como funÃ§Ã£o das outras variÃ¡veis (com ruÃ­do)\n",
        "vendas = (0.8 * marketing + \n",
        "          500 * temperatura + \n",
        "          200 * funcionarios + \n",
        "          -30 * preco_medio +  # PreÃ§o alto diminui vendas\n",
        "          2000 * satisfacao +\n",
        "          np.random.normal(0, 5000, n_meses))  # RuÃ­do\n",
        "\n",
        "# Garantindo valores positivos para vendas\n",
        "vendas = np.maximum(vendas, 1000)\n",
        "\n",
        "# Criando DataFrame\n",
        "df_empresa = pd.DataFrame({\n",
        "    'Vendas': vendas,\n",
        "    'Marketing': marketing,\n",
        "    'Temperatura': temperatura,\n",
        "    'Funcionarios': funcionarios,\n",
        "    'Preco_Medio': preco_medio,\n",
        "    'Satisfacao': satisfacao\n",
        "})\n",
        "\n",
        "print(\"ğŸª Dataset da Empresa criado!\")\n",
        "print(f\"ğŸ“Š Shape: {df_empresa.shape}\")\n",
        "print(f\"ğŸ“… PerÃ­odo: {n_meses} meses ({n_meses//12} anos)\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ EstatÃ­sticas Descritivas:\")\n",
        "print(df_empresa.describe().round(2))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# AnÃ¡lise completa de correlaÃ§Ã£o\n",
        "print(\"ğŸ” ANÃLISE DE CORRELAÃ‡ÃƒO - EMPRESA XYZ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Matriz de correlaÃ§Ã£o\n",
        "corr_matrix = df_empresa.corr()\n",
        "print(\"\\nğŸ“Š Matriz de CorrelaÃ§Ã£o:\")\n",
        "print(corr_matrix.round(3))\n",
        "\n",
        "# Heatmap mais detalhado\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # MÃ¡scara para mostrar sÃ³ metade\n",
        "\n",
        "heatmap = sns.heatmap(corr_matrix, \n",
        "                     mask=mask,\n",
        "                     annot=True, \n",
        "                     cmap='RdBu_r', \n",
        "                     center=0,\n",
        "                     square=True, \n",
        "                     fmt='.3f',\n",
        "                     cbar_kws={'label': 'CorrelaÃ§Ã£o'},\n",
        "                     linewidths=0.5)\n",
        "\n",
        "plt.title('ğŸ”¥ Matriz de CorrelaÃ§Ã£o - Empresa XYZ\\n(AnÃ¡lise de Fatores que Influenciam Vendas)', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AnÃ¡lise especÃ­fica das correlaÃ§Ãµes com vendas\n",
        "correlacoes_vendas = corr_matrix['Vendas'].drop('Vendas').sort_values(key=abs, ascending=False)\n",
        "\n",
        "print(\"\\nğŸ¯ CORRELAÃ‡Ã•ES COM VENDAS (ordenadas por forÃ§a):\")\n",
        "print(\"-\" * 50)\n",
        "for variavel, corr in correlacoes_vendas.items():\n",
        "    forca = \"FORTE\" if abs(corr) > 0.7 else \"MODERADA\" if abs(corr) > 0.3 else \"FRACA\"\n",
        "    direcao = \"POSITIVA\" if corr > 0 else \"NEGATIVA\"\n",
        "    emoji = \"ğŸ“ˆ\" if corr > 0 else \"ğŸ“‰\"\n",
        "    print(f\"{emoji} {variavel:12}: {corr:+.3f} - {forca} {direcao}\")\n",
        "\n",
        "# Insights de negÃ³cio\n",
        "print(\"\\nğŸ’¼ INSIGHTS DE NEGÃ“CIO:\")\n",
        "print(\"-\" * 30)\n",
        "maior_corr = correlacoes_vendas.abs().idxmax()\n",
        "maior_valor = correlacoes_vendas[maior_corr]\n",
        "print(f\"â€¢ A variÃ¡vel que MAIS influencia vendas: {maior_corr} (r = {maior_valor:+.3f})\")\n",
        "\n",
        "menor_corr = correlacoes_vendas.abs().idxmin()\n",
        "menor_valor = correlacoes_vendas[menor_corr]\n",
        "print(f\"â€¢ A variÃ¡vel que MENOS influencia vendas: {menor_corr} (r = {menor_valor:+.3f})\")\n",
        "\n",
        "# RecomendaÃ§Ãµes\n",
        "print(\"\\nğŸš€ RECOMENDAÃ‡Ã•ES:\")\n",
        "print(\"-\" * 20)\n",
        "if correlacoes_vendas['Marketing'] > 0.5:\n",
        "    print(\"â€¢ âœ… Investir mais em marketing pode aumentar vendas significativamente!\")\n",
        "if correlacoes_vendas['Satisfacao'] > 0.3:\n",
        "    print(\"â€¢ âœ… Melhorar satisfaÃ§Ã£o do cliente Ã© fundamental!\")\n",
        "if correlacoes_vendas['Preco_Medio'] < -0.3:\n",
        "    print(\"â€¢ âš ï¸  Cuidado com preÃ§os muito altos - podem reduzir vendas!\")\n",
        "if abs(correlacoes_vendas['Funcionarios']) > 0.4:\n",
        "    print(\"â€¢ ğŸ‘¥ NÃºmero de funcionÃ¡rios tem impacto nas vendas - considerar otimizaÃ§Ã£o!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ® ExercÃ­cio PrÃ¡tico 1: AnÃ¡lise de CorrelaÃ§Ã£o\n\nAgora Ã© sua vez! Vou te dar um dataset e vocÃª vai fazer uma anÃ¡lise completa de correlaÃ§Ã£o.\n\n### ğŸ¯ Desafio: AnÃ¡lise de Notas de Estudantes\n\nVocÃª recebeu dados de 500 estudantes com as seguintes variÃ¡veis:\n- **Horas_Estudo**: Horas semanais de estudo\n- **Horas_TV**: Horas semanais assistindo TV\n- **Horas_Sono**: Horas diÃ¡rias de sono\n- **Nota_Final**: Nota final do semestre (0-10)\n- **Faltas**: NÃºmero de faltas no semestre\n\n### ğŸ“ Tarefas:\n1. Calcule a matriz de correlaÃ§Ã£o\n2. Crie um heatmap\n3. Identifique as 3 correlaÃ§Ãµes mais fortes com a Nota_Final\n4. FaÃ§a recomendaÃ§Ãµes para os estudantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EXERCÃCIO 1: Dataset de estudantes\n",
        "# Vou criar o dataset - vocÃª faz a anÃ¡lise!\n",
        "\n",
        "np.random.seed(123)\n",
        "n_estudantes = 500\n",
        "\n",
        "# Criando variÃ¡veis realistas\n",
        "horas_estudo = np.random.gamma(2, 2, n_estudantes)  # MÃ©dia ~4h, assimÃ©trica\n",
        "horas_tv = np.random.exponential(3, n_estudantes)   # MÃ©dia 3h, alguns assistem muito\n",
        "horas_sono = np.random.normal(7, 1.5, n_estudantes)  # MÃ©dia 7h, normal\n",
        "horas_sono = np.clip(horas_sono, 4, 12)  # Limitando valores realistas\n",
        "\n",
        "# Faltas correlacionadas negativamente com estudo\n",
        "faltas = np.random.poisson(3, n_estudantes) + np.random.poisson(np.maximum(5 - horas_estudo/2, 0))\n",
        "\n",
        "# Nota final como funÃ§Ã£o das outras variÃ¡veis\n",
        "nota_final = (2 + \n",
        "              0.8 * horas_estudo +      # Mais estudo = nota maior\n",
        "              -0.2 * horas_tv +         # Mais TV = nota menor\n",
        "              0.3 * horas_sono +        # Sono adequado ajuda\n",
        "              -0.15 * faltas +          # Faltas prejudicam\n",
        "              np.random.normal(0, 1, n_estudantes))  # RuÃ­do\n",
        "\n",
        "# Limitando nota entre 0 e 10\n",
        "nota_final = np.clip(nota_final, 0, 10)\n",
        "\n",
        "# Criando DataFrame\n",
        "df_estudantes = pd.DataFrame({\n",
        "    'Horas_Estudo': horas_estudo,\n",
        "    'Horas_TV': horas_tv,\n",
        "    'Horas_Sono': horas_sono,\n",
        "    'Nota_Final': nota_final,\n",
        "    'Faltas': faltas\n",
        "})\n",
        "\n",
        "print(\"ğŸ“š Dataset de Estudantes criado!\")\n",
        "print(f\"ğŸ‘¥ {n_estudantes} estudantes\")\n",
        "print(\"\\nğŸ“Š Primeiras 5 linhas:\")\n",
        "print(df_estudantes.head())\n",
        "print(\"\\nğŸ“ˆ EstatÃ­sticas:\")\n",
        "print(df_estudantes.describe().round(2))\n",
        "\n",
        "print(\"\\nğŸ¯ AGORA Ã‰ SUA VEZ!\")\n",
        "print(\"FaÃ§a a anÃ¡lise de correlaÃ§Ã£o completa:\")\n",
        "print(\"1. Calcule a matriz de correlaÃ§Ã£o\")\n",
        "print(\"2. Crie um heatmap\")\n",
        "print(\"3. Analise as correlaÃ§Ãµes com Nota_Final\")\n",
        "print(\"4. DÃª recomendaÃ§Ãµes para os estudantes\")\n",
        "print(\"\\nğŸ’ª Bora lÃ¡!\")\n",
        "\n",
        "# SEU CÃ“DIGO AQUI:\n",
        "# matriz_corr_estudantes = ...\n",
        "# ..."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”— ConexÃ£o com RegressÃ£o Linear (MÃ³dulo 4)\n\nLembra da regressÃ£o linear que vimos no mÃ³dulo anterior? A correlaÃ§Ã£o estÃ¡ **DIRETAMENTE** ligada a ela!\n\n### ğŸ§® A MatemÃ¡tica da ConexÃ£o\n\nPara regressÃ£o simples $y = a + bx$, o coeficiente angular $b$ Ã©:\n\n$$b = r \\cdot \\frac{\\sigma_y}{\\sigma_x}$$\n\nE o $R^2$ (coeficiente de determinaÃ§Ã£o) Ã©:\n\n$$R^2 = r^2$$\n\n**Traduzindo**: \n- A **correlaÃ§Ã£o** te diz a DIREÃ‡ÃƒO e FORÃ‡A da relaÃ§Ã£o\n- A **regressÃ£o** te dÃ¡ a EQUAÃ‡ÃƒO para fazer previsÃµes\n- O **RÂ²** te diz quanto da variaÃ§Ã£o Ã© explicada pelo modelo\n\n**Dica do Pedro**: CorrelaÃ§Ã£o e regressÃ£o sÃ£o irmÃ£s! Uma ajuda a entender a outra! ğŸ‘¯â€â™€ï¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrando a conexÃ£o entre correlaÃ§Ã£o e regressÃ£o\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Usando nossos dados de horas de estudo vs notas\n",
        "x = horas_estudo.reshape(-1, 1)  # sklearn precisa de 2D\n",
        "y = nota_final\n",
        "\n",
        "# Calculando correlaÃ§Ã£o\n",
        "correlacao = np.corrcoef(horas_estudo, nota_final)[0, 1]\n",
        "\n",
        "# Fazendo regressÃ£o linear\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(x, y)\n",
        "y_pred = modelo.predict(x)\n",
        "\n",
        "# Calculando RÂ²\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Coeficientes\n",
        "coef_angular = modelo.coef_[0]\n",
        "intercepto = modelo.intercept_\n",
        "\n",
        "print(\"ğŸ”— CONEXÃƒO: CORRELAÃ‡ÃƒO â†” REGRESSÃƒO\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ“Š CorrelaÃ§Ã£o (r): {correlacao:.4f}\")\n",
        "print(f\"ğŸ“ˆ RÂ² da regressÃ£o: {r2:.4f}\")\n",
        "print(f\"ğŸ¯ rÂ² = {correlacao**2:.4f}\")\n",
        "print(f\"âœ… DiferenÃ§a rÂ² vs RÂ²: {abs(correlacao**2 - r2):.10f}\")\n",
        "\n",
        "print(f\"\\nğŸ“ EquaÃ§Ã£o da reta: y = {intercepto:.3f} + {coef_angular:.3f}x\")\n",
        "print(f\"ğŸ“Š Desvio padrÃ£o X: {np.std(horas_estudo, ddof=1):.3f}\")\n",
        "print(f\"ğŸ“Š Desvio padrÃ£o Y: {np.std(nota_final, ddof=1):.3f}\")\n",
        "print(f\"ğŸ§® b teÃ³rico: r * (Ïƒy/Ïƒx) = {correlacao * np.std(nota_final, ddof=1) / np.std(horas_estudo, ddof=1):.3f}\")\n",
        "\n",
        "# Visualizando\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(horas_estudo, nota_final, alpha=0.5, color='blue', label='Dados')\n",
        "\n",
        "# Linha de regressÃ£o\n",
        "x_linha = np.linspace(horas_estudo.min(), horas_estudo.max(), 100)\n",
        "y_linha = intercepto + coef_angular * x_linha\n",
        "plt.plot(x_linha, y_linha, 'r-', linewidth=2, label=f'RegressÃ£o: y = {intercepto:.2f} + {coef_angular:.2f}x')\n",
        "\n",
        "plt.xlabel('Horas de Estudo por Semana')\n",
        "plt.ylabel('Nota Final')\n",
        "plt.title(f'ğŸ”— CorrelaÃ§Ã£o vs RegressÃ£o\\nr = {correlacao:.3f} | RÂ² = {r2:.3f}', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionando texto explicativo\n",
        "plt.text(0.05, 0.95, f'ğŸ’¡ RÂ² = rÂ² = {correlacao:.3f}Â² = {r2:.3f}', \n",
        "         transform=plt.gca().transAxes, fontsize=12, \n",
        "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ INTERPRETAÃ‡ÃƒO:\")\n",
        "print(f\"â€¢ A correlaÃ§Ã£o r = {correlacao:.3f} indica relaÃ§Ã£o {'forte' if abs(correlacao) > 0.7 else 'moderada' if abs(correlacao) > 0.3 else 'fraca'}\")\n",
        "print(f\"â€¢ O RÂ² = {r2:.3f} significa que {r2*100:.1f}% da variaÃ§Ã£o nas notas Ã© explicada pelas horas de estudo\")\n",
        "print(f\"â€¢ Para cada hora extra de estudo, a nota aumenta {coef_angular:.3f} pontos em mÃ©dia\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ® ExercÃ­cio PrÃ¡tico 2: ImplementaÃ§Ã£o do Zero\n\nAgora o desafio HARDCORE! Vou te dar apenas os dados, e vocÃª vai implementar TUDO do zero:\n\n### ğŸ—ï¸ Desafio: Implemente suas prÃ³prias funÃ§Ãµes\n\n**Crie as seguintes funÃ§Ãµes:**\n1. `minha_covariancia(x, y)` - Calcula covariÃ¢ncia do zero\n2. `minha_correlacao(x, y)` - Calcula correlaÃ§Ã£o do zero\n3. `matriz_correlacao_completa(dataframe)` - Matriz de correlaÃ§Ã£o completa\n4. `interpretar_correlacao(r)` - Retorna interpretaÃ§Ã£o textual\n\n### ğŸ“Š Teste com dados reais\nUse o dataset que vou fornecer e compare seus resultados com o NumPy/SciPy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EXERCÃCIO 2: ImplementaÃ§Ã£o do Zero\n",
        "# Vou dar os dados, vocÃª implementa as funÃ§Ãµes!\n",
        "\n",
        "# Dataset de teste\n",
        "np.random.seed(777)\n",
        "n = 50\n",
        "dados_teste = pd.DataFrame({\n",
        "    'A': np.random.normal(10, 2, n),\n",
        "    'B': np.random.normal(5, 1, n),\n",
        "    'C': np.random.exponential(2, n),\n",
        "    'D': np.random.uniform(0, 10, n)\n",
        "})\n",
        "\n",
        "# Criando algumas correlaÃ§Ãµes artificiais\n",
        "dados_teste['B'] = dados_teste['A'] * 0.7 + np.random.normal(0, 0.5, n)  # CorrelaÃ§Ã£o forte com A\n",
        "dados_teste['C'] = dados_teste['A'] * -0.4 + np.random.normal(5, 1, n)   # CorrelaÃ§Ã£o negativa com A\n",
        "\n",
        "print(\"ğŸ¯ EXERCÃCIO 2: IMPLEMENTAÃ‡ÃƒO DO ZERO\")\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸ“Š Dataset de teste criado!\")\n",
        "print(dados_teste.head())\n",
        "\n",
        "print(\"\\nğŸ—ï¸ SUAS TAREFAS:\")\n",
        "print(\"1. Implemente minha_covariancia(x, y)\")\n",
        "print(\"2. Implemente minha_correlacao(x, y)\")\n",
        "print(\"3. Implemente matriz_correlacao_completa(df)\")\n",
        "print(\"4. Implemente interpretar_correlacao(r)\")\n",
        "print(\"5. Compare com NumPy/SciPy\")\n",
        "\n",
        "# IMPLEMENTE AQUI:\n",
        "\n",
        "def minha_covariancia(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a covariÃ¢ncia entre duas variÃ¡veis\n",
        "    \"\"\"\n",
        "    # SEU CÃ“DIGO AQUI\n",
        "    pass\n",
        "\n",
        "def minha_correlacao(x, y):\n",
        "    \"\"\"\n",
        "    Calcula a correlaÃ§Ã£o de Pearson entre duas variÃ¡veis\n",
        "    \"\"\"\n",
        "    # SEU CÃ“DIGO AQUI\n",
        "    pass\n",
        "\n",
        "def matriz_correlacao_completa(df):\n",
        "    \"\"\"\n",
        "    Cria matriz de correlaÃ§Ã£o completa para um DataFrame\n",
        "    \"\"\"\n",
        "    # SEU CÃ“DIGO AQUI\n",
        "    pass\n",
        "\n",
        "def interpretar_correlacao(r):\n",
        "    \"\"\"\n",
        "    Retorna interpretaÃ§Ã£o textual da correlaÃ§Ã£o\n",
        "    \"\"\"\n",
        "    # SEU CÃ“DIGO AQUI\n",
        "    pass\n",
        "\n",
        "print(\"\\nğŸ’ª Bora implementar! Depois teste com:\")\n",
        "print(\"â€¢ minha_correlacao(dados_teste['A'], dados_teste['B'])\")\n",
        "print(\"â€¢ matriz_correlacao_completa(dados_teste)\")\n",
        "print(\"â€¢ Compare com dados_teste.corr()\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Preparando para o PrÃ³ximo MÃ³dulo: RegressÃ£o LogÃ­stica\n\nNo prÃ³ximo mÃ³dulo, vamos ver **RegressÃ£o LogÃ­stica** - onde a correlaÃ§Ã£o tambÃ©m vai ser importante!\n\n### ğŸ”® O que vem por aÃ­:\n- Como classificar ao invÃ©s de prever valores contÃ­nuos\n- A curva sigmoide e probabilidades\n- Como a correlaÃ§Ã£o ajuda a escolher features\n\n### ğŸ§  Conceitos que vamos reusar:\n1. **Matriz de correlaÃ§Ã£o** para seleÃ§Ã£o de features\n2. **Multicolinearidade** (quando features sÃ£o muito correlacionadas)\n3. **AnÃ¡lise exploratÃ³ria** antes de modelar\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estatÃ­stica-para-ia-modulo-05_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Resumo Final: O que Aprendemos\n\n**Liiindo!** VocÃª chegou ao final do MÃ³dulo 5! ğŸ‰\n\n### ğŸ¯ Conceitos Principais:\n\n#### ğŸ“Š **CovariÃ¢ncia**\n- Mede como duas variÃ¡veis variam juntas\n- FÃ³rmula: $Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$\n- Problema: depende da escala dos dados\n\n#### ğŸ¯ **CorrelaÃ§Ã£o**\n- CovariÃ¢ncia \"normalizada\" (sempre entre -1 e 1)\n- FÃ³rmula: $r = \\frac{Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y}$\n- InterpretaÃ§Ã£o mais fÃ¡cil\n\n#### âš ï¸ **Cuidados**\n- CorrelaÃ§Ã£o â‰  Causalidade\n- Outliers podem distorcer\n- SÃ³ mede relaÃ§Ãµes lineares (Pearson)\n\n#### ğŸ”§ **Tipos**\n- **Pearson**: Para dados numÃ©ricos normais\n- **Spearman**: Para dados ordinais ou nÃ£o-normais\n- **Kendall**: Similar ao Spearman, mais robusta\n\n### ğŸ’ª **Habilidades Desenvolvidas:**\nâœ… Calcular correlaÃ§Ã£o na mÃ£o e com Python  \nâœ… Interpretar matrizes de correlaÃ§Ã£o  \nâœ… Criar visualizaÃ§Ãµes (heatmaps)  \nâœ… Identificar armadilhas e limitaÃ§Ãµes  \nâœ… Aplicar em casos reais de negÃ³cio  \nâœ… Conectar com regressÃ£o linear  \n\n### ğŸŠ **Dica Final do Pedro:**\nCorrelaÃ§Ã£o Ã© uma das ferramentas mais poderosas em Data Science! Use ela pra:\n- Entender seus dados antes de modelar\n- Selecionar features importantes\n- Detectar problemas (multicolinearidade)\n- Comunicar insights para o negÃ³cio\n\n**Bora pro prÃ³ximo mÃ³dulo dominar a RegressÃ£o LogÃ­stica! ğŸš€**"
      ]
    }
  ]
}