{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulo_4_Regressao_Linear_Simples.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìà Regress√£o Linear Simples: A Linha que Tenta Prever o Futuro\n\n## *M√≥dulo 4 - Estat√≠stica para IA*\n\n**Pedro Nunes Guth**\n\n---\n\nE a√≠, pessoal! Bora falar de uma das t√©cnicas mais importantes da estat√≠stica e IA? A regress√£o linear simples √© tipo aquele amigo que sempre tenta adivinhar o que vai acontecer baseado no que j√° rolou antes.\n\nImagina que voc√™ t√° tentando prever o pre√ßo de um apartamento baseado no tamanho dele. Ou quanto voc√™ vai gastar de gasolina baseado na dist√¢ncia que vai viajar. √â exatamente isso que a regress√£o linear faz: ela desenha uma linha no meio dos pontos tentando capturar a rela√ß√£o entre duas vari√°veis!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-04_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - bora importar as bibliotecas que vamos usar!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Configurando o matplotlib para ficar bonitinho\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Para reproduzir os mesmos resultados\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Tudo carregado! Bora come√ßar a divers√£o! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O que √© Regress√£o Linear Simples?\n\nT√°, mas o que √© regress√£o linear simples mesmo? √â basicamente uma t√©cnica que tenta encontrar a **melhor linha reta** que passa pelos nossos dados. Essa linha vai nos ajudar a fazer previs√µes!\n\nPensa assim: voc√™ tem um monte de pontos espalhados num gr√°fico (como chuva de confete no carnaval), e voc√™ quer desenhar uma linha reta que \"resume\" onde esses pontos est√£o. Essa linha √© nossa **linha de regress√£o**!\n\n### A equa√ß√£o da reta que voc√™ aprendeu na escola:\n\n$$y = ax + b$$\n\nNa regress√£o linear, a gente escreve assim:\n\n$$\\hat{y} = \\beta_0 + \\beta_1 x$$\n\nOnde:\n- $\\hat{y}$ = valor previsto (o \"y chap√©u\")\n- $\\beta_0$ = intercepto (onde a linha corta o eixo Y)\n- $\\beta_1$ = coeficiente angular (inclina√ß√£o da linha)\n- $x$ = vari√°vel independente (entrada)\n\n**Dica do Pedro:** Lembra dos m√≥dulos anteriores? Aqui vamos usar muito a correla√ß√£o que estudamos! Se duas vari√°veis t√™m correla√ß√£o forte, a regress√£o linear vai funcionar melhor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar dados sint√©ticos para entender melhor\n",
        "# Imagine que estamos prevendo o pre√ßo de casas baseado no tamanho (em m¬≤)\n",
        "\n",
        "# Tamanho das casas (vari√°vel X)\n",
        "tamanho_casa = np.array([50, 70, 80, 100, 120, 140, 160, 180, 200, 220])\n",
        "\n",
        "# Pre√ßo das casas (vari√°vel Y) - com um pouco de ru√≠do para ficar realista\n",
        "preco_casa = 2000 * tamanho_casa + 50000 + np.random.normal(0, 20000, len(tamanho_casa))\n",
        "\n",
        "print(\"Dados das casas:\")\n",
        "print(f\"Tamanhos: {tamanho_casa}\")\n",
        "print(f\"Pre√ßos: {preco_casa.astype(int)}\")\n",
        "\n",
        "# Vamos visualizar esses dados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(tamanho_casa, preco_casa, color='blue', alpha=0.7, s=100)\n",
        "plt.xlabel('Tamanho da Casa (m¬≤)')\n",
        "plt.ylabel('Pre√ßo da Casa (R$)')\n",
        "plt.title('Rela√ß√£o entre Tamanho e Pre√ßo das Casas')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nOlha s√≥! D√° pra ver que existe uma rela√ß√£o entre tamanho e pre√ßo, n√©?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßÆ A Matem√°tica por Tr√°s: M√©todo dos M√≠nimos Quadrados\n\nAgora vem a parte mais interessante! Como a gente encontra a **melhor linha**? \n\nA resposta √©: usando o **M√©todo dos M√≠nimos Quadrados**. √â tipo um jogo onde voc√™ quer minimizar a \"raiva\" dos pontos em rela√ß√£o √† linha.\n\n### O que s√£o os \"erros\" ou \"res√≠duos\"?\n\nPara cada ponto, temos:\n- $y_i$ = valor real\n- $\\hat{y_i}$ = valor previsto pela nossa linha\n- $e_i = y_i - \\hat{y_i}$ = erro (res√≠duo)\n\n### A fun√ß√£o que queremos minimizar:\n\n$$SSE = \\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$$\n\n**SSE** = Soma dos Quadrados dos Erros (Sum of Squared Errors)\n\n### As f√≥rmulas m√°gicas para encontrar Œ≤‚ÇÄ e Œ≤‚ÇÅ:\n\n$$\\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$\n\n$$\\beta_0 = \\bar{y} - \\beta_1\\bar{x}$$\n\nOnde $\\bar{x}$ e $\\bar{y}$ s√£o as m√©dias que estudamos no M√≥dulo 1!\n\n**Dica do Pedro:** Essa f√≥rmula do Œ≤‚ÇÅ √© praticamente a covari√¢ncia dividida pela vari√¢ncia! Lembra desses conceitos? Vamos ver eles mais a fundo no pr√≥ximo m√≥dulo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos implementar o c√°lculo manual dos coeficientes!\n",
        "# Isso vai nos ajudar a entender a matem√°tica por dentro\n",
        "\n",
        "def calcular_regressao_manual(x, y):\n",
        "    \"\"\"\n",
        "    Calcula os coeficientes da regress√£o linear usando as f√≥rmulas matem√°ticas\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    \n",
        "    # Calculando as m√©dias (M√≥dulo 1!)\n",
        "    x_media = np.mean(x)\n",
        "    y_media = np.mean(y)\n",
        "    \n",
        "    print(f\"M√©dia de X (tamanho): {x_media:.2f} m¬≤\")\n",
        "    print(f\"M√©dia de Y (pre√ßo): {y_media:.2f} R$\")\n",
        "    \n",
        "    # Calculando Œ≤‚ÇÅ (coeficiente angular)\n",
        "    numerador = np.sum((x - x_media) * (y - y_media))\n",
        "    denominador = np.sum((x - x_media) ** 2)\n",
        "    \n",
        "    beta_1 = numerador / denominador\n",
        "    \n",
        "    # Calculando Œ≤‚ÇÄ (intercepto)\n",
        "    beta_0 = y_media - beta_1 * x_media\n",
        "    \n",
        "    print(f\"\\nCoeficientes calculados:\")\n",
        "    print(f\"Œ≤‚ÇÅ (inclina√ß√£o): {beta_1:.2f}\")\n",
        "    print(f\"Œ≤‚ÇÄ (intercepto): {beta_0:.2f}\")\n",
        "    \n",
        "    return beta_0, beta_1\n",
        "\n",
        "# Calculando nossos coeficientes\n",
        "beta_0, beta_1 = calcular_regressao_manual(tamanho_casa, preco_casa)\n",
        "\n",
        "print(f\"\\nInterpreta√ß√£o:\")\n",
        "print(f\"- Para cada m¬≤ a mais, o pre√ßo aumenta R$ {beta_1:.2f}\")\n",
        "print(f\"- Uma casa de 0 m¬≤ custaria R$ {beta_0:.2f} (intercepto)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando a Linha de Melhor Ajuste\n\nAgora que temos nossos coeficientes, vamos desenhar a linha de regress√£o! √â aqui que a m√°gica acontece - vamos ver como nossa linha \"tenta\" passar o mais pr√≥ximo poss√≠vel de todos os pontos.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-04_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar a linha de regress√£o usando nossos coeficientes\n",
        "x_linha = np.linspace(min(tamanho_casa), max(tamanho_casa), 100)\n",
        "y_linha = beta_0 + beta_1 * x_linha\n",
        "\n",
        "# Calculando os valores previstos para nossos pontos originais\n",
        "y_previsto = beta_0 + beta_1 * tamanho_casa\n",
        "\n",
        "# Criando o gr√°fico\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Pontos originais\n",
        "plt.scatter(tamanho_casa, preco_casa, color='blue', alpha=0.7, s=100, label='Dados Reais')\n",
        "\n",
        "# Linha de regress√£o\n",
        "plt.plot(x_linha, y_linha, color='red', linewidth=2, label=f'Linha de Regress√£o: y = {beta_1:.0f}x + {beta_0:.0f}')\n",
        "\n",
        "# Valores previstos\n",
        "plt.scatter(tamanho_casa, y_previsto, color='red', alpha=0.5, s=50, label='Valores Previstos')\n",
        "\n",
        "# Linhas mostrando os erros (res√≠duos)\n",
        "for i in range(len(tamanho_casa)):\n",
        "    plt.plot([tamanho_casa[i], tamanho_casa[i]], [preco_casa[i], y_previsto[i]], \n",
        "             color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.xlabel('Tamanho da Casa (m¬≤)')\n",
        "plt.ylabel('Pre√ßo da Casa (R$)')\n",
        "plt.title('Regress√£o Linear: Tamanho vs Pre√ßo das Casas')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"Liiindo! As linhas cinzas pontilhadas mostram os 'erros' - a diferen√ßa entre o valor real e o previsto.\")\n",
        "print(\"A nossa linha tenta minimizar a soma dos quadrados desses erros!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¢ Calculando as M√©tricas de Avalia√ß√£o\n\nT√°, mas como sabemos se nossa linha √© boa? Precisamos de algumas m√©tricas para avaliar!\n\n### 1. Erro Quadr√°tico M√©dio (MSE - Mean Squared Error):\n$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$$\n\n### 2. Raiz do Erro Quadr√°tico M√©dio (RMSE):\n$$RMSE = \\sqrt{MSE}$$\n\n### 3. Coeficiente de Determina√ß√£o (R¬≤):\n$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum(y_i - \\hat{y_i})^2}{\\sum(y_i - \\bar{y})^2}$$\n\nO **R¬≤** vai de 0 a 1:\n- R¬≤ = 1: Modelo perfeito!\n- R¬≤ = 0: Modelo n√£o explica nada\n- R¬≤ = 0.8: Modelo explica 80% da varia√ß√£o dos dados\n\n**Dica do Pedro:** O R¬≤ est√° relacionado com a correla√ß√£o que vimos antes! Na regress√£o linear simples, R¬≤ = correla√ß√£o¬≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos calcular as m√©tricas de avalia√ß√£o\n",
        "\n",
        "def avaliar_modelo(y_real, y_previsto):\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas de avalia√ß√£o do modelo\n",
        "    \"\"\"\n",
        "    # MSE - Erro Quadr√°tico M√©dio\n",
        "    mse = np.mean((y_real - y_previsto) ** 2)\n",
        "    \n",
        "    # RMSE - Raiz do Erro Quadr√°tico M√©dio\n",
        "    rmse = np.sqrt(mse)\n",
        "    \n",
        "    # R¬≤ - Coeficiente de Determina√ß√£o\n",
        "    ss_res = np.sum((y_real - y_previsto) ** 2)  # Soma dos quadrados dos res√≠duos\n",
        "    ss_tot = np.sum((y_real - np.mean(y_real)) ** 2)  # Soma total dos quadrados\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "    \n",
        "    return mse, rmse, r2\n",
        "\n",
        "# Calculando as m√©tricas\n",
        "mse, rmse, r2 = avaliar_modelo(preco_casa, y_previsto)\n",
        "\n",
        "print(\"üìä M√âTRICAS DE AVALIA√á√ÉO:\")\n",
        "print(f\"MSE (Erro Quadr√°tico M√©dio): {mse:,.2f}\")\n",
        "print(f\"RMSE (Raiz do Erro Quadr√°tico M√©dio): {rmse:,.2f} R$\")\n",
        "print(f\"R¬≤ (Coeficiente de Determina√ß√£o): {r2:.4f}\")\n",
        "\n",
        "print(f\"\\nüìà INTERPRETA√á√ÉO:\")\n",
        "print(f\"- Em m√©dia, nossos erros s√£o de R$ {rmse:,.0f}\")\n",
        "print(f\"- Nosso modelo explica {r2*100:.1f}% da varia√ß√£o nos pre√ßos!\")\n",
        "\n",
        "# Vamos calcular tamb√©m a correla√ß√£o para comparar com R¬≤\n",
        "correlacao = np.corrcoef(tamanho_casa, preco_casa)[0, 1]\n",
        "print(f\"\\nüîó BONUS - Correla√ß√£o: {correlacao:.4f}\")\n",
        "print(f\"Correla√ß√£o¬≤: {correlacao**2:.4f} (bem pr√≥ximo do R¬≤!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Usando o Scikit-learn\n\nT√° bom, agora que entendemos a matem√°tica, vamos ver como fazer isso de forma mais pr√°tica usando o scikit-learn! √â tipo usar uma calculadora depois de aprender a fazer conta na m√£o.\n\n```mermaid\ngraph TD\n    A[Dados de Entrada X,Y] --> B[LinearRegression]\n    B --> C[Fit - Treinar o Modelo]\n    C --> D[Coeficientes Œ≤‚ÇÄ, Œ≤‚ÇÅ]\n    D --> E[Predict - Fazer Previs√µes]\n    E --> F[M√©tricas de Avalia√ß√£o]\n    F --> G[Modelo Pronto!]\n```\n\n**Dica do Pedro:** O sklearn faz exatamente a mesma matem√°tica que implementamos, s√≥ que otimizada e mais r√°pida!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usando o scikit-learn para comparar com nosso c√°lculo manual\n",
        "\n",
        "# Preparando os dados (sklearn precisa de arrays 2D)\n",
        "X = tamanho_casa.reshape(-1, 1)  # Vari√°vel independente\n",
        "y = preco_casa  # Vari√°vel dependente\n",
        "\n",
        "# Criando e treinando o modelo\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(X, y)\n",
        "\n",
        "# Obtendo os coeficientes\n",
        "beta_0_sklearn = modelo.intercept_\n",
        "beta_1_sklearn = modelo.coef_[0]\n",
        "\n",
        "# Fazendo previs√µes\n",
        "y_previsto_sklearn = modelo.predict(X)\n",
        "\n",
        "print(\"üî¨ COMPARA√á√ÉO - Manual vs Scikit-learn:\")\n",
        "print(f\"Œ≤‚ÇÄ (intercepto):\")\n",
        "print(f\"  Manual: {beta_0:.2f}\")\n",
        "print(f\"  Sklearn: {beta_0_sklearn:.2f}\")\n",
        "\n",
        "print(f\"\\nŒ≤‚ÇÅ (inclina√ß√£o):\")\n",
        "print(f\"  Manual: {beta_1:.2f}\")\n",
        "print(f\"  Sklearn: {beta_1_sklearn:.2f}\")\n",
        "\n",
        "# M√©tricas usando sklearn\n",
        "mse_sklearn = mean_squared_error(y, y_previsto_sklearn)\n",
        "r2_sklearn = r2_score(y, y_previsto_sklearn)\n",
        "\n",
        "print(f\"\\nüìä M√âTRICAS (Sklearn):\")\n",
        "print(f\"MSE: {mse_sklearn:,.2f}\")\n",
        "print(f\"R¬≤: {r2_sklearn:.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Perfeito! Os resultados s√£o praticamente id√™nticos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Fazendo Previs√µes\n\nAgora vem a parte divertida! Vamos usar nosso modelo para prever o pre√ßo de casas de tamanhos que n√£o temos nos dados originais.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-04_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos fazer algumas previs√µes interessantes!\n",
        "\n",
        "def fazer_previsao(tamanho, modelo):\n",
        "    \"\"\"\n",
        "    Faz previs√£o do pre√ßo baseado no tamanho\n",
        "    \"\"\"\n",
        "    tamanho_2d = np.array([[tamanho]])\n",
        "    preco_previsto = modelo.predict(tamanho_2d)[0]\n",
        "    return preco_previsto\n",
        "\n",
        "# Testando alguns tamanhos\n",
        "tamanhos_teste = [60, 90, 150, 250, 300]\n",
        "\n",
        "print(\"üè† PREVIS√ïES DE PRE√áOS:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for tamanho in tamanhos_teste:\n",
        "    preco_pred = fazer_previsao(tamanho, modelo)\n",
        "    print(f\"Casa de {tamanho:3d} m¬≤: R$ {preco_pred:8,.0f}\")\n",
        "\n",
        "# Vamos visualizar essas previs√µes\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Dados originais\n",
        "plt.scatter(tamanho_casa, preco_casa, color='blue', alpha=0.7, s=100, label='Dados Originais')\n",
        "\n",
        "# Linha de regress√£o estendida\n",
        "x_estendido = np.linspace(40, 320, 100)\n",
        "y_estendido = modelo.predict(x_estendido.reshape(-1, 1))\n",
        "plt.plot(x_estendido, y_estendido, color='red', linewidth=2, label='Linha de Regress√£o')\n",
        "\n",
        "# Previs√µes\n",
        "precos_teste = [fazer_previsao(t, modelo) for t in tamanhos_teste]\n",
        "plt.scatter(tamanhos_teste, precos_teste, color='green', s=150, marker='^', \n",
        "           label='Previs√µes', edgecolor='black', linewidth=2)\n",
        "\n",
        "# Anota√ß√µes das previs√µes\n",
        "for i, (tamanho, preco) in enumerate(zip(tamanhos_teste, precos_teste)):\n",
        "    plt.annotate(f'{tamanho}m¬≤\\nR${preco:,.0f}', \n",
        "                xy=(tamanho, preco), \n",
        "                xytext=(10, 20), textcoords='offset points',\n",
        "                fontsize=9, ha='center',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', fc='yellow', alpha=0.7))\n",
        "\n",
        "plt.xlabel('Tamanho da Casa (m¬≤)')\n",
        "plt.ylabel('Pre√ßo da Casa (R$)')\n",
        "plt.title('Regress√£o Linear: Dados Originais + Previs√µes')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ Aten√ß√£o: Cuidado com extrapola√ß√µes muito distantes dos dados originais!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Analisando os Res√≠duos\n\nUma parte importante da regress√£o linear √© analisar os **res√≠duos** (erros). Eles nos contam muito sobre a qualidade do nosso modelo!\n\n### O que queremos ver nos res√≠duos:\n1. **Distribui√ß√£o Normal** (lembra do M√≥dulo 2?)\n2. **M√©dia pr√≥xima de zero**\n3. **Vari√¢ncia constante** (homocedasticidade)\n4. **Sem padr√µes √≥bvios**\n\n**Dica do Pedro:** Se os res√≠duos n√£o seguem esses padr√µes, pode ser que a regress√£o linear simples n√£o seja o melhor modelo para os dados!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisando os res√≠duos do nosso modelo\n",
        "\n",
        "# Calculando os res√≠duos\n",
        "residuos = preco_casa - y_previsto_sklearn\n",
        "\n",
        "# Criando subplots para v√°rias an√°lises\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Res√≠duos vs Valores Previstos\n",
        "axes[0, 0].scatter(y_previsto_sklearn, residuos, alpha=0.7)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0, 0].set_xlabel('Valores Previstos')\n",
        "axes[0, 0].set_ylabel('Res√≠duos')\n",
        "axes[0, 0].set_title('Res√≠duos vs Valores Previstos')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Histograma dos Res√≠duos\n",
        "axes[0, 1].hist(residuos, bins=8, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 1].axvline(x=0, color='red', linestyle='--')\n",
        "axes[0, 1].set_xlabel('Res√≠duos')\n",
        "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
        "axes[0, 1].set_title('Distribui√ß√£o dos Res√≠duos')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Q-Q Plot (comparando com distribui√ß√£o normal)\n",
        "from scipy import stats\n",
        "stats.probplot(residuos, dist=\"norm\", plot=axes[1, 0])\n",
        "axes[1, 0].set_title('Q-Q Plot (Normalidade dos Res√≠duos)')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Res√≠duos vs Ordem (para detectar padr√µes temporais)\n",
        "axes[1, 1].scatter(range(len(residuos)), residuos, alpha=0.7)\n",
        "axes[1, 1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[1, 1].set_xlabel('Ordem dos Dados')\n",
        "axes[1, 1].set_ylabel('Res√≠duos')\n",
        "axes[1, 1].set_title('Res√≠duos vs Ordem')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estat√≠sticas dos res√≠duos\n",
        "print(\"üìä ESTAT√çSTICAS DOS RES√çDUOS:\")\n",
        "print(f\"M√©dia dos res√≠duos: {np.mean(residuos):,.2f}\")\n",
        "print(f\"Desvio padr√£o dos res√≠duos: {np.std(residuos):,.2f}\")\n",
        "print(f\"M√≠nimo: {np.min(residuos):,.2f}\")\n",
        "print(f\"M√°ximo: {np.max(residuos):,.2f}\")\n",
        "\n",
        "# Teste de normalidade (Shapiro-Wilk)\n",
        "shapiro_stat, shapiro_p = stats.shapiro(residuos)\n",
        "print(f\"\\nüß™ TESTE DE NORMALIDADE (Shapiro-Wilk):\")\n",
        "print(f\"Estat√≠stica: {shapiro_stat:.4f}\")\n",
        "print(f\"P-valor: {shapiro_p:.4f}\")\n",
        "if shapiro_p > 0.05:\n",
        "    print(\"‚úÖ Res√≠duos seguem distribui√ß√£o normal (p > 0.05)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Res√≠duos podem n√£o seguir distribui√ß√£o normal (p ‚â§ 0.05)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 1: Seu Primeiro Modelo\n\nAgora √© sua vez! Vamos criar um dataset de **horas de estudo vs nota na prova** e voc√™ vai implementar uma regress√£o linear do zero!\n\n**Desafio:**\n1. Calcule os coeficientes Œ≤‚ÇÄ e Œ≤‚ÇÅ manualmente\n2. Fa√ßa previs√µes para 3 valores diferentes\n3. Calcule o R¬≤\n4. Interprete os resultados\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-04_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Horas de Estudo vs Nota na Prova\n",
        "\n",
        "# Dataset: Horas de estudo e notas correspondentes\n",
        "horas_estudo = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "notas_prova = np.array([4.2, 5.1, 5.8, 6.5, 7.2, 7.8, 8.4, 8.9, 9.1, 9.5])\n",
        "\n",
        "print(\"üìö DADOS DO EXERC√çCIO:\")\n",
        "print(f\"Horas de Estudo: {horas_estudo}\")\n",
        "print(f\"Notas da Prova: {notas_prova}\")\n",
        "\n",
        "# TODO: Sua implementa√ß√£o aqui!\n",
        "# 1. Calcule Œ≤‚ÇÄ e Œ≤‚ÇÅ usando as f√≥rmulas matem√°ticas\n",
        "\n",
        "# Suas vari√°veis:\n",
        "# x_media = ?\n",
        "# y_media = ?\n",
        "# beta_1 = ?\n",
        "# beta_0 = ?\n",
        "\n",
        "print(\"\\nüéØ COMPLETE O EXERC√çCIO ACIMA!\")\n",
        "print(\"Dica: Use as f√≥rmulas que vimos anteriormente\")\n",
        "\n",
        "# Visualize os dados primeiro\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(horas_estudo, notas_prova, color='purple', s=100, alpha=0.7)\n",
        "plt.xlabel('Horas de Estudo')\n",
        "plt.ylabel('Nota na Prova')\n",
        "plt.title('Rela√ß√£o: Horas de Estudo vs Nota na Prova')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Exemplo Avan√ßado: Dataset Real\n\nVamos trabalhar com um exemplo mais realista! Vou simular dados de **consumo de combust√≠vel vs dist√¢ncia percorrida** de um carro.\n\nAqui vamos ver como a regress√£o linear se comporta com dados que t√™m mais variabilidade, mais pr√≥ximos da realidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um dataset mais realista: Consumo de Combust√≠vel\n",
        "np.random.seed(123)\n",
        "\n",
        "# Dist√¢ncia percorrida (km)\n",
        "distancia_km = np.random.uniform(50, 500, 50)  # 50 viagens diferentes\n",
        "\n",
        "# Consumo de combust√≠vel (litros) - baseado na dist√¢ncia + ru√≠do\n",
        "# Assumindo um consumo m√©dio de 0.08 litros por km\n",
        "consumo_base = 0.08 * distancia_km\n",
        "ruido = np.random.normal(0, 1.5, len(distancia_km))\n",
        "consumo_litros = consumo_base + ruido\n",
        "consumo_litros = np.maximum(consumo_litros, 0)  # Garantir que n√£o seja negativo\n",
        "\n",
        "# Criando DataFrame para melhor visualiza√ß√£o\n",
        "df_combustivel = pd.DataFrame({\n",
        "    'Distancia_km': distancia_km,\n",
        "    'Consumo_litros': consumo_litros\n",
        "})\n",
        "\n",
        "print(\"üöó DATASET DE COMBUST√çVEL:\")\n",
        "print(df_combustivel.head(10))\n",
        "print(f\"\\nTotal de viagens: {len(df_combustivel)}\")\n",
        "\n",
        "# Estat√≠sticas descritivas (M√≥dulo 1!)\n",
        "print(\"\\nüìä ESTAT√çSTICAS DESCRITIVAS:\")\n",
        "print(df_combustivel.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lise explorat√≥ria dos dados\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# 1. Gr√°fico de dispers√£o\n",
        "axes[0].scatter(df_combustivel['Distancia_km'], df_combustivel['Consumo_litros'], \n",
        "               alpha=0.6, color='green')\n",
        "axes[0].set_xlabel('Dist√¢ncia (km)')\n",
        "axes[0].set_ylabel('Consumo (litros)')\n",
        "axes[0].set_title('Dispers√£o: Dist√¢ncia vs Consumo')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Histograma da dist√¢ncia\n",
        "axes[1].hist(df_combustivel['Distancia_km'], bins=15, alpha=0.7, color='blue', edgecolor='black')\n",
        "axes[1].set_xlabel('Dist√¢ncia (km)')\n",
        "axes[1].set_ylabel('Frequ√™ncia')\n",
        "axes[1].set_title('Distribui√ß√£o das Dist√¢ncias')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Histograma do consumo\n",
        "axes[2].hist(df_combustivel['Consumo_litros'], bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
        "axes[2].set_xlabel('Consumo (litros)')\n",
        "axes[2].set_ylabel('Frequ√™ncia')\n",
        "axes[2].set_title('Distribui√ß√£o do Consumo')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculando a correla√ß√£o\n",
        "correlacao_combustivel = df_combustivel['Distancia_km'].corr(df_combustivel['Consumo_litros'])\n",
        "print(f\"\\nüîó CORRELA√á√ÉO: {correlacao_combustivel:.4f}\")\n",
        "if correlacao_combustivel > 0.8:\n",
        "    print(\"‚úÖ Correla√ß√£o muito forte! Regress√£o linear deve funcionar bem.\")\n",
        "elif correlacao_combustivel > 0.6:\n",
        "    print(\"‚úÖ Correla√ß√£o forte! Regress√£o linear √© uma boa op√ß√£o.\")\n",
        "elif correlacao_combustivel > 0.3:\n",
        "    print(\"‚ö†Ô∏è Correla√ß√£o moderada. Regress√£o linear pode funcionar.\")\n",
        "else:\n",
        "    print(\"‚ùå Correla√ß√£o fraca. Regress√£o linear pode n√£o ser a melhor op√ß√£o.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementando a regress√£o linear no dataset de combust√≠vel\n",
        "\n",
        "# Preparando os dados\n",
        "X_combustivel = df_combustivel['Distancia_km'].values.reshape(-1, 1)\n",
        "y_combustivel = df_combustivel['Consumo_litros'].values\n",
        "\n",
        "# Treinando o modelo\n",
        "modelo_combustivel = LinearRegression()\n",
        "modelo_combustivel.fit(X_combustivel, y_combustivel)\n",
        "\n",
        "# Fazendo previs√µes\n",
        "y_pred_combustivel = modelo_combustivel.predict(X_combustivel)\n",
        "\n",
        "# Coeficientes\n",
        "beta_0_comb = modelo_combustivel.intercept_\n",
        "beta_1_comb = modelo_combustivel.coef_[0]\n",
        "\n",
        "print(\"üöó RESULTADOS DA REGRESS√ÉO - COMBUST√çVEL:\")\n",
        "print(f\"Œ≤‚ÇÄ (intercepto): {beta_0_comb:.4f} litros\")\n",
        "print(f\"Œ≤‚ÇÅ (inclina√ß√£o): {beta_1_comb:.4f} litros/km\")\n",
        "print(f\"\\nInterpreta√ß√£o:\")\n",
        "print(f\"- Para cada km rodado, o consumo aumenta {beta_1_comb:.4f} litros\")\n",
        "print(f\"- Consumo base (0 km): {beta_0_comb:.2f} litros\")\n",
        "\n",
        "# M√©tricas de avalia√ß√£o\n",
        "mse_comb = mean_squared_error(y_combustivel, y_pred_combustivel)\n",
        "r2_comb = r2_score(y_combustivel, y_pred_combustivel)\n",
        "rmse_comb = np.sqrt(mse_comb)\n",
        "\n",
        "print(f\"\\nüìä M√âTRICAS:\")\n",
        "print(f\"MSE: {mse_comb:.4f}\")\n",
        "print(f\"RMSE: {rmse_comb:.4f} litros\")\n",
        "print(f\"R¬≤: {r2_comb:.4f} ({r2_comb*100:.1f}% da varia√ß√£o explicada)\")\n",
        "\n",
        "# Visualizando o resultado\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Pontos originais\n",
        "plt.scatter(df_combustivel['Distancia_km'], df_combustivel['Consumo_litros'], \n",
        "           alpha=0.6, color='green', s=60, label='Dados Reais')\n",
        "\n",
        "# Linha de regress√£o\n",
        "x_range = np.linspace(df_combustivel['Distancia_km'].min(), \n",
        "                     df_combustivel['Distancia_km'].max(), 100)\n",
        "y_range = modelo_combustivel.predict(x_range.reshape(-1, 1))\n",
        "plt.plot(x_range, y_range, color='red', linewidth=3, \n",
        "         label=f'Regress√£o: y = {beta_1_comb:.4f}x + {beta_0_comb:.2f}')\n",
        "\n",
        "plt.xlabel('Dist√¢ncia Percorrida (km)')\n",
        "plt.ylabel('Consumo de Combust√≠vel (litros)')\n",
        "plt.title(f'Regress√£o Linear: Consumo vs Dist√¢ncia (R¬≤ = {r2_comb:.3f})')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüéØ Modelo final: Consumo = {beta_1_comb:.4f} √ó Dist√¢ncia + {beta_0_comb:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 2: An√°lise Completa\n\nSeu desafio final! Vou dar dados de **temperatura vs vendas de sorvete** e voc√™ vai fazer uma an√°lise completa:\n\n**Tarefas:**\n1. An√°lise explorat√≥ria\n2. Implementar regress√£o linear\n3. Avaliar o modelo\n4. Analisar res√≠duos\n5. Fazer 3 previs√µes\n6. Dar sua conclus√£o final\n\n**Dica do Pedro:** Use tudo que aprendemos at√© aqui! √â sua chance de brilhar! üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Temperatura vs Vendas de Sorvete\n",
        "np.random.seed(456)\n",
        "\n",
        "# Dados: Temperatura (¬∞C) vs Vendas de Sorvete (unidades)\n",
        "temperatura = np.array([18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
        "vendas_sorvete = np.array([45, 55, 65, 78, 85, 95, 110, 125, 140, 155, 170, 180]) + \\\n",
        "                np.random.normal(0, 8, len(temperatura))\n",
        "\n",
        "print(\"üç¶ DADOS: TEMPERATURA VS VENDAS DE SORVETE\")\n",
        "print(\"Temperatura (¬∞C):\", temperatura)\n",
        "print(\"Vendas (unidades):\", vendas_sorvete.astype(int))\n",
        "\n",
        "# TODO: Sua an√°lise completa aqui!\n",
        "\n",
        "# 1. AN√ÅLISE EXPLORAT√ìRIA\n",
        "print(\"\\nüìä 1. AN√ÅLISE EXPLORAT√ìRIA:\")\n",
        "# Calcule estat√≠sticas descritivas\n",
        "# Fa√ßa gr√°fico de dispers√£o\n",
        "# Calcule correla√ß√£o\n",
        "\n",
        "# 2. REGRESS√ÉO LINEAR\n",
        "print(\"\\nüî¢ 2. REGRESS√ÉO LINEAR:\")\n",
        "# Implemente ou use sklearn\n",
        "# Encontre Œ≤‚ÇÄ e Œ≤‚ÇÅ\n",
        "# Interprete os coeficientes\n",
        "\n",
        "# 3. AVALIA√á√ÉO DO MODELO\n",
        "print(\"\\nüìà 3. AVALIA√á√ÉO:\")\n",
        "# Calcule MSE, RMSE, R¬≤\n",
        "# Fa√ßa gr√°fico com linha de regress√£o\n",
        "\n",
        "# 4. AN√ÅLISE DE RES√çDUOS\n",
        "print(\"\\nüîç 4. RES√çDUOS:\")\n",
        "# Analise os res√≠duos\n",
        "# Verifique normalidade\n",
        "\n",
        "# 5. PREVIS√ïES\n",
        "print(\"\\nüéØ 5. PREVIS√ïES:\")\n",
        "# Preveja vendas para: 25¬∞C, 35¬∞C, 42¬∞C\n",
        "\n",
        "# 6. CONCLUS√ÉO\n",
        "print(\"\\nüí≠ 6. SUA CONCLUS√ÉO:\")\n",
        "# O modelo √© bom? Por qu√™?\n",
        "# Quais s√£o as limita√ß√µes?\n",
        "\n",
        "print(\"\\nüöÄ M√ÉOS √Ä OBRA! Complete todas as se√ß√µes acima.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Limita√ß√µes e Cuidados da Regress√£o Linear\n\nAntes de terminar, √© importante conhecer as **limita√ß√µes** da regress√£o linear simples:\n\n### üö® Pressupostos da Regress√£o Linear:\n\n1. **Linearidade**: A rela√ß√£o entre X e Y deve ser linear\n2. **Independ√™ncia**: As observa√ß√µes devem ser independentes\n3. **Homocedasticidade**: Vari√¢ncia dos res√≠duos deve ser constante\n4. **Normalidade**: Res√≠duos devem seguir distribui√ß√£o normal\n5. **Aus√™ncia de Outliers**: Pontos extremos podem distorcer o modelo\n\n### üîç Quando N√ÉO usar Regress√£o Linear:\n- Rela√ß√£o n√£o-linear entre vari√°veis\n- Dados categ√≥ricos (use regress√£o log√≠stica - M√≥dulo 6!)\n- M√∫ltiplas vari√°veis independentes (use regress√£o m√∫ltipla)\n- Dados com muitos outliers\n\n**Dica do Pedro:** A regress√£o linear √© poderosa, mas n√£o √© martelo para todo parafuso! Sempre analise seus dados primeiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de quando a regress√£o linear N√ÉO funciona bem\n",
        "\n",
        "# Criando dados com rela√ß√£o n√£o-linear (quadr√°tica)\n",
        "x_nao_linear = np.linspace(-3, 3, 50)\n",
        "y_nao_linear = x_nao_linear**2 + np.random.normal(0, 0.5, len(x_nao_linear))\n",
        "\n",
        "# Tentando ajustar regress√£o linear em dados n√£o-lineares\n",
        "modelo_ruim = LinearRegression()\n",
        "modelo_ruim.fit(x_nao_linear.reshape(-1, 1), y_nao_linear)\n",
        "y_pred_ruim = modelo_ruim.predict(x_nao_linear.reshape(-1, 1))\n",
        "\n",
        "# R¬≤ vai ser baixo!\n",
        "r2_ruim = r2_score(y_nao_linear, y_pred_ruim)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Subplot 1: Dados n√£o-lineares com linha linear\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x_nao_linear, y_nao_linear, alpha=0.6, color='red', label='Dados Reais')\n",
        "plt.plot(x_nao_linear, y_pred_ruim, color='blue', linewidth=2, label='Regress√£o Linear')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title(f'‚ùå Regress√£o Linear em Dados N√£o-Lineares\\n(R¬≤ = {r2_ruim:.3f})')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Res√≠duos mostram padr√£o claro\n",
        "residuos_ruim = y_nao_linear - y_pred_ruim\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_pred_ruim, residuos_ruim, alpha=0.6, color='red')\n",
        "plt.axhline(y=0, color='blue', linestyle='--')\n",
        "plt.xlabel('Valores Previstos')\n",
        "plt.ylabel('Res√≠duos')\n",
        "plt.title('‚ùå Res√≠duos com Padr√£o Claro\\n(Indica modelo inadequado)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚ö†Ô∏è EXEMPLO DE MODELO INADEQUADO:\")\n",
        "print(f\"R¬≤ = {r2_ruim:.3f} (muito baixo!)\")\n",
        "print(f\"Os res√≠duos mostram um padr√£o claro - sinal de que o modelo linear n√£o √© adequado.\")\n",
        "print(f\"\\nSolu√ß√£o: Usar modelos n√£o-lineares ou transformar os dados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resumo e Conex√µes com o Curso\n\nLiiindo! Chegamos ao final do M√≥dulo 4! Vamos recapitular o que aprendemos:\n\n### üß† O que vimos hoje:\n1. **Conceito**: Regress√£o linear encontra a melhor linha reta nos dados\n2. **Matem√°tica**: M√©todo dos m√≠nimos quadrados minimiza os erros ao quadrado\n3. **F√≥rmulas**: Œ≤‚ÇÅ e Œ≤‚ÇÄ calculados com base nas m√©dias e vari√¢ncias\n4. **Avalia√ß√£o**: MSE, RMSE e R¬≤ nos dizem qu√£o bom √© o modelo\n5. **Res√≠duos**: An√°lise dos erros revela problemas do modelo\n\n### üîó Conex√µes com m√≥dulos anteriores:\n- **M√≥dulo 1**: Usamos m√©dia, vari√¢ncia e desvio padr√£o nas f√≥rmulas\n- **M√≥dulo 2**: Assumimos distribui√ß√£o normal dos res√≠duos\n- **M√≥dulo 3**: Aplicamos conceitos de probabilidade condicional\n\n### üöÄ Preparando para os pr√≥ximos m√≥dulos:\n- **M√≥dulo 5**: Vamos aprofundar correla√ß√£o e covari√¢ncia\n- **M√≥dulo 6**: Regress√£o log√≠stica para classifica√ß√£o\n- **M√≥dulo 7**: Amostragem e generaliza√ß√£o dos resultados\n\n```mermaid\ngraph LR\n    A[Dados X,Y] --> B[An√°lise Explorat√≥ria]\n    B --> C[Verificar Correla√ß√£o]\n    C --> D[Calcular Œ≤‚ÇÄ e Œ≤‚ÇÅ]\n    D --> E[Fazer Previs√µes]\n    E --> F[Avaliar com R¬≤, MSE]\n    F --> G[Analisar Res√≠duos]\n    G --> H[Modelo Final!]\n```\n\n**Dica do Pedro Final**: A regress√£o linear √© a base de muitos algoritmos de machine learning! Dominando ela, voc√™ tem uma base s√≥lida para algoritmos mais complexos.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/estat√≠stica-para-ia-modulo-04_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéâ PARAB√âNS! Voc√™ completou o M√≥dulo 4!\n",
        "\n",
        "# Vamos criar um certificado visual do que voc√™ aprendeu\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Dados para demonstra√ß√£o final\n",
        "x_final = np.linspace(0, 10, 100)\n",
        "y_final = 2 * x_final + 1 + np.random.normal(0, 1, 100)\n",
        "\n",
        "# Regress√£o final\n",
        "modelo_final = LinearRegression()\n",
        "modelo_final.fit(x_final.reshape(-1, 1), y_final)\n",
        "y_pred_final = modelo_final.predict(x_final.reshape(-1, 1))\n",
        "\n",
        "# Gr√°fico bonito\n",
        "ax.scatter(x_final, y_final, alpha=0.5, color='lightblue', s=30)\n",
        "ax.plot(x_final, y_pred_final, color='red', linewidth=3)\n",
        "\n",
        "ax.set_xlabel('Vari√°vel Independente (X)', fontsize=14)\n",
        "ax.set_ylabel('Vari√°vel Dependente (Y)', fontsize=14)\n",
        "ax.set_title('üéì REGRESS√ÉO LINEAR SIMPLES - M√ìDULO 4 CONCLU√çDO!\\n' + \n",
        "            'Voc√™ agora sabe como encontrar a linha que prev√™ o futuro!', \n",
        "            fontsize=16, pad=20)\n",
        "\n",
        "# Anota√ß√µes educativas\n",
        "ax.annotate('Pontos = Dados Reais', xy=(2, 6), xytext=(3, 15),\n",
        "            arrowprops=dict(arrowstyle='->', color='blue'),\n",
        "            fontsize=12, color='blue')\n",
        "\n",
        "ax.annotate('Linha Vermelha = Modelo de Regress√£o', \n",
        "            xy=(7, 15), xytext=(5, 20),\n",
        "            arrowprops=dict(arrowstyle='->', color='red'),\n",
        "            fontsize=12, color='red')\n",
        "\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéâ PARAB√âNS! VOC√ä DOMINOU A REGRESS√ÉO LINEAR SIMPLES!\")\n",
        "print(\"\\n‚úÖ Checklist do que voc√™ aprendeu:\")\n",
        "print(\"   ‚Ä¢ Conceitos matem√°ticos por tr√°s da regress√£o\")\n",
        "print(\"   ‚Ä¢ M√©todo dos m√≠nimos quadrados\")\n",
        "print(\"   ‚Ä¢ C√°lculo de Œ≤‚ÇÄ e Œ≤‚ÇÅ\")\n",
        "print(\"   ‚Ä¢ M√©tricas de avalia√ß√£o (MSE, RMSE, R¬≤)\")\n",
        "print(\"   ‚Ä¢ An√°lise de res√≠duos\")\n",
        "print(\"   ‚Ä¢ Implementa√ß√£o pr√°tica com Python\")\n",
        "print(\"   ‚Ä¢ Limita√ß√µes e cuidados\")\n",
        "print(\"\\nüöÄ PR√ìXIMO M√ìDULO: Correla√ß√£o e Covari√¢ncia - Onde as Vari√°veis se Encontram\")\n",
        "print(\"\\nBora continuar essa jornada incr√≠vel pela estat√≠stica! üìä‚ú®\")"
      ]
    }
  ]
}